Name,TitlesAndAbstracts
Bei Yu,"Topic modeling for evaluating students' reflective writing -- Journal writing is an important and common reflective practice in education. Students' reflection journals also offer a rich source of data for formative assessment. However, the analysis of the textual reflections in class of large size presents challenges. Automatic analysis of students' reflective writing holds great promise for providing adaptive real time support for students. This paper proposes a method based on topic modeling techniques for the task of themes exploration and reflection grade prediction. We evaluated this method on a sample of journal writings from pre-service teachers. The topic modeling method was able to discover the important themes and patterns emerged in students' reflection journals. Weekly topic relevance and word count were identified as important indicators of their journal grades. Based on the patterns discovered by topic modeling, prediction models were developed to automate the assessing and grading of reflection journals. The findings indicate the potential of topic modeling in serving as an analytic tool for teachers to explore and assess students' reflective thoughts in written journals.; Language and ideology in congress -- Legislative speech records from the 101st to 108th Congresses of the US Senate are analysed to study political ideologies. A widely-used text classification algorithm - Support Vector Machines (SVM) - allows the extraction of terms that are most indicative of conservative and liberal positions in legislative speeches and the prediction of senators' ideological positions, with a 92 per cent level of accuracy. Feature analysis identifies the terms associated with conservative and liberal ideologies. The results demonstrate that cultural references appear more important than economic references in distinguishing conservative from liberal congressional speeches, calling into question the common economic interpretation of ideological differences in the US Congress.; 3rd International Workshop on news recommendation and analytics (INRA 2015) -- The 3rd International Workshop on News Recommendation and Analytics (INRA 2015) is held in conjunction with RecSys 2015 Conference in Vienna, Austria. This paper presents a brief summary of the INRA 2015. This workshop aims to create an interdisciplinary community that addresses design issues in news recommender systems and news analytics, and promote fruitful collaboration opportunities between researchers, media companies and practitioners. We have a keynote speaker and an invited demo presentation in addition to 4 papers accepted in this workshop.; Documenting business-to-consumer (B2C) communications on facebook -- Purpose – The purpose of this study is to document how restaurant’s business-to-consumer communication strategies evolved on Facebook over time and how consumers’ reactions to a variety of Facebook messages changed over time. Design/methodology/approach – This study analyzed 2,463 Facebook messages posted by seven quick-service restaurant chains and three casual-dining restaurant chains in the fourth quarter of 2010, 2012 and 2014. ANOVA and post hoc t-test were used to compare the differences among four media types (photo, status update, video and hyperlink) in terms of their usage by companies and Facebook users’ reactions to these messages (measured by number of “Likes”, number of comments and number of shares). Findings – Over the three periods of time under observation, there is a substantial decrease of status updates by restaurants and a dramatic increase of photo updates. Photo remained as the most “popular” media type, receiving most “Likes”, comments and shares from consumers. Video was not considered “popular” in 2010 but experienced a slight increase in usage and slowly emerged in 2012 and 2014 as another “popular” media, which no longer had statistical difference with photo in number of comments and shares. Research limitations/implications – Some limitations include an under representable sample and its longitudinal design, but the fndings provide additional insight to current literature in social media. Practical implications – A series of suggestions were advanced from the fndings to help hospitality managers better engage Facebook users. Originality/value – This is probably the frst time-series or longitudinal-like analysis in social media research and yields meaningful fndings.; Exploring the relationship between mood and creativity in rock lyrics -- The relationship between mood and creativity has been widely studied in psychology, however, no conclusion is reached in terms of which mood triggers high creativity, positive or negative. This paper provides new insights to this on-going argument by examining the relationship between lyrics creativity and music mood. We use three computational measures to gauge lyrics creativity: Type-to- Token Ratio, word norms fraction, and WordNet similarity. We then test three hypotheses regarding differences in lyrics creativity between music with different moods on 2715 U.S. rock songs. The three measures led to consistent findings that lyrics of negative and sad songs demonstrate higher linguistic creativity than those of positive and happy songs. Our findings support previous studies in psycholinguistics that people write more creatively when the text conveys sad or negative sentiment, and contradict previous research that positive mood triggers more unusual word associations. The result also indicates that different measures capture different aspects of lyrics creativity.; Teaching information science and technology to the world? Practices, challenges and visions -- Information science and technology (IST) has made unprecedented impacts on society. Teaching IST should by no means be limited within the boundary of the discipline. Based on their experiences in teaching IST in various levels, speakers in this panel will reflect the past, share current practices and envision the future of teaching IST to the world. Collectively we aim to stimulate further discussions on increasing the impact of the field through education.; Spreading Social Media Messages on Facebook -- As a method of determining what types of social media messages work best for hospitality firms, this study examined what types of messages gained the most clicks of ""Like"" and comments on Facebook. An analysis of the number of likes and comments regarding nine hundred and eighty-two Facebook messages from ten restaurant chains and two independent operators revealed clear patterns. The more popular keywords involved information about the restaurant (e.g., menu descriptions) and the less popular messages were those that contained marketing-related words (including ""winner"" and ""check""). Dividing the messages into four media types, namely, status (text only), link (containing a URL), video (embedding a video), and photo (showing photos), revealed that photo and status receive more likes and comments than the other two categories. Social media messages can also be categorized into two message types: sales and marketing (about two-thirds of the messages in this study) and conversational messages. Based on number of likes and comments, conversational messages are endorsed by more Facebook users. Finally, cross-effects of media type and message type affect the number of comments a message received. Although these results do not expressly assess Facebook users' reactions, the guidelines developed here should help managers improve their use of Facebook, as well as provide groundwork for developing a defined typology of Facebook messages and an automatic text classifier with the machine learning techniques.; Taxonomy of Facebook messages in business-to-consumer communications -- This research combines machine learning and human intelligence to analyze 2654 Facebook messages initiated by 26 hospitality companies to develop the taxonomy of Facebook messages in business-toconsumer (B2C) communications. Facebook messages can be classified into two broad message types: Sales/Marketing messages, with five sub-categories of Social Responsibility, Direct Boasting, Indirect Boasting, Product Highlight, and Campaign/Sales, and Conversational messages, with four sub-categories of Call for Action, Provoke Feedback, Advice/Suggestions, and Updates. By comparison, Conversational messages received more ""Likes"" and comments than Sales/Marketing messages. Direct Boasting, Product Highlight, Call for Action, Provoke Feedback, Advice/Suggestions, and Updates received more ""Likes"" than other types; Provoke Feedback and Call for Action received more comments. As compared to current literature, the results allow managers to advance more specific strategies to better engage with Facebook users and provide a more thorough taxonomy for additional analysis on companies' B2C messages on other social media websites.; The 7 Ps marketing mix of home-sharing services -- The 7 Ps model is a very useful tool in helping service firms solve managerial issues in marketing. Guided by the 7 Ps marketing mix framework, a big-data, supervised machine learning analysis was performed with 1,148,062 English reviews of 37,092 Airbnb listings in San Francisco and New York City. The results disclose similar patterns in both markets, where travelers shared their experience about Service Product and Physical Evidence most often; Price and Promotion were the least mentioned elements. Furthermore, through a series of comparisons of Airbnb's 7 Ps marketing mix among the listings managed by different types of hosts, multi-unit and single-unit hosts seem to offer similar services with a small observable difference; whereas superhosts and the ordinary hosts deliver different services. This study makes valuable methodological contributions and provides practical marketing insights for hoteliers and the hosts and webmasters on home-sharing websites. Policymakers should pay special attention to multi-unit hosts.; Identifying Finding Sentences in Conclusion Subsections of Biomedical Abstracts -- Segmenting scientific abstracts and full-text based on their rhetorical function is an essential task in text classification. Small rhetorical segments can be useful for fine-grained literature search, summarization, and comparison. Current effort has been focusing on segmenting documents into general sections such as introduction, method, and conclusion, and much less on the roles of individual sentences within the segments. For example, not all sentences in the conclusion section are describing research findings. In this work, we developed rule-based and machine learning methods and compared their performance in identifying the finding sentences in conclusion subsections of biomedical abstracts. 1100 conclusion subsections with observational and randomized clinical trials study designs covering five common health topics were sampled from PubMed to develop and evaluate the methods. The rule-based method and the bag-of-words based machine learning method both achieved high accuracy. The better performance by the simple rule-based approach shows that although advanced machine learning approaches could capture the main patterns, human expert may still outperform on such a specialized task.; Interventions to support consumer evaluation of online health information credibility -- Purpose: Various interventions have been designed to help consumers better evaluate the credibility of online health information (OHI). However, assessing information credibility remained the most widely reported challenge by online health consumers. This review aims to provide an overview of major intervention approaches for improving consumer ability to evaluate OHI credibility in order to identify opportunities for future interventions. Methods: A scoping review was performed. Seven relevant scientific databases were searched to identify articles that report the design and/or evaluation of interventions to support, facilitate, or assist consumers in assessing the credibility of OHI. Thirty-one articles met the inclusion criteria. Relevant content was extracted from the articles and all codes were validated by second coders. Results: Three major intervention approaches for enhancing consumers' ability to evaluate OHI credibility were identified: educational program, algorithm, and interactive interface. The design of most interventions (particularly the credibility evaluation component) lacked the guidance of theories, and very few studies systematically evaluated their effectiveness in real online search contexts. Few interventions can provide spontaneous support to consumers while they search online. Conclusion: Our understanding of what theoretical constructs contribute to effective OHI credibility evaluation interventions and how intervention outcomes should be measured remained limited. Future efforts need to focus on the design, development, test, and evaluation of theory-guided OHI credibility evaluation interventions that are scalable, sustainable, and can provide real-time support to consumers.; Collecting representative pictures for words -- This poster proposes a human computation approach to collecting representative pictures for words so that the collected pictures can efficiently and effectively convey the meaning of the words or concepts. A large collection of representative pictures can be used in text-to-picture communication systems, and may also be used to teach computers to learn what representative pictures are. We have developed a web application to help players of Draw Something, a popular social mobile game, search pictures for drawing inspiration while at the same time they implicitly help us collect representative pictures for words. Our preliminary result shows that the proposed approach has the potential to harvest Draw Something players for collecting desired data.; Sentence recall game -- Recently we ran a simple memory test experiment, called sentence recall, in which participants were asked to recall sentences that they had just seen on the screen. Many participants, especially non-native English speakers, made various deviations in their recalled sentences. Some deviations represent alternative ways to express the same meaning, but others suggest that there are missing pieces in the participants' language knowledge. The deviation data, on the one hand, can provide individual users valuable feedback on their language usage patterns that they may never notice, on the other hand, can be used as training data for automatically discovering language usage patterns in a subpopulation of language learners. This paper presents our attempts to create an enjoyable sentence recall game for collecting a large amount of deviation data. Our results show that the game is fun to play and the collected deviation data can reveal common language usage patterns among non-native speakers.; Toward predicting popularity of social marketing messages -- Popularity of social marketing messages indicates the effectiveness of the corresponding marketing strategies. This research aims to discover the characteristics of social marketing messages that contribute to different level of popularity. Using messages posted by a sample of restaurants on Facebook as a case study, we measured the message popularity by the number of ""likes"" voted by fans, and examined the relationship between the message popularity and two properties of the messages: (1) content, and (2) media type. Combining a number of text mining and statistics methods, we have discovered some interesting patterns correlated to ""more popular"" and ""less popular"" social marketing messages. This work lays foundation for building computational models to predict the popularity of social marketing messages in the future.; Collecting legacy corpora from social science research for text mining evaluation -- In this poster we describe a pilot study of searching social science literature for legacy corpora to evaluate text mining algorithms. The new emerging field of computational social science demands large amount of social science data to train and evaluate computational models. We argue that the legacy corpora that were annotated by social science researchers through traditional Qualitative Data Analysis (QDA) are ideal data sets to evaluate text mining methods, such as text categorization and clustering. As a pilot study, we searched articles that involve content analysis and discourse analysis in leading communication journals, and then contacted the authors regarding the availability of the annotated texts. Regretfully, nearly all of the corpora that we found were not adequately maintained, and many were no longer available, even though they were less than ten years old. This situation calls for more effort to better maintain and use legacy social science data for future computational social science research purpose.; Crowdsourcing participatory evaluation of medical pictograms using amazon mechanical turk -- Background: Consumer and patient participation proved to be an effective approach for medical pictogram design, but it can be costly and time-consuming. We proposed and evaluated an inexpensive approach that crowdsourced the pictogram evaluation task to Amazon Mechanical Turk (MTurk) workers, who are usually referred to as the ""turkers"". Objective: To answer two research questions: (1) Is the turkers' collective effort effective for identifying design problems in medical pictograms? and (2) Do the turkers' demographic characteristics affect their performance in medical pictogram comprehension? Methods: We designed a Web-based survey (open-ended tests) to ask 100 US turkers to type in their guesses of the meaning of 20 US pharmacopeial pictograms. Two judges independently coded the turkers' guesses into four categories: correct, partially correct, wrong, and completely wrong. The comprehensibility of a pictogram was measured by the percentage of correct guesses, with each partially correct guess counted as 0.5 correct. We then conducted a content analysis on the turkers' interpretations to identify misunderstandings and assess whether the misunderstandings were common. We also conducted a statistical analysis to examine the relationship between turkers' demographic characteristics and their pictogram comprehension performance. Results: The survey was completed within 3 days of our posting the task to the MTurk, and the collected data are publicly available in the multimedia appendix for download. The comprehensibility for the 20 tested pictograms ranged from 45% to 98%, with an average of 72.5%. The comprehensibility scores of 10 pictograms were strongly correlated to the scores of the same pictograms reported in another study that used oral response-based open-ended testing with local people. The turkers' misinterpretations shared common errors that exposed design problems in the pictograms. Participant performance was positively correlated with their educational level. Conclusions: The results confirmed that crowdsourcing can be used as an effective and inexpensive approach for participatory evaluation of medical pictograms. Through Web-based open-ended testing, the crowd can effectively identify problems in pictogram designs. The results also confirmed that education has a significant effect on the comprehension of medical pictograms. Since low-literate people are underrepresented in the turker population, further investigation is needed to examine to what extent turkers' misunderstandings overlap with those elicited from low-literate people.; Language and gender in congressional speech -- This study draws from a large corpus of Congressional speeches from the 101st to the 110th Congress (1989-2008), to examine gender differences in language use in a setting of political debates. Female legislators' speeches demonstrated characteristics of both a feminine language style (e.g. more use of emotion words, fewer articles) and a masculine one (e.g. more nouns and long words, fewer personal pronouns). A trend analysis found that these gender differences have consistently existed in the Congressional speeches over the past 20 years, regardless of the topic of debate. The findings lend support to the argument that gender differences in language use persist in professional settings like the floor of Congress.; The emotional world of health online communities -- This article presents a preliminary study on the emotional world of health online communities. Using sentiment analysis and natural language processing techniques, this study aims to (1) examine the strength of various kinds of emotions (positivity, optimism, negativity, anxiety, anger, and sadness) in online health forum discussions, and (2) compare the emotional status and expression of forum participants under different roles, such as askers and answerers, men and women, and caregivers and patients. This study is expected to improve the understanding of the emotional communication in online health communities.; Automated citation sentiment analysis -- Automated citation sentiment analysis is a newly emerged research topic inspired by traditional citation context analysis in scientometrics and applied linguistics. The main goals of current citation sentiment analysis are to develop new tools to model scientific literature and provide authoring support for researchers in tasks like literature review. In terms of developing authoring support tools, however, current studies have not taken into consideration the behavioral patterns of researchers' literature review practice, leaving user need assessment as a missing piece in current interdisciplinary research effort. This paper analyzed biomedical researchers' need by reviewing their publications on using manual citation sentiment analysis for detecting citation bias, and discussed the differences between biomedical researchers' approach and current automated citation sentiment analysis model. These differences are expected to inform the modeling of automated citation sentiment analysis.; Auto-tracking controversial topics in social-media-based customer dialog -- This study proposed and validated a topic modeling-based approach for auto-tracking customer dialog on social media, using Starbucks as a case study because of its pioneering social media practice in service industry. A topic model was fit based on nearly 150,000 customer comments posted to Starbucks’ Facebook page in 2013. This model was able to identify not only business-related topics, such as customer responses to marketing campaigns, but also controversial topics regarding community involvement and corporate social responsibility, such as gay, gun, and government. Guided by this topic model, each topic’s evolving dynamics and patterns of user participation were further revealed, providing a bird’s-eye view of the topics and their evolution. The case study has demonstrated that the proposed approach can effectively track the main themes in the customer dialog on social media, zoom in on the controversial topics, measure their time spans, and locate the participants and the vocal activists. Such information would be valuable input for companies to design their intervention strategies and evaluate the outcomes in social media discussions.; Detecting causal language use in science findings -- Causal interpretation of correlational findings from observational studies has been a major type of misinformation in science communication. Prior studies on identifying inappropriate use of causal language relied on manual content analysis, which is not scalable for examining a large volume of science publications. In this study, we first annotated a corpus of over 3,000 PubMed research conclusion sentences, then developed a BERT-based prediction model that classifies conclusion sentences into “no relationship”, “correlational”, “conditional causal”, and “direct causal” categories, achieving an accuracy of 0.90 and a macroF1 of 0.88. We then applied the prediction model to measure the causal language use in the research conclusions of about 38,000 observational studies in PubMed. The prediction result shows that 21.7% studies used direct causal language exclusively in their conclusions, and 32.4% used some direct causal language. We also found that the ratio of causal language use differs among authors from different countries, challenging the notion of a shared consensus on causal language use in the global science community. Our prediction model could also be used to help identify the inappropriate use of causal language in science publications.; Measuring Correlation-to-Causation Exaggeration in Press Releases -- Press releases have an increasingly strong influence on media coverage of health research; however, they have been found to contain seriously exaggerated claims that can misinform the public and undermine public trust in science. In this study we propose an NLP approach to identify exaggerated causal claims made in health press releases that report on observational studies, which are designed to establish correlational findings, but are often exaggerated as causal. We developed a new corpus and trained models that can identify causal claims in the main statements in a press release. By comparing the claims made in a press release with the corresponding claims in the original research paper, we found that 22% of press releases made exaggerated causal claims from correlational findings in observational studies. Furthermore, universities exaggerated more often than journal publishers by a ratio of 1.5 to 1. Encouragingly, the exaggeration rate has slightly decreased over the past 10 years, despite the increase of the total number of press releases. More research is needed to understand the cause of the decreasing pattern.; HClaimE -- This study tackles the problem of extracting health claims from health research news headlines, in order to carry out veracity check. A health claim can be formally defined as a triplet consisting of an independent variable (IV – namely, what is being manipulated), a dependent variable (DV – namely, what is being measured), and the relation between the two. In this study, we develop HClaimE, an information extraction tool for identifying health claims in news headlines. Unlike the existing open information extraction (OpenIE) systems that rely on verbs as relation indicators, HClaimE focuses on finding relations between nouns, and draws on the linguistic characteristics of news headlines. HClaimE uses a Naïve Bayes classifier that combines syntactic and lexical features for identifying IV and DV nouns, and recognizes relations between IV and DV through a rule-based method. We conducted an evaluation on a set of health news headlines from ScienceDaily.com, and the results show that HClaimE outperforms current OpenIE systems: the F-measures for identifying headlines without health claims is 0.60 and that for extracting IV-relation-DV is 0.69. Our study shows that nouns can provide more clues than verbs for identifying health claims in news headlines. Furthermore, it also shows that dependency relations and bag-of-words can distinguish IV-DV noun pairs from other noun pairs. In practice, HClaimE can be used as a helpful tool to identifying health claims in news headlines, which can then be further compared against authoritative health claims for veracity. Given the linguistic similarity between health claims and other causal claims, e.g., impacts of pollution on the environment, HClaimE may also be applicable for extracting claims in other domains.; Information quality of reddit link posts on health news -- Inaccuracy has been a common problem in news coverage of scientific research. This problem has been particularly prevalent in health research news. Health research news usually spreads from research publications and press releases to news and social media. In this study we examined the information quality of the Reddit link posts that introduce health news stories. We developed a coding schema to annotate the inaccurate information in a sample of 250 link posts on health research news within the Reddit community r/Health in 2018. The result shows that most link posts simply copied the original news headlines verbatim, while some paraphrased the news stories by adding, deleting, replacing, and combining content. We found that 12 paraphrased link posts contained inaccurate information that may mislead the readers. The most common type of inaccuracy is exaggeration resulted from changing the original speculative claims to direct causal statements by removing the modal verbs such as “may” and “might”. The result shows that although the link posts of health news were generally faithful to the original news stories, exaggerated claims may lead to false hope for researchers and patients."
Beth Patin,"Struggling to breathe -- Purpose: The purpose of this article is to provide a follow up to “Libraries on the Frontlines: Neutrality and Social Justice,” which was published here in 2017. It addresses institutional responses to protests and uprising in the spring and summer of 2020 after the deaths of Ahmaud Arbery, Breonna Taylor and George Floyd, all of which occurred in the context of the global COVID-19 pandemic. The article expands the previous call for libraries to take a stand for Black lives. Design/methodology/approach: The authors describe the events of 2020 (a global pandemic, multiple murders of unarmed Black people and the consequent global protests) and responses from within library and information science (LIS), from the perspectives as women of color faculty and library professionals. Findings: The authors comment on how libraries are responding to current events, as well as the possibilities for panethnic solidarity. The authors also consider specifically how libraries and other institutions are responding to the racial uprisings through statements on social media and call for concrete action to ensure that their organizations and information practices are actively antiracist. In so doing, the authors update the claims and expand the appeals they made in 2017,that Black Lives Matter and that librarianship must not remain neutral. Originality/value: This paper addresses recent institutional and governmental reactions to the COVID-19 pandemic and the racial uprisings of spring and summer 2020. It is original, current and timely as it interrogates ongoing events in a LIS context."
Bruce Kingma,"University-wide entrepreneurship education -- In 2004 and 2007, the Kauffman Foundation awarded 18 universities and colleges $3-5 million dollars each to develop radiant model entrepreneurship education programs and campus-wide entrepreneurial ecosystems. Grant recipients were required to have a senior level administrator to oversee the program who reported to the Provost, President, or Chancellor. Award recipients included Syracuse University (2007) and the University of Rochester (2004). Cornell was not a Kauffman campus. This chapter explores three case studies in the radiant model of university-wide entrepreneurship education as deployed at Cornell University, The University of Rochester, and Syracuse University. The authors examine the history, accelerators, and challenges of the radiant model of university-wide entrepreneurship education.; Academic entrepreneurship and community engagement -- This poigt study presents a collection of research on entrepreneurship and community engagement. The context of this book is Syracuse University's award winning model of Scholarship in Action with its emphasis on sustainable campus-community entrepreneurial partnerships and its resultant 'Syracuse Miracle', the transformation that has occurred in the Central New York community thanks to the university's partnership with the community to drive social, environmental, and economic development.; Creating a dynamic campus-community entrepreneurial ecosystem -- This chapter examines the key characteristics of success of the university-wide entrepreneurial ecosystem at Syracuse University. From 2007 to 2012, Syracuse University developed an academic signature in entrepreneurship, innovation, and community engagement resulting from 165 programs that linked the campus and the community. Nine critical factors of success for individual programs were observed. This chapter provides recommendations for establishing an experientially focused university-wide entrepreneurship education program and suggestions on mistakes to avoid.; Lib-value -- This study measures the return on investment (ROI) of the Syracuse University library. Faculty and students at Syracuse University were surveyed using contingent valuation methodology to measure their willingness to pay in time and money for the services of the academic library. Their travel time and use of the online library was measured to determine the environmental value of the academic library. The economic and environmental value of the Syracuse University library show an ROI of $4.49 returned to the university for every $1.00 spent each year.; The five keys to success in academic entrepreneurship -- ; The Global Sandbox: The International Entrepreneurship Classroom -- ; Religion, Entrepreneurship, Income and Employment -- ; WISE Economics: ROI of Quality and Consortiums -- ; iSchool Innovation: The Impact of Professor Ruth Small -- ; The Kauffman Campuses Initiative Impact in Central New York -- ; Web-based information science education -- Web-based Information Science Education (WISE) is a collaborative distance education model that increases the quality, access and diversity of online education opportunities. The WISE Consortium is a group of graduate Library and Information Science (LIS) programs founded on three pillars: quality, pedagogy, and collaborations (Montague & Pluzhenskaia, 2007). This chapter outlines the approach to achieving these three pillars and the assessment mechanisms used to measure the consortium's success. Highlights include WISE Pedagogy, the administrative division of WISE dedicated to providing faculty development resources for online education, and WISE+, an initiative that supports partnerships enabling WISE schools and LIS associations to develop courses together suitable for graduate credit and continuing education. While the WISE consortium is specific to LIS education, the model could be applied more broadly to other disciplines."
Bryan C Semaan,"“I am uncomfortable sharing what I can't see” -- The emergence of camera-based assistive technologies has empowered people with visual impairments (VIP) to obtain independence in their daily lives. Popular services feature volunteers who answer questions about photos or videos (e.g., to identify a medical prescription). However, people with VIPs can (inadvertently) reveal sensitive information to these volunteers. To better understand the privacy concerns regarding the disclosure of background objects to different types of human assistants (friends, family, and others), we conducted an online survey with 155 visually impaired participants. In general, our participants had varying concerns depending on the type of assistants and the kind of information. We found that our participants were more concerned about the privacy of bystanders than their own when capturing people in images. We also found that participants were concerned about self-presentation and were more comfortable sharing embarrassing information with family than with their friends. Our findings suggest directions for future work in the development of human-assisted question-answering systems. Specifically, we discuss how humanizing these systems can give people a greater sense of personal security.; Translation in personal crises -- This paper reports on a qualitative study exploring personal crises that emerge during transitions. Personal crises, like crises caused by natural disasters, often lead to new behaviors and opportunities for technology appropriation and design. Through interviews with 14 military veterans re-integrating into civilian society, we find that the veterans' transitions involve several impediments related to translation work-the process through which people make sense of the conflicting rules and norms between former and present social realities. We developed guidelines for the design of new wearable devices that can aid veterans in the translation process by proposing a six-fold schema of design criteria for wearables-detection, nudging, portability/proximity, inconspicuousness, connectivity, and reflection-to empower veterans in managing personal crises, fostering resilience, and creating normalcy. Finally, we develop the concept of identity creep to explicate these translation-breakdowns.; Manifesting the cyborg via techno-body modification -- A community of DIY cyborgs has emerged, known as ""grinders"", who practice techno-body modification - the embedding of computing technology into the body. This paper reports on an ethnographic study following GrinderTech, an organization working to design, build and sell these technological artifacts, as it shifts from hacker collective to biotech startup. As technologies are embedded in the body, the boundary between human and machine starts to blur. We find that GrinderTech members, through the design and making of technologies for embedding, do so as a means to move beyond social and gendered binary constructions - or, societal norms that are practiced and performed, and re-enforced through language, as a way of creating power differentials in society, e.g. citizen/scientist and man/woman Moreover, their motivations for designing and making these devices reflects their desire to re-imagine society. Finally, we re-conceptualize Human-Computer Interaction to include Integration - when technology is embedded in the human body - and discuss the theoretical and design implications of human-computer integration.; ""Mothers as Candy Wrappers"" -- The transition into motherhood is a complicated and often unsupported major life disruption. To alleviate mental health issues and to support identity re-negotiation, mothers are increasingly turning to online mothers' groups, particularly private and secret Facebook groups; these can provide a complex system of social, emotional, and practical support for new mothers. In this paper we present findings from an exploratory interview study of how new mothers create, find, use, and participate in ICTs, specifically online mothers' groups, to combat the lack of formal support systems by developing substitute networks. Utilizing a framework of critical infrastructures, we found that these online substitute networks were created by women, for women, in an effort to fill much needed social, political, and medical gaps that fail to see 'woman and mother' as a whole being, rather than simply as a 'discarded candy wrapper'. Our study contributes to the growing literature on ICT use by mothers for supporting and negotiating new identities, by illustrating how these infrastructures can be re-designed and appropriated in use, for critical utilization.; Quoras -- Quora is a fast growing crowdsourced Q/A site that also creates online social networks and community practices among the users. Operating in several regional languages, it catalyzes more contextual discussions on local incidents and issues. To understand how language-specific social communities conduct Q/A-based discussions on online forums, we need to study Quora platform. As the first step to that, we need a data collection API. We introduce quoras, a Python API for collecting data from Quora. The API relies on Selenium, which is an open-source cross platform web automation framework. The API operates by creating custom HTTPS requests to Quora and parsing responses from it. It has the ability to perform many types of advanced searches that are otherwise only available on the Quora website, and not through any other existing APIs. The quoras API is released under an open-source MIT license and available along with the full API reference on GitHub. The latest stable release is also available on Python Package Index (PyPI).; Blogging as recovery -- Military sexual trauma (MST) is a significant concern in the United States military and poses distinct challenges to survivors in seeking traditional means of support. While research has shown blogs to be an effective means of working through crises and seeking support, little work has focused on MST survivors and their use of blogs. In this study, we drew on Herman's stages of recovery in an analysis of 659 posts from five blogs written by MST survivors to understand their blogging behavior. We found that bloggers frequently use their blogs to perform what may be thought of as traditional recovery work. In particular, MST survivors blogged as a means of reconstructing their personal narratives and identities, as well as reaching out and reconnecting with others. In contrast, recovery work focused on establishing safety was underrepresented. Overall, findings suggest blogs to be a useful tool in recovering from sexual trauma and warrant further examination of other online spaces for recovery.; Exploring AAPI identity online -- Asian Americans and Pacific Islanders (AAPIs) are often perceived as a monolithic group, despite their distinct composition of ethnic cultures, political ideologies, and socioeconomic backgrounds. AAPIs increasingly engage in online forums to disclose their experiences and opinions, and in doing so, take part in lengthy discussions that shape the views of their community. We retrieved over 72,000 Reddit comments posted between January to July 2016 for a mixed-methods study of AAPI identity work, analyzing discursive patterns of user-deleted and banned comments. We found that while conservative AAPIs tend to comment anonymously more frequently, progressive AAPIs are less likely to ban comments that did not fit the behavior and norms of their community. AAPI redditors engage differently between conservative and progressive online communities through a process of what we conceptualize as identity work as deliberation.; Identity work as deliberation -- Asian Americans and Pacific Islanders (AAPIs) are perceived as the ""model minority"" with a monolithic identity, in contrast to other marginalized racial groups in the United States. In reality, they are composed of different ethnicities, socio-economic backgrounds, and political ideologies. AAPIs share their political views online, engaging in the public sphere through a collaborative process we coin, ""identity work as deliberation."" Using the 2016 US Presidential Election as a case study, we retrieved 4,406 Reddit comments posted between October 2016 to December 2016. We examine how users engage in an online community through a deliberation lens to understand the extent to which Reddit supports identity work as a deliberative process. Under the collective AAPI umbrella, we find that ethnic identifications complicate the types of discussion possible within r/asianamerica. We discuss how the expression of identity, and thereby solidarity, in a politicized online setting may lead to a social movement.; Challenges in transitioning from civil to military culture -- A critical element for a successful transition is the ability to disclose, or make known, one's struggles. We explore the transition disclosure practices of Reserve Officers' Training Corps (ROTC) students who are transitioning from an individualistic culture to one that is highly collective. As ROTC students routinely evaluate their peers through a ranking system, the act of disclosure may impact a student's ability to secure limited opportunities within the military upon graduation. Through a qualitative interview study of active ROTC students (N=14) examining how they use information communication technologies (ICTs) to disclose their struggles in a hyper-competitive environment, we find they engage in a process of highly selective disclosure, choosing different groups with which to disclose based on the types of issues they face. We share implications for designing ICTs that better facilitate how ROTC students cope with personal challenges during their formative transition into the military.; Moderation practices as emotional labor in sustaining online communities -- We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms.; Decolonizing Tactics as Collective Resilience -- Asian American and Pacific Islander (AAPI) communities use online platforms like Reddit to build capacity for resilience from white hegemony. We conduct interviews with 21 moderators of AAPI subreddits to understand how sociotechnical systems contour and contribute to the marginalization of online communities. We examine marginalization through the analytic framework of decolonization and uncover the threats and tactics that AAPI redditors encounter and employ to decolonize their collective identity. We find that moderators of AAPI subreddits develop collective resilience within their online communities by reclaiming space to confront brigade invasion, recording collective memory to circumvent systemic erasure, and revising cultural narratives to deconstruct colonial mentality. We describe how algorithmic configurations within sociotechnical systems reaffirm existing hegemonic values and discuss how users and designers of sociotechnical systems may work toward resisting white hegemony.; “Coming out okay” -- Online communities provide support for those who are vulnerable, such as LGBTQ people while coming out. Research shows that social support and personal narrative construction are important when recovering from personal crises and traumatic events. As an online community focused on writing fanfiction and also consisting of a large number of LGBTQ members, transformative fandom provides an opportunity to examine the relationship between support, crisis, and narrative. Through an interview study with 31 LGBTQ fanfiction authors, our findings mirror Herman’s model of trauma recovery: these spaces self-organize to support recovery work through constructing ""community narratives"" that help LGBTQ people establish safety when exploring their identity and build LGBTQ support structures without publicly outing themselves before they are ready, challenge stereotypes, and support others through reshaping existing media that perpetuate inaccurate or harmful LGBTQ narratives. These online communities embody ""selective visibility""–that is, though not specifically designed as support structures for identity work and recovery, their design allows people to selectively find and create communities of support for stigmatized issues that they might be unable to safely seek out in other spaces. Based on lessons learned, we generate insights that can inform the design of safe support spaces online.; Crisis warning signs in mHealth for military veterans -- Crises range from global catastrophes to personal disasters. However, systematic inquiry on crises rarely employs a comparative approach to examine commonalities between these seemingly very different events. We argue here that individual psychosocial disasters can inform a broader discussion on crises. Our approach applies general crisis theory to a smartphone based psychosocial support system for US military veterans. We engaged in a process designed to explore how veteran peer-to-peer mentorship can be augmented with IS support to display potential early warning signs as first step toward preventative intervention for high risk behaviors. To gain a better understanding of how military veterans might benefit from such a system, this article focuses on a community collaborative design process. The co-design process used the Small Stories method, allowing important cultural characteristics of to emerge, illuminating considerations in IS design with military veterans, and highlighting how humans think about crisis events at the individual level.; Detecting & visualizing crisis events in human systems -- Designing mHealth applications for mental health interventions has largely focused on education and patient self-management. Next generation applications must take on more complex tasks, including sensor-based detection of crisis events, search for individualized early warning signs, and support for crisis intervention. This project examines approaches to integrating multiple worn sensors to detect mental health crisis events in US military veterans. Our work has highlighted several practical and theoretical problems with applying technology to evaluation crises in human system, which are often subtle and difficult to detect, as compared to technological or natural crisis events. Humans often do not recognize when they are in crisis and under-report crises to prevent reputational damage. The current project explores preliminary use of the E4 Empatica wristband to characterize acute aggression using a combination of veteran self-report data on anger, professional actors simulating aggressive events, and preliminary efforts to discriminate between crisis data and early warning sign data.; Life transitions and social technologies -- When people experience major changes in their lives (e.g., relationship changes, transition from high school to college, realizing an LGBTQ identity, etc.), they often turn to social technologies to help navigate shifting identities and networks and find support and resources. People's experiences using social technologies during times of life transition, and how to better design such technologies, has been a major focus of social computing research. This workshop will gather researchers working in this space to discuss eight themes: life events vs. processes; changing identities; multiple overlapping life events; physical and digital transitions; technology non-use during life transitions; liminality framework; theoretical frames; and methodological considerations. Collaboratively, we will 1) synergize insights from workshop organizers' and participants' research to determine how social technologies can be designed to better support people during life transitions and 2) outline an agenda for the future of social computing work on life transitions.; Insertable digital devices -- This document presents the one day insertable and implantable digital device workshop to be held at DIS 2016 on June 5th 2016. Insertables are a category of devices that go in, through or under the skin, such as implantable medical devices (IMDs) and emerging technologies such as magnets, RFID chips and NFC chips that are inserted under the skin. This workshop will provide an opportunity to gather attendees with an interest in insertables to move this emerging field forward. The workshop goal is to build a community and generate ideas regarding the use of insertables in HCI and propose future research directions.; Policy impacts on the HCI research community -- Recent policy developments in both the United States and elsewhere have sparked significant concern within the HCI research community. Predomitly, increasing isolationism can have a serious impact on collaboration, community engagement and wellness, and knowledge sharing. Policy shifts also have the potential to affect freedom of scientific inquiry, the free flow of information, and funding for computing research. Moreover, what can SIGCHI as an organization do to best support the community under current conditions? In this panel discussion, designed to be heavily participatory, we will take on these issues and discuss what we can do to support our strong, diverse community of researchers.; A confucian look at internet censorship in China -- China’s Internet censorship practices are sophisticated and pervasive. Academic research and media reports have examined the Chinese government’s varied, expansive methods of censorship and Chinese citizens’ techniques of subverting them, but little attention has been paid to understanding how Chinese citizens think about censorship in their everyday lives. We conducted a qualitative study of Chinese mainland citizens who circumvented censorship. We found seemingly contradictory attitudes and practices among our participants. They showed proficiency at bypassing censorship, but were sometimes comfortable with censored information. They were willing to share sensitive information with others, but saw the benefits of limiting the public’s access to information under certain circumstances. We examine how the complex, nuanced attitudes toward censorship resonate with the classic teachings of Confucianism, China’s traditional philosophical and ethical system.; Mediating the undercurrents -- While studies of social movements have mostly examined prevalent public discourses, undercurrents-the backstage practices consisting of meaning-making processes, narratives, and situated work-have received less attention. Through a qualitative interview study with sixteen participants, we examine the role of social media in supporting the undercurrents of the Umbrella Movement in Hong Kong. Interviews focused on an intense period of the movement exemplified by sit-in activities inspired by Occupy Wall Street in the United States. Whereas the use of Facebook for public discourse was similar to what has been reported in other studies, we found that an ecology of social media tools such as Facebook, WhatsApp, Telegram, and Google Docs mediated undercurrents that served to ground the public discourse of the movement. We discuss how the undercurrents sustained and developed public discourses in concrete ways.; Hybrid media consumption -- An increasing number of people are using microblogs to broadcast their thoughts in real time as they watch televised political events. Microblogging social network sites (SNSs) such as Twitter generate a parallel stream of information and opinion. It is presumed that the additional content enhances the viewing experience, but our experiment explores the validity of this assumption. We studied how tweeting, or passively observing Twitter during a debate, influenced affect, recall and vote decision. For most measures, participants' average feeling and recall toward the candidates did not depend on Twitter activity, but Twitter activity did matter for vote choice. People who actively tweeted changed their voting choice to reflect the majority sentiment on Twitter. Results are discussed in terms of the possibility that active tweeting leads to greater engagement but that it may also make people more susceptible to social influence.; ""Social watching"" a civic broadcast -- People increasingly turn to social media to augment their broadcast viewing experience with a parallel stream of information and opinion. Known as ""social watching,"" the practice of integrating broadcast media and social media has become routine for many citizens tracking live events and breaking news. In a controlled laboratory study, we examined how interactivity and exposure to social media opinions influence a sense of community, attitudes and discussion elaboration. The results suggest that receiving positive feedback to social media posts instills a psychological sense of community in the poster, and this feeling of connectedness is related to greater elaboration of the civic social media discussion. Secondly, the study found support for conformity effects. The third contribution of this work is a better understanding of how the valence of others' social media posts and the user's posting activity influences cognitive elaboration of social media discussions during social watching in civic contexts.; Theory-driven collocated CMC -- Computer-mediated communication (CMC) tools are used to increase social interaction in collocated settings. Recent research has been primarily constructive (oriented to building of systems) or phenomenon-driven (serving attempts to understand interactions in collocated CMC). The paper contributes a theory-driven approach and examines collocated CMC as a Habermasean ""public sphere"": a space that supports inclusive, civil, and rational discussion. An in-the-wild experimental study comparing CMC with face-to-face (F2F) communication enabled ascertaining that CMC is more inclusive than F2F communication. Respectfulness levels did not differ but were established differently: via collective construction of a common narrative in F2F and through quick reactions in CMC. Similarly, while rationality figures were on a par, F2F communication allowed participants to justify their claims better. The article discusses how a theory-based approach can strengthen phenomenon-driven research with new conceptual frames and measurement tools, and steer constructive research with a normative framework.; Social media is polarized, social media is polarized -- Social media platforms have often been described as online spaces supporting political discourse. However, online discussions are often polarized; people tend to commune with those who are ideologically similar to them. The HCI response to this phenomenon has been to purposefully expose people to diverse viewpoints. This common design agenda is supported through analysis of link sharing, yet little attention has been paid to how users discuss these links. Therefore, the common design agenda may not mitigate polarization. We study the emergent discourse in 10 Finnish migration-related Face-book groups and examine how the same links are shared and discussed across anti- and pro-migration camps. Qualitative analysis of the posts and comments revealed that shared media links do not bridge polarized groups with regard to worldviews and opinions. We then demonstrate alternative design opportunities to resolve this issue and begin to develop a new design agenda to mitigate polarization.; (Re)design to mitigate political polarization -- Social Media platforms are increasingly being used for political activities and communication, and research suggests that social media design and use is contributing to the polarization of the public sphere. This study draws on Habermas’ ideals concerning deliberative democracy to explore if novel interface designs that diversify information sources through content recommendation, can decrease polarization. Through a design-probe interview approach and insights generated from 19 political and citizen experts in Finland and the United States, we found that our deliberative design can lead to depolarization, while creating additional complexity through which users question content and information. We discuss the need to move beyond naive content recommendation, and user interface level changes, in order to work towards a depolarized public sphere.; Social media mixed with news in political candidate judgment -- In the context of politics, emotions and facts work together to shape opinions about political candidates. While there is considerable research on motivated reasoning about political issues, there is less attention to how affect and rationality combine in the hybrid world of new media. This study examined the interaction of social media comments about politicians with more traditional information sources. Participants were exposed to political candidates' Facebook news feeds, to news articles about the candidates, and to a political speech. The order of exposure was varied and measures of both knowledge and emotion were taken. When social media was encountered before news about a political candidate, it influenced feelings toward the candidate but did not influence personal mood or perceived knowledge. In contrast, when social media was encountered before information unrelated to the candidates, it negatively influenced all dependent measures. The findings are discussed in terms of motivated reasoning theories, Papacharissi's concept of ""affective publics,"" and the implications for civic participation in the new media era.; Social media supporting political deliberation across multiple public spheres -- This paper reports on a qualitative study of social media use for political deliberation by 21 U.S. citizens. In observing people's interactions in the ""sprawling public sphere"" across multiple social media tools in both political and nonpolitical spaces, we found that social media supported the interactional dimensions of deliberative democracy - the interaction with media and the interaction between people. People used multiple tools through which they: were serendipitously exposed to diverse political information, constructed diverse information feeds, disseminated diverse information, and engaged in respectful and reasoned political discussions with diverse audiences. When people's civic agency was inhibited when using a tool, they often adopted, or switched to, alternative media that could afford what they were trying to achieve. Contrary to the polarization perspective, we find that people were purposefully seeking diverse information and discussants. Some individuals altered their views as a result of the interactions they were having in the online public sphere.; Designing political deliberation environments to support interactions in the public sphere -- Little is known about the challenges and successes people face when piecing together multiple social media to interact in the online public sphere when: Seeking information, disseminating information, and engaging in political discussions. We interviewed 29 US citizens and conducted 17 talk-out-loud sessions with people who were using one or more social media technologies, such as Facebook and Twitter, to interact in the online public sphere. We identified a number of challenges and workarounds related to public sphere interactions, and used our findings to formulate requirements for new political environments that support the interactions in the public sphere. Through evolving requirements generation, we developed a new political deliberation technology, dubbed Poli, which is an integrated social media environment with the potential to enable more effective interactions in the public sphere. We discuss several remaining questions and limitations to our tool that will drive future work.; Maintaining and creating social infrastructures -- Societies rely on the social infrastructure for proper societal function. When crises emerge, the importance of the social infrastructure magnifies as people often rely on others, both known and unknown, for support. For citizens experiencing a war environment, however, societal trust can be affected and we show how technologies are used to maintain and create social infrastructures for resilience. Through interviews with 45 Iraqi civilians who had lived through the 2nd Gulf War, we found that people were able to evoke the social infrastructure through technological resources to maintain practices for work, to obtain goods and services, and to receive contextual support. We then theorize properties of social infrastructure that could be developed into affordances for new technologies to promote resilience during crises.; Navigating imagined audiences -- Little is known about why and how people use multiple social media platforms for political participation, or about the contexts through which social media is appropriated. This paper reports on a qualitative interview study of social media use by politically interested citizens. We interviewed 27 residents of the state of Hawaii who integrated one or more social media tools into their daily lives to participate in the online public sphere. Different social media environments offer both different affordances for action and different audiences, and we describe how media choice is driven by the match between motivations and affordances, and also by the imagined audience. We identified a number of motivations including understanding different viewpoints, formulating perspectives, engaging in positive discourse, repairing Hawaii's image, increasing political awareness and improving civic engagement. We discuss how these goals relate to both intrinsic and extrinsic motivations. Finally, we examine how social media choice and satisfaction were tied to the physical world context and people's sense of the audience within any particular medium.; Transition resilience with ICTs -- This paper reports on a qualitative interview study of ICT use amongst a population undergoing transition following a life disruption. We interviewed 13 veterans who were reintegrating into civil society. Veterans are unique in that they experience several transitions at once-that is, after returning home, they often suffer from PTSD, become homeless, change occupations, etc. Amongst other challenges, veterans often undergo identity crises as caused by the lack of continuity between military and civilian social structures. We show how veterans are resilient through their uses of ICTs when navigating identity crises. We find that they use ICTs to develop identity awareness- that is, they connect with a human infrastructure through which they can develop a ""big picture"" understanding of unfamiliar rules and norms and receive support when navigating civil society. We discuss the implications of our study and identify implications for design.; Military masculinity and the travails of transitioning -- Research suggests that the disclosure of struggles and the connection with sympathetic others are critical during periods of transition. Whereas disclosure has been studied in various contexts, the disclosure strategies of United States (US) veterans transitioning back into civil society has not been explored. Through a qualitative study with 15 veterans re-integrating into civil society, we find that the culture of hyper-masculinity learned and performed during military service leads to challenges to disclosure, or nondisclosure, post-service, negatively impacting how military veterans navigate the transition back into civil society. We explore the disclosure issues and strategies of veterans in both offline and online contexts, finding that veterans used online platforms to navigate the challenges limiting disclosure and connect with supportive resources. We conclude by introducing the concept of delayed disclosure-when people postpone making their struggles known in transition- and provide implications for policy, design and future work to help veterans manage their transitions.; Impression management in high context societies -- High context societies are defined by their strong interpersonal relationships, where upholding the shared values of the community, writ large, are of the utmost importance. That is, they prioritize collective identity over individual identity. Through a qualitative case study drawing from a set of 90 semi-structured interviews with Iraqi citizens who were living in Iraq during the 2nd Gulf War, we show how through ICT uses and appropriation, people shape, or influence, social complexities within high context societies. We found that people appropriated ICTs in a way such that they could ""save face"" and manage other people's impressions of themselves and, in turn, maintain a positive collective identity. We then explore the use and appropriation of ICTs for impression management in high context societies as a complex process-one that is both social and technical-introduce the notion of technological imperialism, and develop a model of face saving practices that takes collective identity into account.; ‘Routine infrastructuring’ as ‘building everyday resilience with technology’ when disruption becomes ordinary -- Getting a divorce. Being diagnosed with a disease. Going through a relationship breakup. Living through a natural disaster. All of these events are often life disrupting and debilitating. While some disruptive events are short-lived, some can be a routine part of everyday life. This leads to the question of how people who experience prolonged disruption in their lives build resilience—that is, how do they manage and overcome such events? To explore this question, this paper utilizes a case study approach to explore the use, creation, and re-appropriation of technology across three prolonged disruptions-the Second Gulf War in Iraq, veteran transitions, and the coming out experiences of LGBTQ-identifying people. Using a conceptual frame that brings together routine dynamics and infrastructuring, we find that engaging in routine infrastructuring practices generated resilience in people’s daily lives—a phenomenon we dub ‘routine infrastructuring’ as ‘building everyday resilience with technology.’ We then theorize properties of infrastructure and infrastructuring practice that enable resiliency, and conclude with how infrastructuring is a form of care work that is oriented towards individuals, communities, and society.; Restructuring human infrastructure -- Non-profit organizations (NPOs) are often resourcerestricted and rely on volunteers to function. As such, their human infrastructure-The social system supporting work-is different from conventional organizations, and technologies that function in a traditional organization with a stable workforce may not work in NPOs. Through an investigation of the deployment of an Electronic Health Record (EHR) system in a safety-net free clinic serving underprivileged populations, we report how the EHR system disrupted the human infrastructure-namely, the work typically enacted by volunteers. Specifically, there was a mismatch between the technological and human infrastructures leading to diminished volunteer roles, an increased workload for paid employees, and a negative impact on the quality of patient care. In turn, employees acted to reconcile the disrupted human infrastructure by creating new work roles for volunteers, re-establishing the quality of patient care, and developing workarounds for volunteers to resume their volunteer work. Finally we discuss how the commercial EHR system failed to support the fluid volunteer-based human infrastructure of the free clinic."
Carlos Enrique Caicedo Bastidas,"An initial approach towards quality of service based Spectrum Trading -- Spectrum scarcity has become an important issue as demands for higher data rates increase in diverse wireless applications and aerospace communication scenarios. To address this problem, it becomes necessary to manage radio spectrum assignment in a way that optimizes the distribution of spectrum resources among several users while taking into account the quality of service (QoS) characteristics desired by the users of spectrum. In this paper, a novel approach to managing spectrum assignment based on Spectrum Trading (ST) will be presented. Market based spectrum assignment mechanisms such as spectrum trading are of growing interest to many spectrum management agencies that are planning to increase the use of these mechanisms for spectrum management and reduce their emphasis on command and control methods. This paper presents some of our initial work into incorporating quality of service information into the mechanisms that determine how spectrum should be traded when using a spectrum exchange. Through simulations and a testbed implementation of a QoS aware spectrum exchange our results show the viability of using QoS based mechanisms in spectrum trading and in the enhancement of dynamic spectrum assignment systems.; Enabling remote access to computer networking laboratories for distance education -- Academic organizations that provide students with the facilities for experimenting and learning basic and advanced concepts in networking rely on computer networking laboratories. These facilities can be implemented in many ways with varying degrees of cost, management complexity and capabilities. The benefits of these facilities can be extended by enabling remote access to them for distance education purposes. Providing remote access capabilities to these facilities with the objective of offering the learning experience of a computer networking laboratory to distance education students of Information and Communication Technology (ICT) programs is a challenging task. This paper provides a description and a comparative analysis of the implementation of three different computer network laboratory setups for which remote access was enabled and discusses lessons learned and good practices for similar setups.; Dynamic Radio Frequency Mapping -- An intelligent cognitive radio system is disclosed that acquires information about its environment to make operational decisions. Dynamic radio frequency mapping provides estimates of RF power levels over an area where spectrum activity or changes in the environment may be transient. These power levels can be used for a variety of applications such as interference management, spectrum policing, and facilitating spectrum auctions. The RF mapping can be accomplished by a network of sensors that are distributed in a geographical area and used to spatially sample signal levels. The present invention can quantify the effect of aliasing on the estimation of an RF map as a function of the sampling density and the number of antennas used at the sensing node.; IEEE 1900.5.2 -- Dynamic spectrum access (DSA) is a critical technology that allows diverse systems to rapidly adjust spectrum assignments and share spectrum with each other. This greatly improves overall spectrum efficiency at a time when demands for spectrum are rapidly increasing. Wireless services that use DSA or spectrum sharing mechanisms require a well-defined means to communicate how each device or system is using spectrum resources in a particular situation or at a specific location. Spectrum consumption models (SCMs) address this requirement by providing a means to capture the spectral, spatial, and temporal characteristics of spectrum usage for any specific wireless transmitter, receiver, system, or collection of systems. The 1900.5 Working Group of the IEEE Dynamic Spectrum Access Networks Standardization Committee (DySPAN-SC) has written the IEEE 1900.5.2 standard, which defines a data model for SCMs and procedures to arbitrate compatibility among combinations of RF devices and/or spectrum-dependent systems that have expressed the boundaries of their spectrum use with SCMs. This article provides an overview of the IEEE 1900.5.2 standard using example use cases to illustrate how SCMs can enable a wide variety of efficient spectrum use interactions. Additionally, the article provides a brief description of an open source software tool to facilitate and promote the use of SCMs.; IPv6 Security Analysis (Technical Report T.R. 2014-002) -- ; Security Vulnerability Analysis and Strategies for Trusted Virtualized Computing Environments -- ; The viability of spectrum trading markets -- Spectrum trading markets are of growing interest to many spectrum management agencies. They are motivated by their desire to increase the use of market-based mechanisms for spectrum management and reduce their emphasis on command and control methods. Despite the liberalization of regulations on spectrum trading in some countries, spectrum markets have not yet emerged as a key spectrum assignment component. The lack of liquidity in these markets is sometimes cited as a primary factor in this outcome. This work focuses on determining the conditions for viability of spectrum trading markets. We make use of agentbased computational economics to analyze different market scenario and the behaviors of its participants. Our results provide guidelines regarding the number of market participants and the amount of tradable spectrum that should be present in a spectrum trading market for it to be viable. We use the results of this analysis to make recommendations for the design of these markets.; Spectrum consumption model builder and analysis tool -- Regulatory changes to spectrum management frameworks in the U.S. and worldwide are promoting the use of dynamic spectrum access (DSA) and spectrum sharing mechanisms. Wireless service environments that use these mechanisms will rely heavily on radio interference control and management techniques to coordinate the boundaries of spectrum use for devices owned/managed by different entities. To communicate the characteristics and limits of spectrum use of an RF transmitter, receiver, system or collection of systems, a common data structure to represent this information must be in place. Spectrum consumption models (SCMs) attempt to capture this information and support a set of computations that allow for the determination of the compatibility of the use of spectrum between devices and/or systems that communicate the characteristics of their use of spectrum with these models. SCMs are currently being standardized within the IEEE DySPAN-SC 1900.5.2 workgroup. This paper presents our results and ongoing efforts in developing an open source tool for the construction and analysis of SCMs as a means to promote their use and showcase their potential for enhancing spectrum sharing and DSA interactions.; A standard method for modeling spectrum consumption -- Wireless services that rely on Dynamic Spectrum Access (DSA) or spectrum sharing mechanisms require a well-defined means to communicate how each device or system is using spectrum resources in a particular environment or situation so that the devices that receive such information can make rational decisions on the possible use of the spectrum. Spectrum consumption models (SCMs) address this issue by providing a means to capture the spectral, spatial, and temporal characteristics of spectrum usage for any specific transmitter, receiver, system, or collection of systems. Since 2012 the 1900.5 working group of the IEEE Dynamic Spectrum Access Networks Standardization Committee (DySPAN-SC) has been working on the IEEE 1900.5.2 standard which defines a data model for SCMs and procedures to arbitrate compatibility among combinations of RF devices and/or systems that have expressed the boundaries of their spectrum use with SCMs. This poster provides an overview of SCMs with a focus on example use cases related to current spectrum management scenarios (i.e. SAS, AWS-3, etc.) to illustrate how SCMs can enable innovative and efficient spectrum use interactions in the near future.; IEEE 1900.5.2 Standard Method for Modelng Spectrum Consumption — Introduction and Use Cases -- ; Spectrum Trading: Market Based Architectures for Dynamic Radio Frequency Spectrum Access -- ; A Standard Method for Modelling Spectrum Consumption -- ; Standards for Policy-based Dynamic Spectrum Management -- ; Big data and the changing role of the IT professional -- ; SCMBAT - The Spectrum Consumption Model Builder and Analysis Tool. Release v1.0, 2016. Current version: 1.2 -- ; Developing a New Scale to Measure E-Health Literacy -- ; A Survey of Social Media Sites for Academics -- ; Simulation of Real-time Routing for UAS traffic Management with Communication and Airspace Safety Considerations -- Small Unmanned Aircraft Systems (sUAS) will be an important component of the smart city and intelligent transportation environments of the near future. The demand for sUAS related applications, such as commercial delivery and land surveying, is expected to grow rapidly in next few years. In general, sUAS traffic routing and management functions are needed to coordinate the launching of sUAS from different launch sites and determine their trajectories to avoid conflict while considering several other constraints such as expected arrival time, minimum flight energy, and availability of communication resources. However, as the airborne sUAS density grows in a certain area, it is difficult to foresee the potential airspace and communications resource conflicts and make immediate decisions to avoid them. To address this challenge, we present a temporal and spatial routing algorithm and simulation platform for sUAS trajectory management in a high density urban area that plans sUAS movements in a spatial and temporal maze taking into account obstacles that are either static or dynamic in time. The routing allows the sUAS to avoid static no-fly areas (i.e. static obstacles) or other in-flight sUAS and areas that have congested communication resources (i.e. dynamic obstacles). The algorithm is evaluated using an agent-based simulation platform. The simulation results show that the proposed algorithm outperforms other route management algorithms in many areas, especially in processing speed and memory efficiency. Detailed comparisons are provided for the sUAS flight time, the overall throughput, conflict rate and communication resource utilization. The results demonstrate that our proposed algorithm can be used to address the airspace and communication resource utilization needs for a next generation smart city and smart transportation.; Accessing External Databases from Mobile Applications, version 2.0 (Technical Report) -- ; Accessing External Databases from Mobile Applications (Technical Report) -- ; Study of IPv6 Security Vulnerabilities v2.0 (Technical Report T.R. 2014-001) -- ; The IEEE1900.5.1 standard -- The 1900.5 Workgroup of the IEEE Dynamic Spectrum Access Networks Standards Committee (DySPAN-SC) has been working on the development of the IEEE 1900.5.1 standard which defines a Policy Language for Dynamic Spectrum Access Systems in conformance with the requirements stated in the IEEE 1900.5 standard. The policy language allows for the construction of machine interpretable policies for DSA systems that can express how such systems should adapt their operation under changes in radio environment conditions, among other objectives. The language combines concepts of ontologies, knowledge representation and first order logic. The standard is expected to be released in 2020.; Enabling spectrum sharing via spectrum consumption models -- Spectrum consumption models attempt to capture spectral, spatial, and temporal consumption of spectrum of any specific RF transmitter, receiver, system, or collection of systems. The information contained in the models enables better spectrum management practices and allows for the identification of spectrum reuse opportunities. The characteristics and structure of spectrum consumption models (SCMs) are being standardized within the IEEE DySPAN-SC P1900.5.2 group. This paper presents and discusses how SCMs can be used to enable spectrum sharing and new spectrum management interactions. We describe the ongoing efforts to standardize SCMs to ensure that they can: 1) effectively capture the boundaries of spectrum use in all of its dimensions by devices and systems of devices and 2) provide a stable definition on how to arbitrate the compatibility of SCMs. By achieving these objectives, SCMs will enable innovation in spectrum sharing and in the development of dynamic spectrum access systems.; Service level agreements with spectrum consumption models -- The forecasted growth of wireless services and applications is driving and being driven by regulatory, technological and economic changes that will create new technical and business models in wireless service provision and spectrum management practices. The efficient use of spectrum via Dynamic Spectrum Access (DSA) methods will be key in achieving efficient use of spectrum resources in the future. However, the use of DSA methods and the enablement of efficient spectrum sharing interactions between users of spectrum requires that they can define service level agreements (SLAs) that allow the parties in the agreement to document a common understanding of the aspects of spectrum use and the roles and responsibilities of both parties in maintaining compatible spectrum use, along with enforcement mechanisms. This paper focuses on how the use of spectrum consumption models (SCM) supports the negotiation and definition of SLAs. Spectrum consumption modeling attempts to capture spectral, spatial, and temporal consumption of spectrum of any specific transmitter, receiver, system, or collection of systems. The information contained in the SCMs enable better spectrum management practices and allows for the identification of spectrum reuse opportunities. The recent addition of a probability element to the modeling approach supports the definition of softer boundaries and the negotiation of SLAs. It allows parties to agree that rare occurrences of interference are permissible. The creation of an SLA would have parties define the SCMs of their spectrum use and iteratively exchange them until the SCMs are assessed as compatible. The SLAs would be further complemented with data indicating conditions for compliance in addition to those implied by the SCMs and agreement to the methods to assess compliance and to obtain remediation.; Characterizing the mobile coverage probability in different geometries -- This work characterizes the radio frequency (RF) power distribution within a given area via its mean and variance in three particular geometries. Through our statistical approach we have developed computationally simple equations that can be used to compute the mean value and variance of the RF power received in a circular area and in some other geometries without numerical evaluations of integrals and which improve on the results/methods provided in the literature to date. We begin our study with the analysis of the received power on a linear trajectory and then we extend the result for a circular geometry. We have validated our results via Monte Carlo simulations. These results are useful both the study of the coverage of a RF transmitter and to identify spectrum holes.; A spatial interpolation method for radio frequency maps based on the discrete cosine transform -- Estimating radio frequency (RF) power in a geographic area is almost as old as wireless technology itself. It is crucial to anyone who is working or doing business with wireless technologies: wireless operators, the military, regulators, etc. Under a cognitive radio paradigm, spectrum usage is no longer static and is migrating towards dynamic and shared access paradigms. Enabling this evolution requires the estimation of the Radio Frequency map (RF map) of a given area. A variety of methods have already been proposed and tested to accomplish this estimation by leveraging decades of work on spatial interpolation methods. In this work, we justify, through analysis and simulation, using the Discrete Cosine Transform (DCT) as a more dynamic and accurate interpolation technique through comparison to other deterministic methods such as the Inverse Distance Weighting (IDW) method.; On the Sampling Requirements of Dynamic Frequency Mapping -- ; An Open Source Implementation of a Spectrum Exchange -- ; On the application of blockchains to spectrum management -- Spectrum sharing mechanisms have evolved to meet different needs related to increasing spectrum use efficiency. At first, decentralized and opportunistic cognitive radios (and cognitive radio networks) were the primary focus of research for these mechanisms. This gradually transitioned toward the development of cooperative sharing methods based on databases, typified by TV white spaces databases. Spectrum sharing is now the basis for the dynamic and fine-grained spectrum rights regime for the citizen's band radio service (CBRS) as well as for license shared access (LSA). The emergence of the cryptocurrency Bitcoin has stimulated interest in applying its underlying technology, blockchain, to other applications as well, such as securities trading and supply chain management. This paper explores the application of blockchain to radio spectrum management. While blockchains could underlie radio spectrum management more broadly, we will focus on dynamic spectrum sharing applications. Like the cooperative approaches currently in use, blockchain is a database technology. However, a blockchain is a decentralized database in which the owner of the data maintains control. We consider the benefits and limitations of blockchain solutions in general, and then examine their potential application to four major categories of spectrum sharing.; A simulation framework for fast design space exploration of unmanned air system traffic management policies -- The number of daily small Unmanned Aircraft Systems (sUAS) operations in uncontrolled low altitude airspace is expected to reach into the millions. UAS Traffic Management (UTM) is an emerging concept aiming at the safe and efficient management of such very dense traffic, but few studies are addressing the policies to accommodate such demand and the required ground infrastructure in suburban or urban environments. Searching for the optimal air traffic management policy is a combinatorial optimization problem with intractable complexity when the number of sUAS and the constraints increases. As the demands on the airspace increase and traffic patterns get complicated, it is difficult to forecast the potential low altitude airspace hotspots and the corresponding ground resource requirements. This work presents a Multi-agent Air Traffic and Resource Usage Simulation (MATRUS) framework that aims for fast evaluation of different air traffic management policies and the relationship between policy, environment and resulting traffic patterns. It can also be used as a tool to decide the resource distribution and launch site location in the planning of a next generation smart city. As a case study, detailed comparisons are provided for the sUAS flight time, conflict ratio, cellular communication resource usage, for a managed (centrally coordinated) and unmanaged (free flight) traffic scenario.; Temporal and spatial routing for large scale safe and connected UAS traffic management in urban areas -- Small Unmanned Aircraft Systems (sUAS) will be an important component of the smart city and intelligent transportation environments of the near future. The demand for sUAS related applications, such as commercial delivery and land surveying, is expected to grow rapidly in next few years. In general, sUAS traffic scheduling and management functions are needed to coordinate the launching of sUAS from different launch sites and plan their trajectories to avoid conflict while considering several other constraints such as expected arrival time, minimum flight energy, and availability of communication resources. However, as the airbone sUAS density grows in a certain area, it is difficult to foresee the potential airspace and communications resource conflicts and make immediate decisions to avoid them. To address this challenge, we present a temporal and spatial routing algorithm for sUAS trajectory management in a high density urban area. It plans sUAS movements in a spatial and temporal maze with the consideration of obstacles that are either static or dynamic in time. The routing allows the sUAS to avoid static no-fly areas (i.e. static obstacles) or other in-flight sUAS and areas that have congested communication resources (i.e. dynamic obstacles). The algorithm is evaluated using an agent-based simulation platform. The simulation results show that the proposed algorithm outperforms reference route management algorithms in many areas, especially in processing speed and memory efficiency. Detailed comparisons are provided for the sUAS flight time, the overall throughput, the conflict rate and communication resource utilization. The results demonstrate that our proposed algorithm can be used as a solution to improve the efficiency of airspace and communication resource utilization for next generation smart city and smart transportation.; Mission-Aware Spatio-Temporal Deep Learning Model for UAS Instantaneous Density Prediction -- The number of daily sUAS operations in uncontrolled low altitude airspace is expected to reach into the millions in a few years. Therefore, UAS density prediction has become an emerging and challenging problem. In this paper, a deep learning-based UAS instantaneous density prediction model is presented. The model takes two types of data as input: 1) the historical density generated from the historical data, and 2) the future sUAS mission information. The architecture of our model contains four components: Historical Density Formulation module, UAS Mission Translation module, Mission Feature Extraction module, and Density Map Projection module. The training and testing data are generated by a python based simulator which is inspired by the multi-agent air traffic resource usage simulator (MATRUS) framework. The quality of prediction is measured by the correlation score and the Area Under the Receiver Operating Characteristics (AUROC) between the predicted value and simulated value. The experimental results demonstrate outstanding performance of the deep learning-based UAS density predictor. Compared to the baseline models, for simplified traffic scenario where no-fly zones and safe distance among sUASs are not considered, our model improves the prediction accuracy by up to 15.2% and its correlation score reaches 0.947. In a more realistic scenario, where the no-fly zone avoidance and the safe distance among sUASs are maintained using A∗ routing algorithm, our model can still achieve 0.822 correlation score. Meanwhile, the AUROC can reach 0.951 for the hot spot prediction.; A Cost-Benefit Analysis to Achieve Command and Control (C2) Link Connectivity for beyond Visual Line of Sight (BVLOS) Operations -- Unmanned Aircraft Systems (UAS) operations are changing the way aviation and commerce are conducted today. Until recently, for civil aviation commercial operations, nearly all UAS operations are conducted within visual line of sight (VLOS). However, this severely limits the economic benefits that can be realized by the use of these unmanned, and someday, autonomous systems.Beyond visual line of sight (BVLOS) operations require much more capabilities for the operator to rely on and for the general public to condone and be comfortable with. BVLOS operations rely on ground and platform technologies all with varying states of maturity. In this paper, we focus on the interaction between the UAS operator / Remote Pilot in Command (RPIC) to maintain a continuous Command Control (C2) link with its unmanned aircraft. There must be a reliable, robust, infrastructure in place to enable operators to fly beyond visual range. In areas with sparse communications network coverage, various communication technologies such as LTE and satellite are expected to be utilized in combination to provide C2 connectivity. However, resources for communication links can be saturated, depending on the available spectrum and activity within each network (LTE, Satellite).UAS Traffic Management (UTM) may ultimately be a pay-for-use service. UTM providers will certainly rely on commercial mobile networks for data communications services and guaranteeing quality of service. Use of communication services can be costly so they must consider implementing a cost- benefit analysis to determine service profitability based on number of service missions, mission type, distribution of missions over an area, and cost of use of each communication resource so that adequate price points can be set for its customers' service missions.Using a combination of cost modeling and agent- based simulation, one can define many UTM operation scenarios with different parameters such as LTE service coverage area distributions that can be analyzed to determine when LTE communication channels are lost in order to switch to a secondary satellite link to re-establish a C2 connectivity. In this paper, we develop a cost model based on these parameters and a simulation methodology that is envisaged to help UAV fleet operators to manage and price their services while ensuring that BVLOS operations maintain C2 connectivity via a combination of communication technologies."
Caroline Haythornthwaite,"Linking online identities and content in connectivist MOOCs across multiple social media platforms. -- ; Motivation for open collaboration -- This article presents an examination of motivational factors relating to contribution to the wiki OpenStreetMap, a site for voluntary geographic information. Based on a wide literature review of motivation, open source, volunteerism, and serious leisure, a questionnaire was created and completed by 444 OpenStreetMap contributors. Results of judgments of the motivational importance of 39 reasons for contribution are presented and considered in relation to models of contributory behavior for crowd- and community-based online collaborations. Positive and important motivators were found that accorded with ideas of the 'personal but shared need' associated with contribution to open-source projects, co-orientation to open-source and geographic knowledge, and attention to participation in and by the community. Differences in motivation between serious and casual mappers showed that serious mappers were more oriented to community, learning, local knowledge, and career motivations (although the latter motivation is low in general), and casual mappers were more oriented to general principles of free availability of mapping data. (PsycINFO Database Record (c) 2016 APA, all rights reserved); Conducting Successful Research: From Problem Identification to Research and from Outcome to Translation In the Field of Information -- ; Social media in educational practice: Faculty present and future use of social media in teaching -- ; Enabling community through social media -- Background: Social network analysis provides a perspective and method for inquiring into the structures that comprise online groups and communities. Traces from interaction via social media provide the opportunity for understanding how a community is formed and maintained online. Objective: The paper aims to demonstrate how social network analysis provides a vocabulary and set of techniques for examining interaction patterns via social media. Using the case of the #hcsmca online discussion forum, this paper highlights what has been and can be gained by approaching online community from a social network perspective, as well as providing an inside look at the structure of the #hcsmca community. Methods: Social network analysis was used to examine structures in a 1-month sample of Twitter messages with the hashtag #hcsmca (3871 tweets, 486 unique posters), which is the tag associated with the social media-supported group Health Care Social Media Canada. Network connections were considered present if the individual was mentioned, replied to, or had a post retweeted. Results: Network analyses revealed patterns of interaction that characterized the community as comprising one component, with a set of core participants prominent in the network due to their connections with others. Analysis showed the social media health content providers were the most influential group based on in-degree centrality. However, there was no preferential attachment among people in the same professional group, indicating that the formation of connections among community members was not constrained by professional status. Conclusions: Network analysis and visualizations provide techniques and a vocabulary for understanding online interaction, as well as insights that can help in understanding what, and who, comprises and sustains a network, and whether community emerges from a network of online interactions.; Uses and Gratifications factors for social media use in teaching -- This research was motivated by an interest in understanding how social media are applied in teaching in higher education. Data were collected using an online questionnaire, completed by 333 instructors in higher education, that asked about general social media use and specific use in teaching. Education and learning theories suggest three potential reasons for instructors to use social media in their teaching: (1) exposing students to practices, (2) extending the range of the learning environment, and (3) promoting learning through social interaction and collaboration. Answers to open-ended questions about how social media were used in teaching, and results of a factor analysis of coded results, revealed six distinct factors that align with these reasons for use: (1) facilitating student engagement, (2) instructor’s organization for teaching, (3) engagement with outside resources, (4) enhancing student attention to content, (5) building communities of practice, and (6) resource discovery. These factors accord with a Uses and Gratifications perspective that depicts adopters as active media users choosing and shaping media use to meet their own needs. Results provide a more comprehensive picture of social media use than found in previous work, encompassing not only the array of media used but also the range of purposes associated with use of social media in contemporary teaching initiatives.; Analyzing social media and learning through content and social network analysis: A faceted methodological approach -- ; Coding and Classifying Knowledge Exchange on Social Media -- As social media become a staple for knowledge discovery and sharing, questions arise about how self-organizing communities manage learning outside the domain of organized, authority-led institutions. Yet examination of such communities is challenged by the quantity of posts and variety of media now used for learning. This paper addresses the challenges of identifying (1) what information, communication, and discursive practices support successful online communities, (2) whether such practices are similar on Twitter and Reddit, and (3) whether machine learning classifiers can be successfully used to analyze larger datasets of learning exchanges. This paper builds on earlier work that used manual coding of learning and exchange in Reddit ‘Ask’ communities to derive a coding schema we refer to as ‘learning in the wild’. This schema of eight categories: explanation with disagreement, agreement, or neutral presentation; socializing with negative, or positive intent; information seeking; providing resources; and comments about forum rules and norms. To compare across media, results from coding Reddit’s AskHistorians are compared to results from coding a sample of #Twitterstorians tweets (n = 594). High agreement between coders affirmed the applicability of the coding schema to this different medium. LIWC lexicon-based text analysis was used to build machine learning classifiers and apply these to code a larger dataset of tweets (n = 69,101). This research shows that the ‘learning in the wild’ coding schema holds across at least two different platforms, and is partially scalable to study larger online learning communities.; Internet and Community. -- A special issue on Internet and community.  Trends in Internet accessibility and use demonstrate that information and communication technologies are becoming increasingly integrated in daily life.  People are now using the Internet in ways that drive change in communities, particularly where and how they are formed, and creating transformative effects on how to define, attach and retain communal identity across activities.  The writers introduce the articles in this special issue.; Introduction to the special issue on learning analytics. -- This introduction to the special issue on learning analytics provides an overview of the area, acknowledging the research traditions it emerges from, such as computer-supported collaborative learning, academic analytics, and educational data mining, and the way the field aims to bridge from technological innovation to learning purposes. The introduction provides examples of areas and educational stakeholders who are served by and can benefit from learning analytics initiatives, referring throughout to the articles in this special issue. (PsycINFO Database Record (c) 2016 APA, all rights reserved); An information policy perspective on learning analytics -- Policy for learning analytics joins a stream of initiatives aimed at understanding the expanding world of information collection, storage, processing and dissemination that is being driven by computing technologies. This paper offers a information policy perspective on learning analytics, joining work by others on ethics and privacy in the management of learning analytics data [8], but extending to consider how issues play out across the information lifecycle and in the formation of policy. Drawing on principles from information policy both informs learning analytics and brings learning analytics into the information policy domain. The resulting combination can help inform policy development for educational institutions as they implement and manage learning analytics policy and practices. The paper begins with a brief summary of the information policy perspective, then addresses learning analytics with attention to various categories of consideration for policy development.; Crisis on twitter: information, emotion and political content. -- ; Women in Social Media: Safe and Unsafe Spaces -- ; Learning in the wild -- Learning on and through social media is becoming a cornerstone of lifelong learning, creating places not only for accessing information, but also for finding other self-motivated learners. Such is the case for Reddit, the online news sharing site that is also a forum for asking and answering questions. We studied learning practices found in ‘Ask’ subreddits AskScience, Ask_Politics, AskAcademia, and AskHistorians to develop a coding schema for informal learning. This paper describes the process of evaluating and defining a workable coding schema, one that started with attention to learning processes associated with discourse, exploratory talk, and conversational dialogue, and ended with including norms and practices on Reddit and the support of communities of inquiry. Our ‘learning in the wild’ coding schema contributes a content analysis schema for learning through social media, and an understanding of how knowledge, ideas, and resources are shared in open, online learning forums.; Learning, connectivity and networks -- Purpose: This is paper is concerned with the learning outcomes associated with connectivity through online networks, open online exchange and wider changes associated with contemporary information practices. The theme of connectivity is used here to capture both the detailed specificity of relations that define networks of learners and the ambient effect of wide accessibility to resources and people through open, online forums. Design/methodology/approach: The paper follows the idea of a network from the ground up, outlining the social network perspective as a way to consider the foundational bases of learning and networks, as well as the effect of ambient influence. The paper addresses the ways learning may be viewed as a social network relation, an interpersonal relationship and an outcome of interaction and connectivity, and how network connectivity can be used as input for design for learning. Findings: The paper presents a range of perspectives and studies that view learning from a social network and connectivity perspective, emphasizing both the person-to-person connectivity of a learning tie and the impact of contemporary data and information sharing through the dynamics of open contributory practice. Practical implications: The outcome of connectivity in the service of learning is bound up with digital information practices, including individual practices of search, retrieval, participation, knowledge dissemination, knowledge construction and more. This paper provides a network perspective on learning relations that accommodates analysis in online and offline environments, but incorporates attention to the open, online retrieval and contributory practices that now influence learning practices and which may support design of new learning environments. Originality/value: This paper offers insight into the way social networks and connectivity combine to show network relations, relationships, outcomes and design input at the actor, network and societal levels.; Developing learning analytics methods on Reddit -- ; Learning in the wild: Coding Reddit for learning and practice -- ; Crowdsourcing the curriculum -- Inclusion of open resources that employ a peer-generated approach is changing who learns what, from whom, and via what means. With these changes, there is a shift in responsibilities from the course designer to motivated and self-directed learner-participants. While much research on e-learning has addressed challenges of creating and sustaining participatory environments, the development of massive open online courses calls for new approaches that go beyond the existing research on participatory environments in institutionally defined classes. We decenter institutionally defined classes and broaden the discussion to the literature on the creation of open virtual communities and the operation of open online crowds. We draw on literatures on online organizing, learning science, and emerging educational practice to discuss how collaboration and peer production shape learning and enable “crowdsourcing the curriculum.”; Inaugural issue perspectives on Information and Learning Sciences as an integral scholarly Nexus -- Purpose: The new journal, Information and Learning Sciences, aims to advance the understanding of human inquiry, learning and knowledge building in human design and uses of information systems, e-learning systems and socio-technical system contexts. Design/methodology/approach: Under the new editorial team, advisory board, and reviewer community, the authors aim to develop and provide an established and rigorous space for scholarly development that explores phenomena at the intersections of these two fields of inquiry. The editorial advisory board brings together over 70 leading international scholars who are evenly divided between and across these two disciplines. Findings: To chart the course for the journal’s scope and mission and set a standard for quality, the editorial team decided to launch with an inaugural issue of eight articles comprising mainly of theoretical syntheses and editorial essays, alongside three works that report empirical study research findings as exemplars. Authors were chosen by the editorial team based on their known thought leadership at this intersection, and the articles underwent a single-blind review process with a period of revisions. All articles and issues moving forward will be double-blind peer reviewed under both fields’ expected norms and standards of rigorous editorial excellence. The authors invite all interested experts and experts-in-development in our two disciplines, to submit work and volunteer as reviewers in these pursuits. The authors present a brief summary narrative discussing a selection of four recent areas of interdisciplinary research out of which the journal has emerged. The authors then describe each of the special issue articles contributed by our generous invited authors. Originality/value: The authors enthusiastically and warmly invite continued engagement along these lines in the journal’s pages, and also welcome related, and wholly contrary points of view, and points of departure that may build upon or debate some of the themes we raise in this introduction and inaugural issue."
Carsten Oesterlund,"Living with Monsters? -- These proceedings of the IFIP WG 8.2 reflects the response of the research community to the theme selected for the 2018 working conference: “Living with Monsters? Social Implications of Algorithmic Phenomena, Hybrid Agency and the Performativity of Technology”.; Socio-Material Design: Bounding Technologies in Practice -- ; Drift and shift in the organizing vision career for personal health records -- Organizational information technology innovations develop and diffuse through the efforts of communities of stakeholders working in cooperation and competition to articulate, motivate, and diffuse an innovation. Community members' discourse can reveal competing interests and tensions that influence whether ideas central to the innovation coalesce, drift apart, or dissipate and thus the innovation's trajectory. To investigate these dynamics, we adopted the theoretical lens of the organizing vision framework and historical and discourse analysis methods to study developments with personal health records (PHRs) in the U.S. for over a decade (2003-2013). Our analysis revealed ongoing drift in PHR discourse across the innovation community despite concerted efforts by key stakeholders to promote an overarching vision. Shifts in discourse developed as four competing PHR versions coalesced around different institutional arrangements for health and health data stewardship, health data stores, and innovation community actors. This analysis furthers our understanding of career dynamics of an organizing vision and the implications of these dynamics for innovation diffusion. The study also highlights implications for health IT innovation research and for practice.; Introduction to the Minitrack on Crowd-enhanced Technologies for Improving Reasoning and Solving Complex Problems -- ; Beyond data management: Exploring new roles for librarians in citizen science projects -- ; Learning at the seafloor, looking at the sky -- In this study, we explore the relationship between individual and collaborative learning activities as they occur in two online citizen science projects, Seafloor Explorer and Planet Hunters. Trace ethnography is suggested as a methodology suitable for investigating this relationship. Preliminary findings identify relationships between four types of activities that emerge which support individual and collaborative learning activities and participation.; Networks of Influential Participants -- ; Event-based Analysis of a Citizen Science Community: Are new non-sustained users included? -- ; Linguistic Changes in Online Citizen Science: A Structurational Perspective -- For peer-production projects to be successful, members must develop a specific and universal language that enables them to cooperate. Complicating the development of language in some projects is the lack of formalized structures (e.g., roles) that communicate to members the norms and practices around language. We address the question of how do role differences among participants interact with the adoption and dissemination of new terminologies in open peer production communities? Answering this question is crucial because we want communities to be productive even when self-managed, which requires understanding how shared language emerges. We examine this question using a structurational lens in the setting of a citizen science project. Exploring the use of words in the Gravity Spy citizen science project, we find that many words are reused and that most new words that are introduced are not picked up, showing a reproduction of structure. However, some novel words are used by others, showing an evolution of the structure. Participants with roles closer to the science are more likely to have their words reused, showing the mutually reinforcing nature of structures of signification, legitimation, and domination.; E-infrastructures for research collaboration -- Collaborative research practices are a highly interesting domain for CSCW. So far, CSCW has mainly focused on computation- and/or data-intensive research endeavors. Here, resources are typically pooled via common e-infrastructures for data access and processing, a set-up requiring additional layers of coordination. Such a focus largely foregrounds the sciences and other fields that rely on highly structured (or structure-able) data and the routinized processes of analysis. In contrast, in this one-day workshop we discuss the conditions and challenges characteristic of research collaboration in the qualitative social sciences and humanities (SSH). In particular, we examine the sociotechnical infrastructures that enable and support research practices that - in comparison with the collaborative paradigm of the natural sciences - tend to be less structured, compartmentalized, and routinized, but more fluid, flexible, and open-ended. The workshop seeks to collect empirical insights and design experiences, preparing the grounds for a comprehensive understanding of the role of einfrastructures for collaborative research practices in SSH.; Open Community Health -- This report summarizes key outcomes from a workshop on open community health conducted at the University of Nebraska at Omaha in April 2018. Workshop members represented research and practice communities across Citizen Science, Open Source, and Wikipedia. The outcomes from the workshop include (1) comparisons among these communities, (2) how a shared understanding and assessment of open community health can be developed, and (3) a taxonomical comparison to begin a conversation between these communities that have developed disparate languages.; Boundary-spanning documents in online communities -- Online communities bring together people with varied access to and understanding of the work at hand, who must collaborate through documents of various kinds. We develop a framework articulating the characteristics of documents supporting collaborators with asymmetric access to knowledge versus those with symmetric knowledge. Drawing on theories about document genre, boundary objects and provece, we hypothesize that documents supporting asymmetric groups are likely to articulate or prescribe their own 1), purpose, 2), context of use, 3), content and form and 4), provece in greater detail than documents used by people with symmetric access to knowledge. We are testing these hypotheses through content analysis of documents and instructions from a variety offree/libre open source projects. We present preliminary findings consistent with the hypotheses developed. The completed study will suggest new directions for research on communications in online communities, as well as advice for those supporting such communities.; The Hermeneutics of Trace Data: Building an Apparatus -- When people interact via information systems, the data is captured by the systems as a side effect of the interaction. These data are increasingly interesting and available for research. In a sense, these systems become a new kind of research apparatus, and like all advances in instrumentation, open up new areas of study with the potential for discovery. While at first glance, such “big data” analysis seems to be most suitable for a positivist quantitative research approach. However, a closer inspection reveals that interpretive research strategies may better support the challenges associated with digital trace data. By merging insights from hermeneutics and sociomateriality, we argue that trace data analysis entails the building of a research apparatus. Hermeneutic principles play a key role in the application of this apparatus and allow researchers to make sense of the often partial traces left by online participants. Drawing on longitudinal trace data from a study of citizen science practices the paper illustrates the value of merging insights from hermeneutics with sociomaterial insights. The approach allows researchers to account for not only the material dynamics of digital trace data but also the temporal dimension of online practices.; Personal Health Records: Empowering patients through information systems? -- ; Mother, My Medical Record: What role does patients with chronic conditions and parents play in the management of their medical information? -- ; Typologies of Learning in Online Collaborative Communities -- ; Building an Apparatus -- We propose a set of methodological principles and strategies for the use of trace data, i.e., data capturing performances carried out on or via information systems, often at a fine level of detail. Trace data comes with a number of methodological and theoretical challenges associated with the inseparable nature of the social and material. Drawing on Haraway and Barad’s distinctions among refraction, reflection and diffraction, we compare three approaches to trace data analysis. We argue that a diffractive methodology allows us to explore how trace data are not given but created though construction of a research apparatus to study trace data. By focusing on the diffractive ways in which traces ripple through an apparatus, it is possible to explore some of the taken-for-granted, invisible dynamics of sociomateriality. Equally, important this approach allows us to describe what and when distinctions within entwined phenomena emerge in the research process. Empirically, we illustrate the guiding principles and strategies by analyzing trace data from Gravity Spy, a crowdsourced citizen science project on Zooniverse. We conclude by suggesting that a diffractive methodology may help us draw together quantitative and qualitative research practices in new and productive ways that also raises interesting design questions.; Introduction to materiality of information, documents, and work minitrack -- ; Introduction to materiality of information, documents and work minitrack -- ; Sociomateriality and design -- Design research and the literature on sociomateriality emerge out of different academic traditions but share a common interest in the material. A sociomaterial perspective allows us to account for the complex ways people mingle and mangle information systems of all sorts into their social endeavors to accomplish organizational tasks. But, how do we account for these sociomaterial phenomena in all their complexity when faced with the task of designing information systems? The panel brings together prominent researchers bridging the gap between design research and the current debate on sociomateriality. Each presenter addresses the challenges associated with informing grounded design work with insights from a highly abstract intellectual debate.; Artificial intelligence and the world of work, a co-constitutive relationship -- The use of intelligent machines—digital technologies that feature data-driven forms of customization, learning, and autonomous action—is rapidly growing and will continue to impact many industries and domains. This is consequential for communities of researchers, educators, and practitioners concerned with studying, supporting, and educating information professionals. In the face of new developments in artificial intelligence (AI), the research community faces 3 questions: (a) How is AI becoming part of the world of work? (b) How is the world of work becoming part of AI? and (c) How can the information community help address this topic of Work in the Age of Intelligent Machines (WAIM)? This opinion piece considers these 3 questions by drawing on discussion from an engaging 2019 iConference workshop organized by the NSF supported WAIM research coordination network (note: https://waim.network).; Preface -- ; Rethinking Documents -- ; Document Practice as Insight to Digital Infrastructures of Distributed, Collaborative Social Scientists -- ; Using Ethnography of Email to Understand Distributed Scientific Collaborations -- ; Sociomateriality in the Sand Box -- 	Entrepreneurs are important drivers of innovation. Their work is highly creative while also requiring a distinct paper trail for processes such as incorporation of a business, filing of patents, and management of shifting resources. In order for entrepreneurial team members to interact in productive and creative ways, they need to establish shared and stable frames of reference (i.e., actional field) to support collaborative decision-making and coordination. Documents play a central role in this process. The authors present an ethnographic study of 20 student start-up teams that explored the ways in which young entrepreneurs use documents of mixed materiality (both visual and text-based, analog and digital) to demarcate the actional field for their communicative activities. Many of the teams in this study were embarking on their first experience with the start-up process, providing an interesting opportunity to observe the sociomaterial relationship between their emergent communicative activities and documenting practices.; Towards a Method of Documentary Practices for Personal Health Information Management -- ; TRACE -- Crowdsourcing has become a frequently adopted approach to solving various tasks from conducting surveys to designing products. In the field of reasoning-support, however, crowdsourcing-related research and application have not been extensively implemented. Reasoning-support is essential in intelligence analysis to help analysts mitigate various cognitive biases, enhance deliberation, and improve report writing. In this paper, we propose a novel approach to designing a crowdsourcing platform that facilitates stigmergic coordination, awareness, and communication for intelligence analysis. We have partly materialized our proposal in the form of a crowdsourcing system which supports intelligence analysis: TRACE (Trackable Reasoning and Analysis for Collaboration and Evaluation). We introduce several stigmergic approaches integrated into TRACE and discuss the potential experimentation of these approaches. We also explain the design implications for further development of TRACE and similar crowdsourcing systems to support reasoning."
Daniel Acuna,"Science Concierge -- Finding relevant publications is important for scientists who have to cope with exponentially increasing numbers of scholarly material. Algorithms can help with this task as they help for music, movie, and product recommendations. However, we know little about the performance of these algorithms with scholarly material. Here, we develop an algorithm, and an accompanying Python library, that implements a recommendation system based on the content of articles. Design principles are to adapt to new content, provide near-real time suggestions, and be open source. We tested the library on 15K posters from the Society of Neuroscience Conference 2015. Human curated topics are used to cross validate parameters in the algorithm and produce a similarity metric that maximally correlates with human judgments. We show that our algorithm significantly outperformed suggestions based on keywords. The work presented here promises to make the exploration of scholarly material faster and more accurate.; Claim Extraction in Biomedical Publications using Deep Discourse Model and Transfer Learning --  Claims are a fundamental unit of scientific discourse. The exponential growth in the number of scientific publications makes automatic claim extraction an important problem for researchers who are overwhelmed by this information overload. Such an automated claim extraction system is useful for both manual and programmatic exploration of scientific knowledge. In this paper, we introduce a new dataset of 1,500 scientific abstracts from the biomedical domain with expert annotations for each sentence indicating whether the sentence presents a scientific claim. We introduce a new model for claim extraction and compare it to several baseline models including rule-based and deep learning techniques. Moreover, we show that using a transfer learning approach with a fine-tuning step allows us to improve performance from a large discourse-annotated dataset. Our final model increases F1-score by over 14 percent points compared to a baseline model without transfer learning. We release a publicly accessible tool for discourse and claims prediction along with an annotation tool. We discuss further applications beyond biomedical literature. ; Estimating a Null Model of Scientific Image Reuse to Support Research Integrity Investigations --  When there is a suspicious figure reuse case in science, research integrity investigators often find it difficult to rebut authors claiming that ""it happened by chance"". In other words, when there is a ""collision"" of image features, it is difficult to justify whether it appears rarely or not. In this article, we provide a method to predict the rarity of an image feature by statistically estimating the chance of it randomly occurring across all scientific imagery. Our method is based on high-dimensional density estimation of ORB features using 7+ million images in the PubMed Open Access Subset dataset. We show that this method can lead to meaningful feedback during research integrity investigations by providing a null hypothesis for scientific image reuse and thus a p-value during deliberations. We apply the model to a sample of increasingly complex imagery and confirm that it produces decreasingly smaller p-values as expected. We discuss applications to research integrity investigations as well as future work. ; Bioscience-scale automated detection of figure element reuse -- Scientists reuse figure elements sometimes appropriately, e.g. when comparing methods, and sometimes inappropriately, e.g. when presenting an old experiment as a new control. To understand such reuse, automatically detecting it would be important. Here we present an analysis of figure element reuse on a large dataset comprising 760 thousand open access articles and 2 million figures. Our algorithm detects figure region reuse, while being robust to rotation, cropping, resizing, and contrast changes, and estimates which of the reuses have biological meaning. Then a three-person panel analyzes how problematic these biological reuses are using contextual information such as captions and full texts. Based on the panel reviews, we estimate that 9% of the biological reuses would be uimously perceived as at least suspicious. We further estimate that 0.6% of all articles would be uimously perceived as fraudulent, with inappropriate reuses occurring 43% across articles, 28% within article, and 29% within a figure. Our tool rapidly detects image reuse at scale, promising to be useful to a broad range of people that campaign for scientific integrity. We suggest that a great deal of scientific fraud will be, sooner or later, detectable by automatic methods.; People efficiently explore the solution space of the computationally intractable traveling salesman problem to find near-optimal tours -- Humans need to solve computationally intractable problems such as visual search, categorization, and simultaneous learning and acting, yet an increasing body of evidence suggests that their solutions to instantiations of these problems are near optimal. Computational complexity advances an explanation to this apparent paradox: (1) only a small portion of instances of such problems are actually hard, and (2) successful heuristics exploit structural properties of the typical instance to selectively improve parts that are likely to be sub-optimal. We hypothesize that these two ideas largely account for the good performance of humans on computationally hard problems. We tested part of this hypothesis by studying the solutions of 28 participants to 28 instances of the Euclidean Traveling Salesman Problem (TSP). Participants were provided feedback on the cost of their solutions and were allowed unlimited solution attempts (trials). We found a significant improvement between the first and last trials and that solutions are significantly different from random tours that follow the convex hull and do not have self-crossings. More importantly, we found that participants modified their current better solutions in such a way that edges belonging to the optimal solution (""good"" edges) were significantly more likely to stay than other edges (""bad"" edges), a hallmark of structural exploitation. We found, however, that more trials harmed the participants' ability to tell good from bad edges, suggesting that after too many trials the participants ""ran out of ideas."" In sum, we provide the first demonstration of significant performance improvement on the TSP under repetition and feedback and evidence that human problem-solving may exploit the structure of hard problems paralleling behavior of state-of-the-art heuristics.; Limiting motor skill knowledge via incidental training protects against choking under pressure -- The paradoxical harmful effects of motivation and incentives on skilled performance (“choking under pressure”) are observed in a wide variety of motor tasks. Two theories of this phenomenon suggest that choking under pressure occurs due to maladaptive attention and top-down control, either through distraction away from the task or interference via an overreliance on controlled processing of a skilled task. A third theory, overmotivation (or overarousal), suggests that under pressure, “instinctive” or Pavlovian approach/withdrawal responses compete with the desired response. Only the two former theories predict that choking under pressure would be less likely to occur if an individual is unaware of the skill over which to assert top-down control. Here we show that only participants who train and perform with premovement cues that allowed for preparatory movement planning choke under pressure due to large monetary incentives, and that this effect is independent of the level of skill attained. We provide evidence that this might be due to increased movement variability under performance pressure. In contrast, participants trained incidentally to reduce explicit skill knowledge do not modulate performance on the basis of incentives and appear immune to choking. These results are most consistent with distraction theories of choking and suggest that training strategies that limit awareness may lead to skills that are more robust under performance pressure.; Artificial mental phenomena -- Detecting biases in artificial intelligence has become difficult because of the impenetrable nature of deep learning. The central difficulty is in relating unobservable phenomena deep inside models with observable, outside quantities that we can measure from inputs and outputs. For example, can we detect gendered perceptions of occupations (e.g., female librarian, male electrician) using questions to and answers from a word embedding-based system? Current techniques for detecting biases are often customized for a task, dataset, or method, affecting their generalization. In this work, we draw from Psychophysics in Experimental Psychology-meant to relate quantities from the real world (i.e., “Physics”) into subjective measures in the mind (i.e., “Psyche”)-to propose an intellectually coherent and generalizable framework to detect biases in AI. Specifically, we adapt the two-alternative forced choice task (2AFC) to estimate potential biases and the strength of those biases in black-box models. We successfully reproduce previously-known biased perceptions in word embeddings and sentiment analysis predictions. We discuss how concepts in experimental psychology can be naturally applied to understanding artificial mental phenomena, and how psychophysics can form a useful methodological foundation to study fairness in AI.; Intellectual synthesis in mentorship determines success in academic careers -- As academic careers become more competitive, junior scientists need to understand the value that mentorship brings to their success in academia. Previous research has found that, unsurprisingly, successful mentors tend to train successful students. But what characteristics of this relationship predict success, and how? We analyzed an open-access database of 18,856 researchers who have undergone both graduate and postdoctoral training, compiled across several fields of biomedical science with an emphasis on neuroscience. Our results show that postdoctoral mentors were more instrumental to trainees’ success compared to graduate mentors. Trainees’ success in academia was also predicted by the degree of intellectual synthesis between their graduate and postdoctoral mentors. Researchers were more likely to succeed if they trained under mentors with disparate expertise and integrated that expertise into their own work. This pattern has held up over at least 40 years, despite fluctuations in the number of students and availability of independent research positions.; Chunking as the result of an efficiency computation trade-off -- How to move efficiently is an optimal control problem, whose computational complexity grows exponentially with the horizon of the planned trajectory. Breaking a compound movement into a series of chunks, each planned over a shorter horizon can thus reduce the overall computational complexity and associated costs while limiting the achievable efficiency. This trade-off suggests a cost-effective learning strategy: to learn new movements we should start with many short chunks (to limit the cost of computation). As practice reduces the impediments to more complex computation, the chunking structure should evolve to allow progressively more efficient movements (to maximize efficiency). Here we show that monkeys learning a reaching sequence over an extended period of time adopt this strategy by performing movements that can be described as locally optimal trajectories. Chunking can thus be understood as a cost-effective strategy for producing and learning efficient movements.; Show me your app usage and I will tell who your close friends are -- Personal interactions using cell phones are so embedded in our everyday lives that they go almost unnoticed. We may try to protect ourselves from releasing sensitive information by increasing privacy protections, but how much can be inferred from our most basic phone usage? Using a largescale annotated dataset of cell phone usage, we build a predictor to determine location context (home, work, commute) and social relationships (with close friend, with family) based on the clock of the phone and sequences of apps executed. Surprisingly, we show that just using this basic information we can accurately predict whether someone is at home, at work, and/or with close friends, family. We note that this is almost inevitable because it only depends on using the phone and not the privacy settings. Our results suggest that our relationship with technology gives away more than we might suspect. This presents opportunities and challenges discussed in this paper.; The sociology of scientific validity -- Professional connections between the creators and evaluators of scientific work are ubiquitous, and the possibility of bias ever-present. Although connections have been shown to bias predictions of uncertain future performance, it is unknown whether such biases occur in the more concrete task of assessing scientific validity for completed works, and if so, how. This study presents evidence that connections between authors and reviewers of neuroscience manuscripts are associated with biased judgments and explores the mechanisms driving that effect. Using reviews from 7981 neuroscience manuscripts submitted to the journal PLOS ONE, which instructs reviewers to evaluate manuscripts on scientific validity alone, we find that reviewers favored authors close in the co-authorship network by ∼0.11 points on a 1.0–4.0 scale for each step of proximity. PLOS ONE's validity-focused review and the substantial favoritism shown by distant vs. very distant reviewers, both of whom should have little to gain from nepotism, point to the central role of substantive disagreements between scientists in different professional networks (“schools of thought”). These results suggest that removing bias from peer review cannot be accomplished simply by recusing closely connected reviewers, and highlight the value of recruiting reviewers embedded in diverse professional networks.; Scientific Image Tampering Detection Based On Noise Inconsistencies --  Scientific image tampering is a problem that affects not only authors but also the general perception of the research community. Although previous researchers have developed methods to identify tampering in natural images, these methods may not thrive under the scientific setting as scientific images have different statistics, format, quality, and intentions. Therefore, we propose a scientific-image specific tampering detection method based on noise inconsistencies, which is capable of learning and generalizing to different fields of science. We train and test our method on a new dataset of manipulated western blot and microscopy imagery, which aims at emulating problematic images in science. The test results show that our method can detect various types of image manipulation in different scenarios robustly, and it outperforms existing general-purpose image tampering detection schemes. We discuss applications beyond these two types of images and suggest next steps for making detection of problematic images a systematic step in peer review and science in general. ; Dead Science -- Scientific progress critically depends on disseminating analytic pipelines and datasets that make results reproducible and replicable. Increasingly, researchers make resources available for wider reuse and embed links to them in their published manuscripts. Previous research has shown that these resources become unavailable over time but the extent and causes of this problem in open access publications has not been explored well. By using 1.9 million articles from PubMed Open Access, we estimate that half of all resources become unavailable after 8 years. We find that the number of times a resource has been used, the international (int) and organization (org) domain suffixes, and the number of affiliations are positively related to resources being available. In contrast, we found that the length of the URL, Indian (in), European Union (eu), and Chinese (cn) domain suffixes, and abstract length are negatively related to resources being available. Our results contribute to our understanding of resource sharing in science and provide some guidance to solve resource decay.; Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models -- Scientist learn early on how to cite scientific sources to support their claims. Sometimes, however, scientists have challenges determining where a citation should be situated—or, even worse, fail to cite a source altogether. Automatically detecting sentences that need a citation (i.e., citation worthiness) could solve both of these issues, leading to more robust and well-constructed scientific arguments. Previous researchers have applied machine learning to this task but have used small datasets and models that do not take advantage of recent algorithmic developments such as attention mechanisms in deep learning. We hypothesize that we can develop significantly accurate deep learning architectures that learn from large supervised datasets constructed from open access publications. In this work, we propose a bidirectional long short-term memory network with attention mechanism and contextual information to detect sentences that need citations. We also produce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset, which is orders of magnitude larger than previous datasets. Our experiments show that our architecture achieves state of the art performance on the standard ACL-ARC dataset (F1= 0.507) and exhibits high performance (F1= 0.856) on the new PMOA-CITE. Moreover, we show that it can transfer learning across these datasets. We further use interpretable models to illuminate how specific language is used to promote and inhibit citations. We discover that sections and surrounding sentences are crucial for our improved predictions. We further examined purported mispredictions of the model, and uncovered systematic human mistakes in citation behavior and source data. This opens the door for our model to check documents during pre-submission and pre-archival procedures. We discuss limitations of our work and make this new dataset, the code, and a web-based tool available to the community.; Assigning credit to scientific datasets using article citation networks -- A citation is a well-established mechanism for connecting scientific artifacts. Citation networks are used by citation analysis for a variety of reasons, prominently to give credit to scientists' work. However, because of current citation practices, scientists tend to cite only publications, leaving out other types of artifacts such as datasets. Datasets then do not get appropriate credit even though they are increasingly reused and experimented with. We develop a network flow measure, called DataRank, aimed at solving this gap. DataRank assigns a relative value to each node in the network based on how citations flow through the graph, differentiating publication and dataset flow rates. We evaluate the quality of DataRank by estimating its accuracy at predicting the usage of real datasets: web visits to GenBank and downloads of Figshare datasets. We show that DataRank is better at predicting this usage compared to alternatives while offering additional interpretable outcomes. We discuss improvements to citation behavior and algorithms to properly track and assign credit to datasets.; The effect of novelty on the future impact of scientific grants --  Government funding agencies and foundations tend to perceive novelty as necessary for scientific impact and hence prefer to fund novel instead of incremental projects. Evidence linking novelty and the eventual impact of a grant is surprisingly scarce, however. Here, we examine this link by analyzing 920,000 publications funded by 170,000 grants from the National Science Foundation (NSF) and the National Institutes of Health (NIH) between 2008 and 2016. We use machine learning to quantify grant novelty at the time of funding and relate that measure to the citation dynamics of these publications. Our results show that grant novelty leads to robust increases in citations while controlling for the principal investigator's grant experience, award amount, year of publication, prestige of the journal, and team size. All else held constant, an article resulting from a fully-novel grant would on average double the citations of a fully-incremental grant. We also find that novel grants produce as many articles as incremental grants while publishing in higher prestige journals. Taken together, our results provide compelling evidence supporting NSF, NIH, and many other funding agencies' emphases on novelty. "
Ingrid Erickson,"The ethos and pragmatics of data sharing -- The focus of this panel is the pragmatics of data sharing as framed by the needs and pressures of scholarly work. Panelists represent a lively blend of quantitative, qualitative and mixed methods researchers with recent experiences in developing and sharing data. Panelists will present research and address questions related to data collection and management, human subjects protocols, data archival and data repositories and other emergent issues.; Commentary -- ; Workshop -- This all-day workshop aims to promote convergence among its participants on research related to working with intelligent machines. We define intelligent machines as both material (e.g., robots) and immaterial (e.g., algorithms) computing technologies that can be characterized by autonomy, the ability to learn, and the ability to interact with other systems and with humans. The workshop has three goals: identifying specific research problems around work and intelligent machines, developing a common language base that can facilitate interdisciplinary collaboration among researchers, and identifying information and cyber-infrastructure needs to support convergent research. Workshop activities will facilitate interdisciplinary dialogue and strive to generate high-impact research ideas to advance each of these goals.; Infrastructuring as Bricolage -- ; Flexible Turtles and Elastic Octopi -- This paper takes as its starting place the rich context of many knowledge workers today—highly distributed, increasing project focused, typically atypical days, infrastructural—and attempts to push past extant descriptions of their practices as ‘flexible’. Using empirical data informed by a practice theory lens, we expand the understanding of flexibility with regard to work by augmenting how worker disposition, as well as the ability to engage with agility in dynamic circumstances, should be considered as a factor when examining and designing for this population. We make several contributions of interest to the wider CSCW community. First, we distinguish between those who showcase flexible practices and those who proactively orient around flexibility. We call this second group ‘elastic workers’. Second, we raise new questions for us as scholars and designers keen to exploit the conceptual and pragmatic intersection of technology and work. These questions create opportunities to explore different methods for understanding complex phenomena such as flexibility, as well as understanding how we might design for this phenomenon with more foresight in the future.; Editor's welcome -- ; Envisioning futures of practice-centered computing -- In this panel, we will engage with the conference's membership and friends to consider directions for the possible futures of practice-centered computing. This panel is not targeting or aiming to result in a single, agreed ""universal” vision, nor to ask for a shared vision among the panelists and the audience. Rather, we offer several and diverse vision statements by distinguished and innovative ECSCW scholars, being experts in their specific domain or context of research. These statements will be necessarily incomplete until the ECSCW membership has joined the discussion, offering their own, additional visions of the futures of the field. With this, the panel aims to engage in a discussion that foresees exciting future research directions for the field of ECSCW but likewise also unveils potential hurdles the community might face.; Everyday automation experience -- Automated systems and their interfaces are increasingly merging with our ambient environment leading to a heightened impact on our everyday leisure and work experiences. While automation systems have been a realm for highly specialized tasks and trained experts until recently, now more and more non-expert users encounter automated systems in their everyday life. The deployment of these systems fundamentally changes practices and experiences in various domains. The overall goal of this workshop is to investigate the requirements and design criteria for automation that are experienced in everyday situations. In particular we will strive to come up with a set of principles for three key areas of everyday automation experience: intelligibility, experienced control, and capturing automation experience. This way, the workshop provides a first forum for knowledge exchange and networking across usage domains and contexts.; Crafting moral infrastructures -- We present findings from interviews with 23 individuals affiliated with non-profit organizations (NPOs) to understand how they deploy information and communication technologies (ICTs) in civic engagement efforts. Existing research about NPO ICT use is largely critical, but we did not find evidence that NPOs fail to use tools effectively. Rather, we detail how various ICT use on the part of NPOs intersects with unique affordance perceptions and adoption causes. Overall, we find that existing theories about technology choice (e.g., task-technology fit, uses and gratifications) do not explain the assemblages NPOs describe. We argue that NPOs fashion infrastructures in accordance with their moral economy frameworks rather than selecting tools based on utility. Together, the rhetorics of infrastructure and moral economies capture the motivations and constraints our participants expressed and challenge how prevailing theories of ICT usage describe the non-profit landscape.; Infrastructure vs. Community -- Co-working and co-living companies are rising globally and the increasing participation within the gig economy has extended the range of users of community-based spaces (co-spaces) and raised a set of different community models in considering how to support them. In this paper, we specifically focus on the needs of digital nomads in co-spaces who struggle to pursue their personal and professional freedom. In so doing, we raise awareness of existing tensions that currently hinder the social engagement of these individuals in co-space settings.; The social infrastructure of Co-spaces -- The rise of co-working and co-living spaces, as well as related shared spaces such as makerspaces and hackerspaces—a group we refer to as various types of “co-spaces”—has helped facilitate a parallel expansion of the “digital nomad (DN)” lifestyle. Digital nomads, colloquially, are those individuals that leverage digital infrastructures and sociotechnical systems to live location-independent lives. In this paper, we use Oldenburg’s framework of a first (home), second (work), and third (social) place as an analytical lens to investigate how digital nomads understand the affordance of these different types of spaces. We present an analysis of posts and comments on the ‘/r/digitalnomad’ subreddit, a vibrant online community where DNs ask questions and share advice about the different types of places and amenities that are necessary to pursue their digital nomad lifestyle. We found that places are often assessed positively or negatively relative to one primary characteristic: either they provide a means for nomads to maintain a clear separation between the social and professional aspects of their lives, or they provide a means to merge these aspects together. Digital nomads that favor the first type of place tend to focus on searching for factors that they feel will promote their own work productivity, whereas DNs that favor the second type of place tend to focus on factors that they feel will allow them to balance their work and social lives. We also build on linkages between the notion of a third place and the more recent theoretical construct of social infrastructure. Ultimately, we demonstrate how DNs’ interests in co-spaces provide a kind of edge-case for CSCW and HCI scholars to explore how sociotechnical systems, such as variants of co-spaces, inform one another as well as signify important details regarding new ways of living and engaging with technology.; The product of availability -- Constant connectivity and total availability to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability of employees is possible and presumed. Scholars have explored how new technological affordances, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. That is, current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm. In this paper we use qualitative data to illustrate how total availability is an integral aspect of the 'product' offered by professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes.; People who can take it how women wikipedians negotiate and navigate safety -- Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors—a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users.; Digital literacy and informal learning environments -- New technologies and developments in media are transforming the way that individuals, groups and societies communicate, learn, work and govern. This new socio-technical reality requires participants to possess not only skills and abilities related to the use of technological tools, but also knowledge regarding the norms and practices of appropriate usage. To be 'digitally literate' in this way encompasses issues of cognitive authority, safety and privacy, creative, ethical, and responsible use and reuse of digital media, among other topics. A lack of digital literacy increasingly implicates one's full potential of being a competent student, an empowered employee or an engaged citizen. Digital literacy is often considered a school-based competency, but it is introduced and developed in informal learning contexts such as libraries, museums, social groups, affinity spaces online, not to mention the home environment. This article recognizes and connects the ways and places we might conceptualize and realize an expanded view of digital literacy that fits today's changing reality.; The expression of emotions on Instagram -- This preliminary research study examines women farmers on Instagram who use the hashtag #womenwhofarm. We investigate the emotional valence of these posts using a multimodal analysis of both text and images. Previous research has found a positivity bias on Instagram, wherein users predomitly express themselves with a positive emotional tone. Using open-ended coding of 651 Instagram posts, this study finds that women farmers use mostly neutral emotional tonality in their images and text content. The study points to a need for disambiguation between different affective terminology in research on emotions in social media and highlights the need for continued theorization on the relationship between images and emotions.; Editors' welcome -- ; Theory transfers? Social theory & CSCW research -- Finding time to present and discuss theories at CSCW events has proven a perpetual challenge. This workshop takes up this cause by facilitating an open-ended discussion about how diverse strands of social theory not only align with but support innovative CSCW research. The workshop will focus on three guiding questions: How, when, and to what end can social theory benefit CSCW research? What recent developments in social theory could be especially impactful for CSCW research today? What can CSCW research contribute to social theory? With an aim to building a new community of practice, the workshop will provide an open forum for scholars and practitioners to probing the merits and limitations of social theory for CSCW research. We welcome participants with diverse theoretical interests, ranging from organizational theory to intersectionality, social materiality to pragmatism, practice theory, and beyond."
Jason Dedrick,"Who captures value from science-based innovation? the distribution of benefits from GMR in the hard disk drive industry -- We analyze the discovery of giant magneto-resistance (GMR) and its development and commercialization by the global disk drive industry to answer the question of ""Who captures the benefits from innovation in a global innovation system?"" We assess the returns to the scientists, firms, and countries associated with GMR. We find that the French and German scientists that discovered GMR and their labs benefited by receiving the Nobel Prize and small licensing fees. The firm that first commercialized the technology, IBM, captured profits from selling hard disk drives and magnetic heads using GMR. Other hard disk drive and head manufacturers based in the U.S. and Japan were able to quickly assimilate the technology and catch up with IBM. France and Germany reaped limited returns due to the lack of domestic firms with the absorptive capacity to commercialize GMR. The U.S. and Japan benefited from the success of their firms in commercializing GMR, as did other countries which were part of the global value chains of those companies. Consumers and firms that incorporated hard drives in their products ultimately benefited from cheaper hard drives with greater capacity. These findings illustrate the importance of absorptive capacity at the firm and national level in capturing benefits from innovation. They also show that the benefits to first mover firms can be short-lived in a competitive industry with open transfer of knowledge and limited appropriability regimes. Finally, they show that the location of jobs and wages associated with innovative products depends on the structure of the global value chains of leading firms.; The distribution of value in the mobile phone supply chain -- The supply chains of the mobile phone industry span national and firm boundaries. To analyze how value is distributed among the participants, a framework based on theories of firm strategy is applied, and a novel methodology is used to measure value capture in three phone models introduced from 2004 to 2008. The research shows that carriers capture the greatest value (in terms of gross profit) from each handset, followed closely by handset makers, with suppliers a distant third. However, the situation is reversed in terms of operating profit. Carriers shoulder the burden of network installation, maintece, and upgrading, which absorbs much of the value from their subscription fees. Handset maker nationality, which may also influence supplier choice, is a key determit of the geographic distribution of value capture. The results are also used to estimate the relationship of handset subsidies to carrier profits, which has been an issue of concern for antitrust authorities in several countries. The analysis shows how the framework can be used to calculate how much service charges might be inflated to cover the subsidies.; Wind Energy -- An analysis of the private and social costs of wind versus natural gas finds that wind energy is competitive when all costs are considered. The wind energy industry also provides tens of thousands of well-paying jobs in the U.S. State and federal support appear to be warranted. At the federal level, a production tax credit with a multi-year phase-down would provide certainty to investors and limit the cost to taxpayers.; Market Making in the Personal Computer Industry -- In this chapter, Jason Dedrick and Kenneth L. Kraemer analyze a transformation in the personal computer (PC) industry. In the traditional structure of the PC industry, PCs were marketed through a variety of channels from direct sales forces, to corporate resellers and electronic superstores. The connection between the PC manufacturer and the final consumer was weak (via advertising) or non-existent. In the mid-1990s, a major shift began in the US market toward direct sales of PCs, led by Dell Computer, which allowed PC makers better to match demand and supply. Dell Computers pioneered a new type of PC maker, which was basically as an assembler of parts made by contract manufacturers and assembled according to the consumers' specifications. This approach cut out the distributor and retailer, putting the PC maker/brand-name merchandiser in the role of market maker. Direct sales accounted for over half of all PC sales by 2005, dominating the corporate market and augmented by the consumer acceptance of e-commerce. The direct sales model has made smaller inroads outside the USA. Currently, there are three major retail models in the US PC consumer market. The first is the traditional indirect model and the second is the PC maker as retailer. The third, which might be called the retailer as PC maker, includes the private label brands sold by some retailers, such as Wal-Mart and CompUSA, and local ""white-box"" makers that sell primarily to small businesses. In terms of impacts on suppliers, PC makers have adopted just-in-time practices and moved to vendor-owned inventory to reduce costs. As PC firms have focused on retailing and marketing, they have outsourced even new product development to a contingent of original design manufactures, mostly in Asia.; Strategic orientation in the globalization of software firms -- In the search for profits, software firms are globalizing their development activities. Some firms achieve greater profits by becoming more efficient, whereas others do so by reaching new markets; some do both. This paper creates an a priori typology of strategies based on the extent to which firms are focused on operational improvement or market access, have a dual focus or are unfocused. We find that firms with these strategies differ in degree of internationalization, organization of offshoring and performance outcomes related to offshoring. Market-oriented firms receive a greater proportion of their total revenue from sales outside the U.S., showing a greater international orientation. They keep more of their offshore development in-house via captive operations. They also are most likely to report increased non-U.S. sales as a result of offshoring. On the other hand, operations-oriented firms have lower levels of international sales, are more likely to go offshore via outsourced software development, and achieve greater costs savings and labor force flexibility as a result of offshoring. Operations-oriented firms also face more obstacles in offshoring, perhaps because of their reliance on outsourcing. Dual focus firms generally achieve some of the best of both strategies, whereas unfocused firms achieve lower cost benefits. The research shows that it pays to have a well-defined strategy for going offshore, and that firms with an explicit strategy are more likely to achieve performance consistent with their strategy. It further shows that captive and outsourced offshoring result in different obstacles and outcomes. In general, market-oriented firms that use captive offshoring versus outsourced offshoring perform better in developing non-U.S. sales.; Information technology and productivity in developed and developing countries -- Previous research has found that information technology (IT) investment is associated with significant productivity gains for developed countries but not for developing countries. Yet developing countries have continued to increase their investment in IT rapidly. Given this apparent disconnect, there is a need for new research to study whether the investment has begun to pay off in greater productivity for developing countries. We analyze new data on IT investment and productivity for 45 countries from 1994 to 2007, and compare the results with earlier research. We find that upper-income developing countries have achieved positive and significant productivity gains from IT investment in the more recent period as they have increased their IT capital stocks and gained experience with the use of IT. We also find that the productivity effects of IT are moderated by country factors, including human resources, openness to foreign investment, and the quality and cost of the telecommunications infrastructure. The academic implication is that the effect of IT on productivity is expanding from the richest countries into a large group of developing countries. The policy implication is that lower-tier developing countries can also expect productivity gains from IT investments, particularly through policies that support IT use, such as greater openness to foreign investment, increased investment in tertiary education, and reduced telecommunications costs.; A dynamic model of offshore software development -- As the offshoring of knowledge work has accelerated, theoretical models to explain the phenomenon have not kept up. Most theoretical models assume a static transactional relationship from various factors to a binary offshoring decision. Such models do not take into account the mix of sourcing choices at the level of a firm, nor do they consider dynamic changes over time. To help fill these gaps, we use five case studies on offshore migration of software work by major US companies. Data were collected from senior executives. We use these data to develop a dynamic conceptual model that incorporates three factor groupings which collectively help explain offshore sourcing outcomes: (1) economic factors; (2) the nature of the development activity; and (3) managerial capabilities and practices. Importantly, the model includes five feedback loops among sourcing decisions, sourcing mix, and these three factors. Thus, the relationships in the model are not unidirectional, nor static; rather, they are iterative and dynamic, involving feedback loops, learning, and cumulative effects over time. In this dynamic model, the sourcing 'mix', a continuously changing offshore portfolio, is a key firm-level dependent variable, closer to the economic concept of a 'stock' measure that represents the cumulative effect of sourcing decisions over time. This variable may be measured in different ways, for instance as the amount of work done offshore, or the number of workers employed offshore.; Green IS -- While public awareness of environmental sustainability is growing, there is concern about the economic costs of shifting to a greener economy. In the case of climate change, a critical issue is the relationship of economic output to greenhouse gas emissions, which has been labeled carbon productivity. Increasing carbon productivity means that economic growth can be sustained while emissions are reduced. Information technology has great potential to enhance carbon productivity, as IT is used to increase the energy efficiency of buildings, transportation systems, supply chains and electrical grids. On the other hand, the production and use of computers is a fast-growing component of global energy consumption and greenhouse gas emissions, a fact that must be balanced against the benefits of IT use. Green IS refers to the use of information systems to achieve environmental objectives, while Green IT emphasizes reducing the environmental impacts of IT production and use. This article focuses primarily on Green IS. It reviews existing Green IS research, presents a model of IT investment and carbon productivity, and lays out suggestions for future research.; Impacts of internal and interorganizational information systems on the outsourcing of manufacturing -- Drawing on transaction cost economics, this paper looks at the relationship of IT use to the outsourcing of manufacturing using survey data from US manufacturers. We find that greater use of interorganizational systems (IOS) is associated with greater outsourcing, but we do not find any main effects between internal IT and outsourcing. A negative interaction effect is found between measures of internal IT and IOS, suggesting that the two may be substitutes rather than complements. This distinction between internal IT and IOS, and the relationship of the two, offers scholars a more nuanced understanding of the nature and impacts of IT. It provides managers insight into how different types of IT can support different sourcing options.; Erratum to -- ; Adoption of smart grid technologies by electric utilities -- Incorporation of information and communications technologies has the potential to reduce the environmental impacts of electricity generation and distribution while improving the quality, reliability and efficiency of electricity supply. However, integrating smart grid technologies presents major organizational challenges to utilities, and adoption rates are still low. New knowledge is needed on organizational innovation in response to this potentially disruptive technology in the context of a regulated monopoly. This study examines factors influencing the adoption of smart grid technologies using data from 15 interviews with 12 U.S. utilities. The study provides useful insights and implications for utilities and regulators.; Learning strategies in smart grid adoption -- ; China's indigenous innovation policy -- Multinational corporations seeking access to China's burgeoning consumer markets and human resources are establishing R&D centers in the country and developing ways to thread a path through its complex innovation policies.; One Laptop Per Child (OLPC) -- This study applies concepts about computerization movements (CMs) to a case study of the diffusion of innovation in the developing world and thereby to draw lessons for undertaking similar technology projects. We identify the key characteristics of a computerization movement in the scholarly literature and then review the One Laptop Per Child (OLPC) Project in terms of each, identifying where OLPC adds new understanding about CMs. The OLPC project is an example of a computerization movement that has launched a new generation of low-cost computers in the developing world, while failing in its own ambitious goals. The OLPC project provides insights into the nature of computerization movements, in particular the process of mobilization, the diffusion of innovations in the developing world, and the overlap of multiple movements. OLPC's limited success to date illustrates the importance of having: (1) ficial resources beyond deployment for economic sustainability, (2) local skills, infrastructure and deployment capability for operational sustainability, and (3) a replicable and scalable deployment model for ease of implementation across many sites.; Innovation and job creation in a global economy: the case of Apple's iPod -- ; Sustainable Urban Community Eco-Feedback through Simulation-enabled Performance Dashboards -- ; Risks, benefits, and control of information -- Smart electric meters collect data on electricity use to potentially improve efficiency for utilities, shape power consumption, and ultimately reduce greenhouse gas emissions. Consumer groups and experts have raised concerns about privacy, as smart meters can provide detailed information about activity within the home. This study examines privacy beliefs of U.S. consumers using qualitative data from focus groups together with experimental data from a national online survey of utility customers. Exploratory analysis of focus group findings suggested that consumers who felt in control of their data perceived fewer risks and more benefits from having access to the data. Participants in the online experiment saw greater risk and less benefit when advised that smart meters could be used to raise prices under time-of-use pricing. Participants also saw greater risk when the utility shared customer data with a third party. Risks and benefits influenced perceptions of control. These findings accord with several information privacy frameworks adding new insights about consumers' perceived control over their energy data. The findings can inform utility companies and policymakers with respect to giving consumers more control over their data, reducing consumers' privacy concerns, communicating benefits of smart meter data, and providing accurate information about the risks.; Value capture in global production networks -- In today's global electronics industry, lead firms and suppliers of key components capture greater value than contract manufacturers. Using data from the Taiwanese Stock Exchange from 2002 to 2009, this research aims to examine if the pattern of value capture in the global electronics industry holds for Taiwan. We also test the impacts of research and development (R&D) spending on firm profitability and returns. Our results show that lead firms and component suppliers capture higher gross profits from their R&D spending, compared to contract manufacturers. However, contract manufacturers have higher return on equity. Component suppliers' return to R&D as measured by return on equity is lower than contract manufacturers. These findings suggest that component suppliers capture higher profits as lead firms do, but the cost of R&D for component suppliers is so high that their returns on investment are not as great as contract manufacturers. This also suggests that Taiwanese component suppliers are unable to create entry barriers or gain pricing power from their R&D investments.; Value Capture in the Global Electronics Industry -- This research asks who captures the greatest value in the global electronics industry by testing the concept of the ""smiling curve"", which predicts that the greatest value is captured by upstream and downstream firms, and the lowest value is captured in the middle of the value chain. We test the concept using the Electronic Business 300 data-set for 2000-2005. We find that lead firms and component suppliers earn higher gross margins and net margins compared to contract manufacturers. However, the differences are minimal for return on assets (ROA) and return on equity (ROE). We also find that active component suppliers gain higher profits than passive component suppliers. These findings suggest that the smiling curve is right if value is defined in terms of gross margins, but the cost of sustaining a position on either end of the curve is so high that returns on investment are similar across the curve.; R&D and firm performance in the semiconductor industry -- While the semiconductor industry is still dominated by large vertically integrated firms, fabless firms, which outsource their manufacturing, are gaining market share. Fabless firms are considered to have an advantage in product innovation, as they can focus their innovation efforts on chip design and can benefit from investments in process innovation made by their manufacturing partners. However, there is little empirical evidence of the performance of fabless firms compared to vertically integrated firms. This research empirically examines the relationship between R&D and the ficial performance of fabless and vertically integrated firms from 2000 to 2010. Our results show that fabless firms maintain higher gross and net margins, earn a higher return on assets (ROA) and have greater intangible value (Tobin’s q) than vertically integrated firms when controlling for size, capital intensity and R&D ratio (R&D/sales). This supports the argument that fabless firms achieve greater performance by focusing on one part of the innovation process. The relationship of R&D ratio to net margin is negative for the whole sample, suggesting that the industry may be overinvesting in R&D. Notably, the negative relationship is greater for fabless firms, which spend a higher amount of their sales on R&D. The relationship of R&D ratio to ROA and Tobin’s q is negative, and there is no significant difference between fabless and integrated firms. We conclude that fabless firms outperform integrated firms overall, but are somewhat worse in terms of increasing profits and creating value from their R&D investments.; An exploratory study of the determinants of information technology hardware production -- This research examines empirically factors influencing IT hardware production by employing a country-level data set for 1985–2009. Our results show that IT hardware production is driven by various country-level factors, but the impacts of these factors differ for two types of IT hardware. Electronic data processing (EDP) production has shifted to low GDP countries where wage levels are low, and a large portion of EDP produced in these countries tend to be exported to high GDP countries where demand is high. While the gap has decreased, however, medical and industrial equipment (MIE) production is still largely done in advanced economies. These findings imply that losing the manufacturing base in the U.S. might not be an issue for certain types of products, such as EDP, but it could be a serious issue for MIE. Thus, policies must be industry specific; a ‘one-size-fits-all’ policy would not work for the global IT industry.; Global diffusion of the Internet XVI: the role of economic development and firm internationalization in internet business practices -- ; Learning from adopters -- Smart grid represents a perfect example of using green technologies to realize economic, societal and environmental sustainability. Yet outcomes from smart grid use can be different, and there lacks an adequate understanding of what factors are critical for utilities to achieve maximum value from smart grid. We use multiple case studies comparing utilities with different sizes, ownership forms, state regulatory environments, and market structures to identify factors influencing smart grid value achievement. We find on-going top management support, active project management and change management, adequate IT capabilities, good stakeholder relationships and continuing grid-improving efforts are critical factors. We also find that size and ownership forms do not moderate utilities' performance but differences in state regulatory environments shape how much value utilities can gain from smart grid."
Jeffrey Hemsley,"Automated Diffusion? Bots and Their Influence During the 2016 US Presidential Election -- In the 2016 U.S. Presidential election, some candidates used to automated accounts, or bots, to boost their social media presence and followership. Categorizing all automated accounts as “bots” obfuscates the role different types of bots play in the spread of political information in election campaigns. Exploring strategies for automated information diffusion helps scholars understand and model online political behavior. This paper presents an initial effort aimed at understanding the disparate roles of bots in diffusion of political messages on Twitter. Having collected over 300 million tweets from candidates and the public from the U.S. presidential election, we use three OLS regression models to explore the strategic advantages of different types of automated accounts. We approach this by analyzing retweet events, testing a series of hypotheses regarding bots’ influence on the size of retweet events, and the change in candidates’ followers. Next, we develop an estimator to analyze the spread of information across the networks, demonstrating that, while ‘benevolent bots’ serve as overt information aggregators and have an effect on information diffusion, “nefarious bots” act as false amplifiers, covertly mimicking the spread of online information with no effect on diffusion. Making this important distinction allows us to disambiguate the concept of “bots” and reach a more nuanced and detailed understanding of the role of automated accounts in information diffusion in political campaigning online.; Automated diffusion? Bots and their influence during the 2016 U.S. Presidential election -- In the 2016 U.S. Presidential election, some candidates used to automated accounts, or bots, to boost their social media presence and followership. Categorizing all automated accounts as “bots” obfuscates the role different types of bots play in the spread of political information in election campaigns. Exploring strategies for automated information diffusion helps scholars understand and model online political behavior. This paper presents an initial effort aimed at understanding the disparate roles of bots in diffusion of political messages on Twitter. Having collected over 300 million tweets from candidates and the public from the U.S. presidential election, we use three OLS regression models to explore the strategic advantages of different types of automated accounts. We approach this by analyzing retweet events, testing a series of hypotheses regarding bots’ influence on the size of retweet events, and the change in candidates’ followers. Next, we develop an estimator to analyze the spread of information across the networks, demonstrating that, while ‘benevolent bots’ serve as overt information aggregators and have an effect on information diffusion, “nefarious bots” act as false amplifiers, covertly mimicking the spread of online information with no effect on diffusion. Making this important distinction allows us to disambiguate the concept of “bots” and reach a more nuanced and detailed understanding of the role of automated accounts in information diffusion in political campaigning online.; Big data, big metadata and quantitative study of science -- Large cyberinfrastructure-enabled data repositories generate massive amounts of metadata, enabling big data analytics to leverage on the intersection of technological and methodological advances in data science for the quantitative study of science. This paper introduces a definition of big metadata in the context of scientific data repositories and discusses the challenges in big metadata analytics due to the messiness, lack of structures suitable for analytics and heterogeneity in such big metadata. A methodological framework is proposed, which contains conceptual and computational workflows intercepting through collaborative documentation. The workflow-based methodological framework promotes transparency and contributes to research reproducibility. The paper also describes the experience and lessons learned from a four-year big metadata project involving all aspects of the workflow-based methodologies. The methodological framework presented in this paper is a timely contribution to the field of scientometrics and the science of science and policy as the potential value of big metadata is drawing more attention from research and policy maker communities.; Mixed-initiative social media analytics at the World Bank -- This paper discusses a project that studied the relationship between citizen trust and social protest using visual analysis of approximately 11 million sentiment classified Tweets from the period of the 2014 Brazilian World Cup. The results of the study reveal that the 2014 World Cup protests in Brazil sprang from a wide range of grievances coupled with a relative sense of deprivation compared with emergent comparative 'standards'. This sense of grievance gave rise to sentiments that activated online protest that may have led to other forms of social protest, such as demonstrations. The paper describes an innovative approach to big data analytics-mixed initiative social media analytics - and discusses the potential of using big data in social science research of this kind, as well as some of the open methodological, technical and ethical issues still to be addressed.; Introduction to the 2017 international conference on social media and society -- This is an introduction to the Proceedings of the 2017 International Conference on Social Media and Society, an annual gathering of leading social media researchers from around the world. The conference is organized by the Social Media Lab (http://socialmedialab.ca) at Ryerson University. Now, in its 8th year, the 2017 conference in Toronto, Canada (July 28-30) features an intensive three-day program showcasing 24 doubleblind peer reviewed full papers, 34 double-blind peer reviewed work-in-progress (WIP) papers, 8 workshops, 8 panels, and 35 posters. These papers were selected from research submitted by nearly 400 scholars from 43 countries and territories, working in many fields including Communications, Computer Science, Education, Journalism, Information, Management, Political Science, and Sociology. The Proceedings feature a total of 58 papers including both full and WIP papers.; Introduction to the 2018 international conference on social media and society -- This paper provides an introduction to the 2018 Proceedings of the International Conference on Social Media and Society (#SMSociety). The conference is an annual gathering of leading social media researchers, policy makers, and practitioners from around the world. Now in its 9th year, the 2018 conference is hosted by the Centre for Business Data Analytics at the Copenhagen Business School, Copenhagen, Denmark. The Proceedings features a total of 60 papers, including both full and work-in-progress papers (the acceptance rate for 2018 is 43%).; Introduction to the 2019 International Conference on Social Media & Society -- This paper provides an introduction to the Proceedings of the 2019 International Conference on Social Media and Society (#SMSociety). The conference is an annual gathering of leading social media researchers, policy makers, and practitioners from around the world. Now in its 10th year, the 2019 conference is hosted by the Social Media Lab at the Ted Rogers School of Management at Ryerson University in Toronto, Canada. The Proceedings features a total of 26 papers (the acceptance rate is 42%).; Going Viral -- ; Studying the viral growth of a connective action network using information event signatures -- ; Retweets for policy advocates -- Technological advances have increasingly automated tasks that have hitherto been done by humans. The disruption to the labor market is expected to grow as more and more jobs are lost to automation. Society would benefit from the open discussion of alternative policy approaches, such as Universal Basic Income (UBI), that can alleviate social tensions related to joblessness. In this study, we examine tweets related to the discussion of UBI in an effort to understand the types of messages most likely to spread information about policy innovations, and most likely to bring new voices into the discussion. We find that messages that resonate with users are more likely to reach new audiences and bring new actors into the discussion space. Our work offers prescriptions for policy advocates, and provides insights for social scientists studying Twitter and policy and information diffusion.; Call to retweet -- Twitter allows political candidates to broadcast messages directly to the public, some of which spread virally and potentially reach new audiences and supporters. During the 2014 U.S. gubernatorial election, 74 candidates posted 20,580 tweets, of which, 10,946 were retweeted a total of 139,315 times. Using content analysis, automated classification and regression analysis, we show that actors with different levels of network influence tend to promote different types of election content, but that the convergence of their choices and actions lead to information flows that reach the largest audiences. We also show that actors with middle-level influence, in terms of the number of followers they have, tend to be the most influential in the diffusion process. Our work provides empirical support for the theoretical framework of negotiated diffusion, which suggests that information flows are the result of the convergence of top-down forces (structures and powerful gatekeepers) and bottom-up forces (collective sharing of actors with varying degrees of influence).; Tweeting to the Target -- This paper reports on a mixed-methods (i.e., content analysis, machine learning, and quantitative analysis) study of Twitter use among 74 U.S. gubernatorial candidates during the 2014 election. In extending the theory of controlled interactivity, this article focuses on politicians’ use of the @mention where we detail differing messaging strategies when candidates mention themselves versus their opponents, and between incumbents and challengers. Results suggest that candidates use the @mention feature as a subtle audience targeting mechanism. Our work also offers a methodological contribution by showing that machine-learning models perform better when context variables are included.; Dribbble: Exploring the Concept of Viral Events on an Art World Social Network Site -- While virality is a much-studied topic on popular social media sites, it has been rarely explored on sites like Dribbble, a social networking site for artists and designers. Using a mixed-method approach, we explore virality from a user-centric perspective. Interviews with informants confirm that viral-like events do exist on Dribbble, though what spreads are stylistic choices. While what spreads is different than on other platforms, our work suggests that the mechanics that drive these events are similar, suggesting an underlying social phenomenon that is reflected in different ways on different platforms. Our results are supported by regression modeling using variables identified by our informants. Our work contributes to social media studies since smaller sites like Dribbble are rarely studied, particularly using mixed methods approaches, as well as to the body of research around information diffusion and viral events.; Tweets That Resonate -- Social media are an important space for people to discuss novel policy innovations. In particular, Twitter, whose user base is skewed toward those who disproportionately affect news coverage, and by extension the public agenda, represents a particularly useful platform for policy advocates wishing to grow their audience. This article extends theoretical understandings of information flows and the growth of networked discussion spaces by examining the online discussion space around a Universal Basic Income (UBI), which has been proposed to alleviate social tensions relating to joblessness resulting from technological advances. Using content analysis and statistical methods, we show that tweets in the UBI discussion space that inform others are the most likely to be shared, but tweets that emotionally resonate with users are the most likely to reach new audiences and therefore bring new actors into the discussion space. These findings contribute to the literature on viral events and dynamic networks, providing insight into how policies like UBI are discussed and diffuse on social media platforms like Twitter.; Political issues that spread -- We present preliminary results from analysis of what topics presidential candidates tweeted about and the public’s response to those tweets in the form of retweets. Using exploratory data analysis and simple correlations to explore the 4,754 tweets posted by U.S. presidential candidates over the last 3 months of the 2016 Election, we find a mismatch between the topics that candidates tweet about the most and the topics that the public retweets the most. We discuss the possible reasons for the mismatch and outline future work that will include a similar analysis with Facebook data and a breakdown by party.; Viral design -- Virality is a much-studied topic on popular social media sites, but has been rarely explored on niche sites. Dribbble is a niche social networking site for artists and designers with over 600,000 users. Using a mixed-method approach, we explore virality from a user-centric perspective. Interviews confirm that viral-like events do exist on Dribbble. Through interviews we identify the measures and possible driving factors of viral-like events. While what spreads is different than on other platforms, our work suggests that the measures and mechanics that drive these events are similar. These similarities reflect fundamental human behavior underlying social phenomenon across different platforms. Our results are supported by regression modeling using variables identified by our informants. Smaller sites like Dribbble are rarely studied, so our work contributes to social media studies, particularly using mixed methods approaches, and to the body of research around information diffusion and viral events.; Social Media for Social Good or Evil -- In the heyday of social media, individuals around the world held high hopes for the democratizing force of social media; however, in light of the recent public outcry of privacy violations, fake news, and Russian troll farms, much of optimism toward social media has waned in favor of skepticism, fear, and outrage. This special issue critically explores the question, “Is social media for good or evil?” While good and evil are both moral terms, the research addresses whether the benefits of using social media in society outweigh the drawbacks. To help conceptualize this topic, we examine some of the benefits (good) and drawbacks (evil) of using social media as discussed in eight papers from the 2017 International Conference on Social Media and Society. This thematic collection reflects a broad range of topics, using diverse methods, from authors around the world and highlights different ways that social media is used for good, or evil, or both. We conclude that the determination of good and evil depends on where you stand, but as researchers, we need to go a step further to understand who it is good for and who it might hurt.; Followers Retweet! The Influence of Middle-Level Gatekeepers on the Spread of Political Information on Twitter -- Twitter allows political candidates to broadcast messages directly to the public, some of which spread virally, potentially reaching new supportive audiences. During the 2014 U.S. gubernatorial election, 74 candidates for State Governor posted 20,580 tweets, of which 10,946 were retweeted almost 140,000 times. By analyzing a collection of tweets posted by gubernatorial candidates that were classified by machine learning into categories of message types, we find that while candidates tend to post tweets that advocate for themselves the most, the public is more likely to retweet attack messages and messages labeled as call-to-action. As measured by number of retweets, call-to-action tweets tend to reach the broadest audience. We also find that middle-level gatekeepers, those with between 1,800 and 26,000 followers, tend to have the most influence over the flow of political information. Since retweets tend to bring new followers, these findings suggest that politicians wishing to grow their audience may benefit from posting more call-to-action and attack messages, and that candidates may wish to find ways to actively enlist the support of middle-level gatekeepers.; Scratching a Niche -- Researchers have been studying the viral flow of information since the late 1990s, but this work has mainly focused on big sites like Twitter and Facebook. However, to comprehensively explore social phenomena such as virality requires us to look beyond the domit networks. This study addresses this by looking at how users think about virality on Dribbble, a social network site with around 600,000 users that was created in 2009 for designers to showcase and get feedback on their work and to connect clients to design talent. Interviews confirm that viral-like events do exist on Dribbble. Our informants suggest that what spreads on Dribbble are elements of design (e.g., color palettes, line styles, textures), and they identify a number of factors they believe drive these viral-like events, which are the same kinds of factors that drive virality on larger sites. We briefly discuss how Dribbble feeds the gig economy in the creative industry and how virality becomes an important path for designers in a competitive environment. This work makes a contribution to the study of virality by focusing a small niche social media site and by looking at how users perceive and think about viral events.; Identifying political topics in social media messages -- In this paper, we introduce a lexicon-based method for identifying political topics in social media messages. After discussing several critical shortcomings of unsupervised topic identification for this task, we describe the lexicon-based approach. We test our lexicon on candidate-generated campaign messages on Facebook and Twitter in the 2016 U.S. presidential election. The results show that this approach provides reliable results for eight of nine political topic categories. In closing, we describe steps to improve our approach and how it can be used for future research on political topics in social media messages.; The open community data exchange -- While online behavior creates an enormous amount of digital data that can be the basis for social science research, to date, the science has been conducted piecemeal, one internet address at a time, often without social or scholarly impact beyond the site's own stakeholders. Scientists lack the tools, methods, and practices to combine, compare, contrast and communicate about online behavior across internet addresses or over time. In response, we are building the infrastructure for computational social scientists, social scientists, and citizens to make corresponding advances in our understanding of online human interactions. In this paper, we present our effort to specify the Open Community Data Exchange (OCDX) metadata standard to describe datasets, as well as the necessary infrastructure for creating, editing, viewing, sharing, and analyzing manifests. The purpose of this paper is to communicate the current state of our project and represent our current findings through our ongoing engagement with the scientific community and to engage in dialog among computational social scientists.; Fifteen Minutes of Fame: The Power of Blogs in the Lifecycle of Viral Political Information -- ; Social media, U.S. Presidential campaigns, and public opinion polls -- The use of digital technologies by political campaigns has been a topic of scholarly concern for over two decades. However, these studies have been mostly focused on analyzing the use of digital platforms without considering contextual factors of the race, like public opinion polling data. Polling data is an important information source for both citizens and candidates, and provides the latter with information that might drive strategic communication. In this paper, we explore the relationship between the use of social media in the 2016 U.S. Presidential Elections and candidates' standing in public opinion polls focusing on the surfacing and primary stages of the campaign. We are also interested in understanding whether candidates use Twitter and Facebook in similar ways. We used automated content analysis to categorize social media posts from all 21 Republican and Democratic candidates that ran for president in 2016. Specifically, we are interested in observing whether a candidate's performance in the polls drives certain communicative strategies, such as the use of attacks and messages of advocacy, as well as the focus on personal image or policy issues.; Social Media, Opinion Polls, and the Use of Persuasive Messages During the 2016 US Election Primaries -- Political campaigns’ use of digital technologies has been a topic of scholarly concern for over two decades, but most studies have been focused on analyzing the use of digital platforms without considering contextual factors of the race, like public opinion polls. Opinion polls are an important information source for citizens and candidates and provide the latter with information that might drive strategic communication. In this article, we explore the relationship between the use of social media in the 2016 US presidential elections and candidates’ standing in public opinion polls, focusing on the surfacing and primary stages of the campaign. We use automated content analysis to categorize social media posts from all 21 Republican and Democratic candidates. Results indicate that a candidate’s performance in the polls drives certain communicative strategies, such as the use of messages of attacks and advocacy, as well as the focus on personal image.; Information affordances -- Emergent social movements benefit from technologies that support the information activities that core actors perform to achieve the goals of the movement. Starting with an information-centric perspective, we use the theoretical lens of information processing, to examine the roles of Twitter affordances during the Occupy movement in solving information problems. Our data is a corpus of tweets from the core actors of the movement, as identified by our extended 1/9/90 rule. Using inferential statistics and network visualization, we show how different Twitter affordances act as mechanisms to resolve information problems in many different ways. Our network visualization shows the ecology of the interactions amongst the core actors, and between the core actors and the public. Our work contributes to the discussion around recent social movements on Twitter and advances the theory of information processing.; Studying Celebrity Practices on Twitter Using a Framework for Measuring Media Richness -- Social media enables the performative actions needed for celebrities to build and maintain audiences. Platforms like Twitter mediate identity construction and interaction with fans while enabling environments that are co-constructed by celebrities, fans, and the platform itself. We use the theoretical lens of media richness to study the ways that different types of celebrities enact “micro-celebrity” by mapping three richness dimensions (contextual, interactional, and informational) into groupings of Twitter’s affordances. Utilizing crowdsourcing and regression analysis, we systematically weigh each affordance and generate richness scores for each dimension, for each tweet. Using these richness scores, we find that performance of different types of celebrity requires different affordance mixtures, and that these mixtures reflect differences in the environments within which celebrities operate. Our research contributes to work at the intersection of Twitter affordances and celebrity studies in new media, and provides a framework for generating richness scores."
Jeffrey M Stanton,"eScience professional positions in the job market -- We have observed the emerging needs of the new information professions in science and engineering disciplines, called ""eScience Professionals."" The purpose of this research is to analyze the job advertisements (ads) of eScience professionals as accessible indicators of the work duties and the worker characteristics required for eScience professional positions by employers. Two hundred job ads were gathered between November 2009 and April 2010 (for 6 months), and then content analysis of job ads including the work environments, the works performed, and the worker competencies required was conducted. This job ads analysis shows the emerging needs of eScience professionals in the job market, and it presents eScience professionals' major work duties and their Knowledge, Skills, Ability, and Others (KSAOs) required.; Enhancing Retention of Future Information Professionals Using Attitude Inoculation -- Employment predictions in the field of Information Systems (IS) vary over time, but employers often report a gap between the available IT workforce and their needs for skilled information professionals. The existence of such gaps raises questions about how college students make decisions about persistence in majors with respect to available information about employment prospects. The main objective of this article is to understand whether and how inoculating messages may help students to maintain pre-existing positive attitudes towards occupational features of the IT profession; to explore why some choose to stay in the information technology disciplines; and to suggest potential solutions to augment the number of those who stay.This research study used Inoculation Theory to hypothesize that students who heard an inoculative message prior to a persuasive message concerning post-graduate employment would show a greater resistance to attitude change than students in a control group, and that there would be a difference in resistance to change based on gender and on program of study.The results of our field experiment showed that significant differences arose among the different groups of students. As hypothesized, the participants in the treatment group had more resistance to attitude change; participants in control groups were more affected by the persuasive message than participants who had received an inoculation treatment. The analyses did not detect significant differences in attitudes based on gender and major. These results have implications for effective retention of future information professionals.; Information security practices in latin america -- In this paper, we present a social/behavioral study of individual information security practices of internet users in Latin America, specifically presenting the case of Bolivia. The research model uses social cognitive theory in order to explain the individual cognitive factors that influence information security behavior. The model includes individuals' beliefs about their abilities to competently use computer information security tools and information security awareness in the determination of effective information security practices. The operationalization of constructs that are part of our research model, such as information security practice as the dependent variable, self-efficacy and information security awareness as independent variables, are presented both in Spanish and English. In this study, we offer the analysis of a survey of 255 Internet users from Bolivia who replied to our survey and provided responses about their information security behavior. A discussion about information security awareness and practices is presented.; Beyond being (t)here -- This literature review discusses the social phenomena that surround and affect the process of making music with a distant collaborator, and probes future directions for this area known as ""computer supported collaborative music"" [3]. Articles were sampled by searching the SCOPUS, EBSCOHOST, IIMP, ACM Digital Library and Google Scholar for abstracts that included the keywords ""collaborative music"" or ""networked music"". From this group of article the author highlights studies that have reported factors that altered the experience of collaborative composition. Preliminary results indicate that novices to music composition can use metaphors, (present in tools that do not replicate face to face interaction) to compose pieces with others without formal music training.; Institutional and individual influences on scientists3 data sharing behaviors -- The objective of this research is to investigate the institutional and individual factors which influence scientists' data sharing behaviors across different scientific disciplines. Two theoretical perspectives, institutional theory and theory of planned behavior, are employed in developing a research model, which shows the complementary nature of the institutional and individual factors influencing scientists' data sharing behaviors. This research uses a survey method to examine to what extent those institutional and individual factors influence scientists' data sharing behaviors in diverse scientific disciplines. The national survey (with 1,317 scientists in 43 disciplines) shows that regulative pressure by journals; normative pressure at a discipline level; and perceived career benefit and scholarly altruism at an individual level have significant positive relationships with data sharing behaviors; and that perceived effort has a significant negative relationship. Regulative pressure by funding agencies and the availability of data repositories at a discipline level and perceived career risk at an individual level were not found to have any significant relationships with data sharing behaviors.; Institutional and individual factors affecting scientists' data-sharing behaviors -- The objective of this research was to investigate the institutional and individual factors that influence scientists' data-sharing behaviors across different scientific disciplines. Two theoretical perspectives, institutional theory, and theory of planned behavior, were employed in developing a research model that showed the complementary nature of the institutional and individual factors influencing scientists' data-sharing behaviors. This research used a survey method to examine to what extent those institutional and individual factors influence scientists' data-sharing behaviors in a range of scientific disciplines. A national survey (with 1,317 scientists in 43 disciplines) showed that regulative pressure by journals, normative pressure at a discipline level, and perceived career benefit and scholarly altruism at an individual level had significant positive relationships with data-sharing behaviors, and that perceived effort had a significant negative relationship. Regulative pressure by funding agencies and the availability of data repositories at a discipline level and perceived career risk at an individual level were not found to have any significant relationships with data-sharing behaviors.; Education for eScience Professionals -- Large, collaboratively managed datasets have become essential to many scientific and engineering endeavors, and their management has increased the need for ""eScience professionals"" who solve large scale information management problems for researchers and engineers. This paper considers the dimensions of work, worker, and workplace, including the knowledge, skills, and abilities needed for eScience professionals. We used focus groups and interviews to explore the needs of scientific researchers and how these needs may translate into curricular and program development choices. A cohort of five masters students also worked in targeted internship settings and completed internship logs. We organized this evidence into a job analysis that can be used for curriculum and program development at schools of library and information science.; Institutional and Individual Influences on Scientists' Data Sharing Behaviors -- Many contemporary scientific endeavors now rely on the collaborative efforts of researchers across multiple institutions. As a result of this increase in the scale of scientific collaboration, sharing and reuse of data using private and public repositories has increased. At the same time, data sharing practices and capabilities appear to vary widely across disciplines and even within some disciplines. This research sought to develop an understanding of this variation through the lens of theories that account for individual choices within institutional contexts. We conducted a total of 25 individual semi-structured interviews to understand researchers’ current data sharing practices. The main focus of our interviews was: (1) to explore domain specific data sharing practices in diverse disciplines, and (2) to investigate the factors motivating and preventing the researchers’ current data sharing practices. Results showed support for an institutional perspective on data sharing as well as a need for better understanding of scientists’ altruistic motives for participating in data sharing and reuse. ; Private Eyes Are Watching You -- Purpose: This study explored reactions to location sensing technologies (LSTs) which enable organizations to track the location and movements of employees, even off-site. In particular, we examined the relationships among two monitoring characteristics (i. e., purpose and control), perceptions of privacy invasion, and monitoring fairness. Design/Methodology/Approach: This study employed a 2 (purpose) × 2 (control) factorial design using 208 college students. Study hypotheses were tested using hierarchical regression. Findings: The ability to control the location sensing device was related to monitoring fairness via privacy invasion, but no support was found for monitoring purpose. Implications: The results underscore the importance of giving employees a sense of control over monitoring and providing them with ""protected spaces"" where monitoring can be avoided. Originality/Value: This study offers the first examination of attitudes toward location sensing technologies.; Analyzing hate speech with incel-hunters' critiques -- The ubiquity of online media services helps to promote free speech but also provides opportunities for the spread of problematic content such as hate speech. A group of individuals known as ""incels"" (involuntary celibates) sometimes use online media services to publish hateful content. To expose and condemn incel hate speech, other individuals, sometimes called ""incel hunters"" create online communities where they critique screenshots of content posted by incels. In this paper, using 18,187 posts collected from a subreddit named r/IncelTears, we explore the potential for transforming screenshots of incel hate speech and oppositional statements into training data that could be used as the basis for automated or semi-automated content moderation tools.; Spreading the word -- This poster presents the initial findings of an approach used to analyze a faculty member's direct and relevant indirect networks in order to develop connections with academic peers of similar research interests to expand the visibility and awareness of the faculty member's research through the use of an online collaborative group. It is anticipated that by developing this group, where sharing of publications and ideas is promoted, that the faculty member will increase their virtual research footprint through the awareness and referencing of their publications.; Events, emotions, and technology -- Purpose: The purpose of this article is to understand the relationship between emotional salience and workplace events related to technology change by using a combination of key features of two popular psychological theories - regulatory focus theory and affective events theory - to view the change process in diverse settings. Design/methodology/approach: This paper is based on analysis of 18 months of qualitative interview data (n = 52 respondents) collected before, during and after the introduction of three different new technologies in three organizations - a hospital, a manufacturing facility, and a psychological counseling center. The mixed methods approach combined descriptive case studies and a structured coding approach derived from a synthesis of the two theories with which the transition processes at each organization were examined. Findings: Employees with a so-called promotion-focused orientation were more likely to accept an IT change and the events related to it. Organizational cultures and the staging of events play a role in individuals' affective reactions and behavior. The use of the framework is promising for illuminating the role of emotions, the timing of change events, and subsequent behavior in response to organizational change. Research limitations/implications: The variety of types of organizations and job types represented, as well as the types of IT change proposed in each, provides a rich sample of diverse motivations and scenarios. Further development of the relationships between the timing of organizational events and regulatory focus is needed. Practical implications: The proposed framework suggests a shift in emphasis away from beliefs and towards emotionally relevant events. The findings suggest consideration of two distinct motivational aspects of both new and old technology. A peak in emotional events related to training indicates that an organization must actively manage how the plans, strategies, and communications with regard to training affect workers' beliefs and expectations. Originality/value: The paper highlights how an emphasis on emotionally relevant events and attention to the regulatory focus involved in interpretation of those events could provide the basis for new approaches to organizational interventions. Interventions should focus on facilitating situations where individuals can frame relevant transition events with a promotion focus.; Data mining -- ; ICAO and the biometric RFID passport -- ; Interdisciplinary data science education -- Data scientists are information professionals who contribute to the collection, cleaning, transformation, analysis, visualization, and curation of large, heterogeneous data sets. Although some conceptions of data science focus primarily on analytical methods, data scientists must also have a deep understanding of how project data were collected, preprocessed and transformed. These processes strongly influence the analytical methods that can be applied, and more importantly how the results of those methods should be interpreted. In the present chapter we provide background information on educational challenges for data scientists and report on the results of a workshop where experts from the information field brainstormed on the educational dimensions of data science. Results of the workshop showed that data scientists must possess a breadth of expertise across three areas - curation, analytics, and cyber-infrastructure - with deep knowledge in at least one of these areas. Workshop participants also underscored the importance of domain knowledge to the success of the data science role. Additionally, the workshop highlighted a factor that differentiates data science from other professional specialties: the emphasis on serving the data needs of information users and decision makers.; Got MOOC? -- Media reports concerning massive open online courses (MOOCs) have vacillated between talk of an educational revolution and disillusionment with an over-hyped instructional technology. This paper reports how a group of university faculty and staff designed and delivered a MOOC to more than 800 students. The delivery of the MOOC was a labor-intensive, costly process that resulted in a variety of educational and institutional outcomes. The case report contains lessons for other groups who may have an interest in delivering a MOOC. The paper concludes with an interpretation of the significance of MOOCs for higher education.; InfoSec in synthetic worlds -- From the time of clay tablets and abacuses, people have always sought new technological methods for supporting the organization and conduct of work. A new possibility in this realm has arisen over recent years in the form of threedimensional immersive environments, or synthetic worlds. In a synthetic world, each user has a representation of the self, called an “avatar,” that can be used to navigate through a realistic 3D environment rendered on a display. Although the idea of using a synthetic world to organize a large-scale work activity might seem like anathema to those whose jobs involve mainly physical resources, consider that more than 99 percent of the information produced by the human race last year was originated in digital form. Many contemporary theories and models of organizations focus primarily on the information management and processing capabilities of the organization and consider the movement of physical materials an important, but secondary concern. In this regard, virtual spaces are plausible as a substrate for functioning organizations. Indeed virtual spaces are, in effect, constructed from information. Whenever information is handled by humans, however, there is the possibility of mishandling and malfeasance. When appropriately motivated, people will hide information, corrupt information, send information to the wrong person, or otherwise misuse the information. In a synthetic world, which exists for exchange and manipulation of information, these possibilities for malfeasance could be devastating. Fortunately, we have a substantial history to draw upon because the creation of synthetic worlds predated the creation of the Internet. The first multi-user information interaction environments were developed in the 1970s, long before the Internet caught on as a public phenomenon. These early environments were called MUD s (multi-user dungeons) and almost from the start, security issues were an important consideration. This chapter reviews the history of MUD s, MOO s (MUD s object oriented) and MMOGs (massively multiplayer online games) for important clues about the future of security in virtual spaces. The chapter then provides an overview of areas where security researchers and practitioners should focus their efforts in these areas. As with other contributions to this volume, this chapter begins with a future scenario that highlights possible future security problems in virtual space.; Sensing big data -- ; Burdens of Proof -- ; Information nation -- ; Reasoning with data -- ; Education for eScience professionals: Job analysis, curriculum guidance, and program considerations -- ; Big Data and the Library Professional --  The news is full of headlines describing the “rise of big data” and the consequent need for data scientists and big data professionals. Yet, as stewards of vast troves of printed and electronic information for generations, haven’t librarians always dealt with big data? The attention we give to this question has the potential to influence the future of the library as well as the long-term viability of librarianship as a profession. ; Coordination between an Information Technology Department and a Human Resources Department -- These readings provide students with a depth of content and analytical perspective not found in other textbooks. Organized into five units, Planning, Policy, People, Projects and Protection, each unit includes items such as academic research papers, summaries of industry practices or written cases to give students valuable resources to use as industry professionals.; Evaluating Equivalence and Confirming the Null in the Organizational Sciences -- Testing and rejecting the null hypothesis is a routine part of quantitative research, but relatively few organizational researchers prepare for confirming the null or, similarly, testing a hypothesis of equivalence (e.g., that two group means are practically identical). Both theory and practice could benefit from greater attention to this capability. Planning ahead for equivalence testing also provides helpful input on assuring sufficient statistical power in a study. This article provides background on these ideas plus guidance on the use of two frequentist and two Bayesian techniques for testing a hypothesis of no nontrivial effect. The guidance highlights some faulty strategies and how to avoid them. An organizationally relevant example illustrates how to put these techniques into practice. A simulation compares the four techniques to support recommendations of when and how to use each one. A nine-step process table describes separate analytical tracks for frequentist and Bayesian equivalence techniques."
Jeffrey Saltz,"Modular design of data-driven analytics models in smart-product development -- Data-driven analytics models have been built as critical components of a smart product to enable product autonomy and intelligence. Due in part to the dynamic nature of the machinelearning algorithms used in data-driven analytics models, the configuration of a smart product is frequently refined, often in a real-time context. Hence, a smart product requires a continuous evolution of its architecture. This paper proposes a systematic method to facilitate the modularization of an analytics model architecture, so that a modular smart-product architecture can be achieved. Productizing an analytics model transforms conventional taskoriented data analytics activities into a data product development process. Issues related to the standardization of analytics models, the modular design approaches, the modularity quantification, and their impacts on the overall smart product design, are discussed. The proposed method is applied to an unmanned aircraft system (UAS) design so that a modular UAS architecture can be configured for various mission applications.; Towards an integrated process model for new product development with data-driven features (NPD3) -- New information and communication technologies are changing the way products are developed, manufactured, serviced and managed over the product’s lifecycle. Today’s smart products not only consist of their physical components, but are also endowed with intelligence. Data and the capabilities to process data into knowledge and eventually decisions have become critical components of the product itself and of the process to develop/operate the product. This paper investigates how engineers and a new functional role, data scientists, can effectively collaborate in a mixed team for new product development with data-driven features (NPD3). We focus on the concept development stage, typically the fuzziest phase of product development. In this paper, an integrated process model is explored by revisiting the traditional new product development (NPD) process model as well as the knowledge discovery and data mining (KDDM) process model. Then a case study of the development of an application-specific unmanned aircraft system (UAS) is used to examine the proposed model.; The GET immersion experience -- This article describes a new and innovative open co-op program for MIS/IS students. The program, Global Enterprise Technology Immersion Experience (GET IE), has a global enterprise focus that is integrated with hands-on experiential work-based learning to provide a context in which students are stimulated to utilize their classroom knowledge. The program includes a two-semester internship component that can be seamlessly incorporated with an existing MIS curriculum. The internship's unique pedagogical innovation is to deliver academic coursework on global enterprise technology to the students just in time-that is, while they are participating in an extended internship. The program, in effect, creates a domain-specific, next generation co-op program that complements traditional information systems curricula with a skillset that is required for creating and running very large global enterprise applications. The guiding GET consortium consists of four universities and a number of large companies, and the consortium is open to future expansion. The continued growth of the consortium would enrich student choices and foster cross-fertilization of curriculum activities.; An open co-op model for global enterprise technology education -- We present an open co-op program called Global Enterprise Technology Immersion Experience (GET IE) developed by JPMorgan Chase & Co. and Syracuse University. The new program creates a global enterprise focus in technology-oriented academic majors, integrated with hands-on experiential work-based learning to provide a context in which students are stimulated to utilize their classroom experience. The program includes a two-semester paid internship component that can be seamlessly incorporated with the existing computer science curriculum at Syracuse and else where. The internship's unique pedagogical innovation is to simultaneously provide the students academic course work that is integrated within a students extended internship and provides relevant problems in global enterprise technology. The curricula is ""open"" in the sense that other institutions and companies can join the consortium to enrich choices for the students and foster cross-fertilization of curricula activities. The program, in effect, creates a domain specific next generation co-op program that complements typical computer science curricula with a skill-set that is required for creating very large, global enterprise applications for technically and socially diverse organizations.; The need for new processes, methodologies and tools to support big data teams and improve big data project effectiveness -- As data continues to be produced in massive amounts, with increasing volume, velocity and variety, big data projects are growing in frequency and importance. However, the growth in the use of big data has outstripped the knowledge of how to support teams that need to do big data projects. In fact, while much has been written in terms of the use of algorithms that can help generate insightful analysis, much less has been written about methodologies, tools and frameworks that could enable teams to more effectively and efficiently «do» big data projects. Hence, this paper discusses the key research questions relating methodologies, tools and frameworks to improve big data team effectiveness as well as the potential goals for a big data process methodology. Finally, the paper also discusses related domains, such as software development, operations research and business intelligence, since these fields might provide insight into how to define a big data process methodology.; Exploring the process of doing data science via an ethnographic study of a media advertising company -- This paper presents the results of an ethnographic study focused on how data science projects were conducted within a global media advertising company. Observations, via embedding a researcher within the team, as well as more structured interviews and surveys, are documented. Recommendations to improve the current data science methodology within the company are also discussed. Overall, there had been little focus on the team's process methodology and the suggested process improvements would result in the company's data science projects having less risk and shorter timelines. Other big data teams might also benefit from reviewing and refining their work processes, but more work needs to be done to validate this assumption.; A framework for describing big data projects -- With the ability to collect, store and analyze an ever-growing diversity of data generated with ever-increasing frequency, Big Data is a rapidly growing field. While tremendous strides have been made in the algorithms and technologies that are used to perform the analytics, much less has been done to determine how the team should work together to do a Big Data project. Our research reports on a set of case studies, where researchers were embedded within Big Data teams. Since project methodologies will likely depend on the attributes of a Big Data effort, we focus our analysis on defining a framework to describe a Big Data project. We then use this framework to describe the organizations we studied and some of the socio-technical challenges linked to these newly defined project characteristics.; Not all software engineers can become good data engineers -- The amount of data that businesses collect and analyze has been rapidly increasing, which has triggered an increase in big data teams. With the growth of both the number and size of big data teams, specialized roles are starting to be defined. One such role is the data engineer, who focuses on ensuring that the data is easily available for advanced analytics. Via a case study, this paper explores the role of the data engineer and the key characteristics that enable someone to be a good data engineer. The paper also explores if good software engineers could become good data engineers. Our findings show that the knowledge and skills required to be a data engineer are significantly different from those required to be a software engineer. Hence, not surprisingly, we found that that not all software engineers could become good data engineers.; Big data team process methodologies -- This paper reports on our review of published research relating to how teams work together to execute Big Data projects. Our findings suggest that there is no agreed upon standard for executing these projects but that there is a growing research focus in this area and that an improved process methodology would be useful. In addition, our synthesis also provides useful suggestions to help practitioners execute their projects, specifically our identified list of 33 important success factors for executing Big Data efforts, which are grouped by our six identified characteristics of a mature Big Data organization.; Predicting data science sociotechnical execution challenges by categorizing data science projects -- The challenge in executing a data science project is more than just identifying the best algorithm and tool set to use. Additional sociotechnical challenges include items such as how to define the project goals and how to ensure the project is effectively managed. This paper reports on a set of case studies where researchers were embedded within data science teams and where the researcher observations and analysis was focused on the attributes that can help describe data science projects and the challenges faced by the teams executing these projects, as opposed to the algorithms and technologies that were used to perform the analytics. Based on our case studies, we identified 14 characteristics that can help describe a data science project. We then used these characteristics to create a model that defines two key dimensions of the project. Finally, by clustering the projects within these two dimensions, we identified four types of data science projects, and based on the type of project, we identified some of the sociotechnical challenges that project teams should expect to encounter when executing data science projects.; Comparing Data Science Project Management Methodologies via a Controlled Experiment -- Data Science is an emerging field with a significant research focus on improving the techniques available to analyze data. However, there has been much less focus on how people should work together on a data science project. In this paper, we report on the results of an experiment comparing four different methodologies to manage and coordinate a data science project. We first introduce a model to compare different project management methodologies and then report on the results of our experiment. The results from our experiment demonstrate that there are significant differences based on the methodology used, with an Agile Kanban methodology being the most effective and surprisingly, an Agile Scrum methodology being the least effective.; What is a data science/analytics degree? -- Data science, and the related field of analytics, is an emerging discipline that integrates concepts across a range of domains, including computer science, information systems, software engineering and statistics. While the number of data science / analytics programs continues to increase, there has been little discussion on how we should define this emerging educational field. This panel will foster a debate with respect to what are the key learning objectives within these programs and should there be different types of data science related programs (such as an applied data science program or a business analytics program in addition to data science programs). Via a debate, this panel, along with the audience, will explore the field of data science and these emerging questions regarding data science and analytics education.; A framework to explore ethical issues when using big data analytics on the future networked internet of things -- The networked future will generate a huge amount of data. With this in mind, using big data analytics will be an important capability that will be required to fully leverage the knowledge within the data. However, collecting, storing and analyzing the data can create many ethical situations that data scientists have yet to ponder. Hence, this paper explores some of the possible ethical conundrums that might have to be addressed within a big data network of the future project and proposes a framework that can be used by data scientists working within such a context. These ethical challenges are explored within an example of future networked vehicles. In short, the framework focuses on two high level ethical considerations that need to be considered: data related challenges and model related challenges.; Key concepts for a data science ethics curriculum -- Data science is a new field that integrates aspects of computer science, statistics and information management. As a new field, ethical issues a data scientist may encounter have received little attention to date, and ethics training within a data science curriculum has received even less attention. To address this gap, this article explores the different codes of conduct and ethics frameworks related to data science. We compare this analysis with the results of a systematic literature review focusing on ethics in data science. Our analysis identified twelve key ethics areas that should be included within a data science ethics curriculum. Our research notes that none of the existing codes or frameworks covers all of the identified themes. Data science educators and program coordinators can use our results as a way to identify key ethical concepts that can be introduced within a data science program.; Does pair programming work in a data science context? An initial case study -- While pair programming has been studied extensively for software programmers, very little has been reported with respect to pair programming in a data science project. This paper reports on a case study evaluating the effectiveness of pair programming within a data science / big data context. Our findings show that pair programming can be useful for data science teams. In addition, while the driver role was similar to what has been described for software programmers, we note that the observer role had an expanded set of responsibilities, which we termed researcher activities. Further exploration is required to explore if these expanded roles are specific to data science pair programming.; The ambiguity of data science team roles and the need for a data science workforce framework -- This paper first reviews the benefits of well-defined roles and then discusses the current lack of standardized roles within the data science community, perhaps due to the newness of the field. Specifically, the paper reports on five case studies exploring five different attempts to define a standard set of roles. These case studies explore the usage of roles from an industry perspective as well as from national standard big data committee efforts. The paper then leverages the results of these case studies to explore the use of data science roles within online job postings. While some roles appeared frequently, such as data scientist and data engineer, no role was consistently used across all five case studies. Hence, the paper concludes by noting the need to create a data science workforce framework that could be used by students, employers, and academic institutions. This framework would enable organizations to staff their data science teams more accurately with the desired skillsets.; Key Management and Governance Challenges when Executing Data Science / Analytics Projects -- Big data, data science and analytics have become increasingly important strategic assets because they can help organizations make better decisions, discover new insights, competitively differentiate, and they enable the embedding of intelligence into automated processes so organizations can efficiently respond at the speed of business. Effective organizational management and goverce of data science practices are necessary in order to mitigate risks associated with analytics deployment. For example, organizations need to capture and manage critical meta-information detailing modeling and environmental assumptions underlying the analytics solutions, they also need to establish policies and a culture designed to ensure adherence to the highest ethical standards of data management and predictive model deployment. At a higher level, unleashing machine learning algorithms may require safeguards and risk mitigation monitoring to address these types of socio-technical challenges. This panel will foster a debate with respect to what are the most important concerns or potential issues that an organization should focus on while executing a data science/analytics project. Via a debate, the panel, along with the audience, will explore the field of data science and predictive analytics, and what are the key project risks that need to be mitigated.; Exploring project management methodologies used within data science teams -- There are many reasons data science teams should use a well-defined process to manage and coordinate their efforts, such as improved collaboration, efficiency and stakeholder communication. This paper explores the current methodology data science teams use to manage and coordinate their efforts. Unfortunately, based on our survey results, most data science teams currently use an ad hoc project management approach. In fact, 82% of the data scientists surveyed did not follow an explicit process. However, it is encouraging to note that 85% of the respondents thought that adopting an improved process methodology would improve the teams' outcomes. Based on these results, we described six possible process methodologies teams could use. To conclude, we outlined plans to describe best practices for data science team processes and to develop a process evaluation framework.; Exploring how different project management methodologies impact data science students -- This paper reports on a controlled experiment comparing different approaches on how to guide students through a semester long data science project. Four different methodologies, ranging from a traditional “just assign some intermediate milestones” to other more agile methodologies, are compared. The results of the experiment shows that the project methodology used in the classroom made a significant difference in student outcomes. Surprisingly, an Agile Kanban approach was found to be much more effective than an Agile Scrum methodology, which was not one of the leading ap-proaches.; Acceptance factors for using a big data capability and maturity model -- Big data is an emerging field that combines expertise across a range of domains, including software development, data management and statistics. However, it has been shown that big data projects suffer because they often operate at a low level of process maturity. To help address this gap, the Diffusion of Innovation Theory is used as a theoretical lens to identify factors that might drive an organization to try and improve their process maturity. Specifically, thirteen acceptance factors for teams to use (or not use) a Big Data CMM are identified. These results suggest that a positive perception exists with respect to relative advantage, compatibility and observability factors, and a negative perception exists with respect to perceived complexity. While more work is required to refine the list of factors, this insight can help guide the improvement of big data team processes.; A Scalable Methodology to Guide Student Teams Executing Computing Projects -- ; Data Science Roles and the Types of Data Science Programs -- ; Helping Data Science Students Develop Task Modularity -- This paper explores the skills needed to be a data scientist. Specifically, we report on a mixed method study of a project-based data science class, where we evaluated student effectiveness with respect to dividing a project into appropriately sized modular tasks, which we termed task modularity. Our results suggest that while data science students can appreciate the value of task modularity, they struggle to achieve effective task modularity. As a first step, based our study, we identified six task decomposition best practices. However, these best practices do not fully address this gap of how to enable data science students to effectively use task modularity. We note that while computer science/information system programs typically teach modularity (e.g., the decomposition process and abstraction), and there remains a need identify a corresponding model to that used for computer science / information system students, to teach modularity to data science students.; Identifying the key drivers for teams to use a data science process methodology -- While data science teams do not yet typically use a standard team process methodology, researchers are starting to explore process methodologies that improve team performance. However, little has been done to understand what might be the key acceptance factors for teams to implement a data science process methodology. To address this gap, the Diffusion of Innovation Theory is used as a theoretical lens to identify factors that might drive an organization to adopt a data science process methodology. The results of this qualitative research effort found ten factors that can influence a team to use, or not use, a data science process methodology. In short, eight positive factors were found with respect to relative advantage and compatibility and two negative factors were identified with respect to complexity. While more work is required to validate and refine these factors, the derived acceptance model can help teams as they consider adopting an improved data science process methodology.; Data science ethical considerations -- Data science, and the related field of big data, is an emerging discipline involving the analysis of data to solve problems and develop insights. This rapidly growing domain promises many benefits to both consumers and businesses. However, the use of big data analytics can also introduce many ethical concerns, stemming from, for example, the possible loss of privacy or the harming of a sub-category of the population via a classification algorithm. To help address these potential ethical challenges, this paper maps and describes the main ethical themes that were identified via systematic literature review. It then identifies a possible structure to integrate these themes within a data science project, thus helping to provide some structure in the on-going debate with respect to the possible ethical situations that can arise when using data science analytics.; Exploring the use of a Kanban coach for student teams -- Recent research has noted the benefit of using Kanban, both within industry and for team-based student projects. Unfortunately, there has been minimal research on how to improve student learning of the Kanban process. This paper starts to address this gap by reporting on the results of an in-class experiment that explores how to implement a Kanban Coach (KC) for student teams that use Kanban. We first outline the key KC responsibilities and interaction mechanisms that enables the KC to efficiently guide student teams, and then report on the results of our experiment. Our results suggest that a KC can be implemented efficiently within an educational context, and that the use of a KC improves student learning and the quality of the team’s project. Hence, our initial results suggest that the use a KC should be considered as part of the project support for student team-based projects and that a KC helps students internalize how to effectively use the Kanban process methodology.; Visualizing Kanban work -- Kanban is an agile and lean process methodology that is growing in use across a number of domains, including software development. While the use of the process methodology has been growing, the ability to track team member contributions when using Kanban has been noted as a gap in the methodology. This research starts to address this gap by creating a prototype application that visualizes the contribution of individual team members within the Kanban team. The visualizations are then evaluated via a case study. Initial results suggest that the visualizations, which show the tasks done by week for each team member, were helpful in understand team member participation and that they were easy to understand and use.; Introduction to Data Science -- ; Integrating ethics within machine learning courses -- This article establishes and addresses opportunities for ethics integration into Machine Learning (ML) courses. Following a survey of the history of computing ethics and the current need for ethical consideration within ML, we consider the current state of ML ethics education via an exploratory analysis of course syllabi in computing programs. The results reveal that though ethics is part of the overall educational landscape in these programs, it is not frequently a part of core technical ML courses. To help address this gap, we offer a preliminary framework, developed via a systematic literature review, of relevant ethics questions that should be addressed within an ML project. A pilot study with 85 students confirms that this framework helped them identify and articulate key ethical considerations within their ML projects. Building from this work, we also provide three example ML course modules that bring ethical thinking directly into learning core ML content. Collectively, this research demonstrates: (1) the need for ethics to be taught as integrated within ML coursework, (2) a structured set of questions useful for identifying and addressing potential issues within an ML project, and (3) novel course models that provide examples for how to practically teach ML ethics without sacrificing core course content. An additional by-product of this research is the collection and integration of recent publications in the emerging field of ML ethics education.; SKI -- This paper explores data science project management by first noting the need for a new process management framework and then defines a process framework that effectively supports the needs of a data science team. The paper also reports on a pilot study of teams using the framework. The framework adheres to the lean Kanban philosophy but augments Kanban by providing a structured iteration process for teams to incrementally explore and learn via lean hypothesis testing. Specifically, the Structured Kanban Iteration (SKI) framework focuses on having teams define capability-based iterations (as opposed to Kanban-like no iterations or Scrumlike time-based sprints). Furthermore, unlike Kanban, the framework leverages Scrum best practices to define roles, meetings and artifacts. Thus, SKI implements the Kanban process, but with a more repeatable and structured approach.; Using structured pair activities in a distributed online breakout room -- With the increasing availability of synchronous video-based breakout rooms within online courses, a growing need exists to understand how to best leverage this technology for enhanced online education. To help address this challenge, this paper reports on a case study that explored student activity within online video-based breakout rooms via a Structured Paired Activity (SPA) methodology. SPA, which is adapted from the concept of Paired Programming, defines a general way to structure roles and activities for the participants within the breakout room. Initial qualitative results suggest that the use of SPA in online breakout rooms increases student engagement and process effectiveness. These results are potentially applicable to a broad range of web-based synchronous online courses.; Exploring which agile principles students internalize when using a kanban process methodology -- This paper reports on a case study of the Agile Kanban project methodology, which while growing in popularity, has had far less analysis on its usefulness in the classroom as compared to other frameworks such as Agile Scrum. Our study provides insight into why the Kanban methodology is useful by mapping student comments about the methodology to the twelve principles laid down in the Agile Manifesto. Our analysis identified two key agile principles that help to explain the value of Kanban. Specifically, we found that the students focused on self-organizing teams and reflection at regular intervals, and that these two principles led to improved team communication and coordination. Our findings are useful for those looking to use or define a process management methodology for student teams as well as others exploring the more general challenge of incorporating agile into the classroom.; The need for an enterprise risk management framework for big data science projects -- This position paper explores the need for, and benefits of, a Big Data Science Enterprise Risk Management Framework (RMF). The paper highlights the need for an RMF for Big Data Science projects, as well as the gaps and deficiencies of current risk management frameworks in addressing Big Data Science project risks. Furthermore, via a systematic literature review, the paper notes a dearth of research which looks at risk management frameworks for Big Data Science projects. The paper also reviews other emerging technology domains, and notes the creation of enhanced risk management frameworks to address the new risks introduced due to that emerging technology. Finally, this paper charts a possible path forward to define a risk management framework for Big Data Science projects.; Will Deep Learning Change How Teams Execute Big Data Projects? -- As data continues to be produced in ever increasing quantities, and technologies such as high performance computing continue to be enhanced, the number of big data projects using advanced neural network machine learning, often referred to as deep learning, continues to increase. Unfortunately, while much has been written on the use of deep learning algorithms in terms of generating insightful analysis, much less has been written about the project management process methodologies that could enable teams to more effectively and efficiently »do» big data deep learning projects. Specifically, the rapid growth in the use of deep learning techniques might introduce new challenges with respect to how to execute a big data deep learning project, due to how deep learning models can learn features automatically. For example, feature engineering and model evaluation phases of big data projects might grow in importance, while other areas, such as model selection, might decrease in importance. Hence, this paper discusses the key research questions relating the potential impact of the use of deep learning on how teams should execute big data projects.; Using a coach to improve team performance when the team uses a kanban process methodology -- Teams are increasing their use of the Kanban process methodology across a range of information system projects, including software development and data science projects. While the use of Kanban is growing, little has been done to explore how to improve team performance for teams that use Kanban. One possibility is to introduce a Kanban Coach (KC). This work reports on exploring the use of a Kanban Coach, with respect to both how the coach could interact with the team as well as how the use of a coach impacts team results. Specifically, this paper reports on an experiment where teams either had, or did not have, a Kanban Coach. A quantitative and qualitative analysis of the data collected during the experiment found that introducing KC led to significant improvement of team performance. Coordination Theory and Shared Mental Models were then employed to provide an explanation as to why a KC leads to better project results. While this experiment was done within a data science project context, the results are likely applicable across a range of information system projects.; A predictive model to identify Kanban teams at risk -- Kanban, which is an agile process methodology as well as a means to implement lean principles, has been growing as a project management framework across a range of domains, including manufacturing, software development and data science. This paper explores, for teams using Kanban, the ability to predict low team performance. The prediction is based on an analytical model that uses specific project metrics that can be collected via the team's visual Kanban board. Specifically, data from 80 teams was used to build and test machine learning models that predict teams at risk for delivering low quality results. The model developed was significantly better than the baseline situation of thinking that all teams were at risk. While this analysis was done within a data science project context, the results are likely applicable across a range of information system projects.; Improving Data Science Projects by Enriching Analytical Models with Domain Knowledge -- Domain knowledge is very important to support the development of analytic models. However, in today's data science projects, domain knowledge is typically documented, but not captured and integrated with the actual analytic model. This raises problems in interoperability and traceability of the relevant domain knowledge that is used to develop an analytic model. To address this challenge, this paper proposes a Knowledge Enriched Analytic Model (KEAM) to enrich analytic models with domain knowledge. To explore the proposed methodology and its benefits, a case study explores the utilization of KEAM to support the development of a Bayesian Network model within the smart manufacturing domain. The case study shows that the efficiency in developing an analytic model is improved by using the proposed KEAM."
Jennifer Stromer-Galley,"Digital Media, Power, and Democracy in Parties and Election Campaigns -- The role of digital media practices in reshaping political parties and election campaigns is driven by a tension between control and interactivity, but the overall outcome for the party organizational form is highly uncertain. Recent evidence contradicts scholarship on the so-called “death” of parties and suggests instead that parties may be going through a long-term process of adaptation to postmaterial political culture. We sketch out a conceptual approach for understanding this process, which we argue is being shaped by interactions between the organizations, norms, and rules of electoral politics; postmaterial attitudes toward political engagement; and the affordances and uses of digital media. Digital media foster cultures of organizational experimentation and a party-as-movement mentality that enable many to reject norms of hierarchical discipline and habitual partisan loyalty. This context readily accommodates populist appeals and angry protest—on the right as well as the left. Substantial publics now see election campaigns as another opportunity for personalized and contentious political expression. As a result, we hypothesize that parties are being renewed from the outside in, as digitally enabled citizens breathe new life into an old form by partly remaking it in their own participatory image. Particularly on the left, the overall outcome might prove more positive for democratic engagement and the decentralization of political power than many have assumed.; Effective Mitigation of Anchoring Bias, Projection Bias, and Representativeness Bias from Serious Game-based Training -- Although human use of heuristics can result in ‘fast and frugal’ decision-making, those prepotent tendencies can also impair our ability to make optimal choices. Previous work had suggested such cognitive biases are resistant to mitigation training. Serious games offer a method to incorporate desirable elements into a training experience, and allow the use of mechanisms that enhance learning and retention. We developed a game to train recognition and mitigation of three forms of cognitive bias: anchoring, a tendency to be inordinately influenced by one piece of information; projection, an implicit assumption that others think or know what you do; and representativeness, judging the likelihood of a hypothesis by how much the available data resembles it. Participants were randomly assigned to play the training game once, twice spaced by 10 to 12 days, or a control condition that used a training video. External questionnaire-based assessments were given immediately post-training and 12 weeks later. Superior training was seen from the game. An independent group using our training game with their own novel bias assessment instruments (to which the researchers and game-developers had no access or content information) validated the key finding. These results demonstrate the viability and high value of using serious computer games to train mitigation of cognitive biases.; Analytics-driven design -- The number of educational or serious games (SGs) available to educators has increased in recent years as the cost of game development has been reduced. A benefit of SGs is that they employ not only lesson content but also knowledge contexts where learners can connect information to its context of use with active participation and engagement. This, in turn, improves learners’ ability to recall, integrate, and apply what they learn. Much of the research on game analytics has examined learner in-game trails to build predictive models that identify negative learner actions (e.g., systematic guessing after the fact). However, analytics can also be used in the game design and development phases. Drawing on evidence-centered design (ECD), the chapter outlines ways that analytics can drive the development of scenarios and activities in a game and thus allows SGs to function as contextual apprenticeships, providing robust assessment opportunities. We describe how ECD theory was applied in a project to develop and test a SG that trains people to reduce their reliance on cognitive biases. We describe instances during the design process where our team encountered obstacles due to differing psychological and learning/teaching orientations, a topic rarely explored in the SG or ECD literature. Furthermore, we describe the final analytics-based game design features. We propose an additional element (persona) and how we anticipate incorporating that ECD extension into future projects.; The Temporal Attentive Observation (TAO) Scale -- The engaging nature of video games has intrigued learning professionals attempting to capture and retain learners’ attention. Designing learning interventions that not only capture the learner’s attention, but also are designed around the natural cycle of attention will be vital for learning. This paper introduces the temporal attentive observation (TAO) instrument, an instrument developed to assess attentive behavior sequences during serious gameplay. We use an established three-step process for developing observational systems that includes identifying the construct, determining validity, and demonstrating practicality criteria. We conclude that the TAO instrument reliably measures attention behaviors where participants’ faces can be recorded during an experiment. Furthermore, we suggest that TAO should be considered as a part of an attention measurement package.; Communicating age in Second Life -- Although considerable research has identified patterns in online communication and interaction related to a range of individual characteristics, analyses of age have been limited, especially those that compare age groups. Research that does examine online communication by age largely focuses on linguistic elements. However, social identity approaches to group communication emphasize the importance of non-linguistic factors such as appearance and non-verbal behaviors. These factors are especially important to explore in online settings where traditional physical markers of age are largely unseen. To examine ways that users communicate age identity through both visual and textual means, we use multiple linear regression and qualitative methods to explore the behavior of 201 players of a custom game in the virtual world Second Life. Analyses of chat, avatar movement, and appearance suggest that although residents primarily used youthful-looking avatars, age differences emerged more strongly in visual factors than in language use.; The strategic female -- As players craft and enact identities in digital games, the relationship between player and avatar gender remains unclear. This study examines how 11 in-game chat, movement, and appearance behaviors differed by gender and by men who did and did not use a female avatar - or 'gender-switchers'. Drawing on social role and feminist theories of gender, we argue that gender differences in behavior align with the social roles and norms that establish appropriate and inappropriate behavior for men and women. Thus we complicate questions of 'gender-switching' by examining not only player gender, but also player psychological Gender Role as measured by the Bem Sex Role Inventory to examine how gender does - and does not - manifest in digital worlds. Analysis revealed that men may not necessarily seek to mask their offline gender when they use a female avatar, but there is evidence they do reinforce idealized notions of feminine appearance and communication. Movement behaviors, however, show no differences across men who do and do not gender-switch. That is, selecting avatar gender may be less a matter of identity expression, and more a strategic selection of available multi-modal codes that players take up in their navigation of this digital space.; Measuring Game Engagement -- Background. Engagement has been identified as a crucial component of learning in games research. However, the conceptualization and operationalization of engagement vary widely in the literature. Many valuable approaches illuminate ways in which presence, flow, arousal, participation, and other concepts constitute or contribute to engagement. However, few studies examine multiple conceptualizations of engagement in the same project.Method. This article discusses the results of two experiments that measure engagement in five different ways: survey self-report, content analyses of player videos, electro-dermal activity, mouse movements, and game click logs. We examine the relationships among these measures and assess how they are affected by the technical characteristics of a 30-minute, custom-built, educational game: use of a customized character, level of narrative complexity, and level of art complexity.Results. We found that the five measures of engagement correlated in limited ways, and that they revealed substantially different relationships with game characteristics. We conclude that engagement as a construct is more complex than is captured in any of these measures individually and that using multiple methods to assess engagement can illuminate aspects of engagement not detectable by a single method of measurement.; Balancing Play and Formal Training in the Design of Serious Games -- This article discusses the design and development of two serious games intended to train people to reduce their reliance on cognitive biases in their decision-making in less than an hour each. In our development process, we found a tension between rich and flexible experimentation and exploration experiences and robust learning experiences that ensured the lesson content was easily understood and recalled. In line with game-based learning research, initial designs were oriented toward exploration and discovery. Analyses of interviews, playtesting, logs, and surveys revealed that many players were frustrated or confused by the interface and content of the more complex games, even when consistent differences between levels of visual detail or narrative complexity were not present. We conclude that teaching complex topics such as cognitive biases to the widest range of learners required reducing the games’ playful and exploratory elements and balancing formal training content with simpler visuals and text.; Testing the power of game lessons -- Educational games have generated attention for their potential to teach more successfully and with longer-lasting outcomes than traditional teaching methods. Questions remain, however, about which features of games enhance learning. This study investigates the effects of art style and narrative complexity on training outcomes of a game designed to help players mitigate three cognitive biases. The training was effective and was retained eight weeks later, although differences in art style and narrative complexity did not affect overall learning. The games were also compared with an alternative training technique, a professionally produced video. Immediately after exposure, the games produced better training than the video on two of the biases; eight weeks later, the games produced better training than the video on one of the biases.; We don't need no stinkin' badges -- Drawing from recent research on the ability of video games to satisfy psychological needs, this paper identifies how the presence of rewards influences learning complex concepts and tasks using an educational video game. We designed and developed two 60-min educational games with and without a range of reward features and examined learning outcomes among 242 participants in university laboratories. Although both games improved learning, analyses suggest that the quantity of in-game rewards did not have an impact on biased behavior avoidance or knowledge about biases. To further illuminate these findings, we examined perceptions of feeling rewarded and found that those who felt more rewarded had more favorable views of the gameplay experience, but they did not demonstrate different learning outcomes.; The relationship between race competitiveness, standing in the polls, and social media communication strategies during the 2014 U.S. gubernatorial campaigns -- Political campaigns have been systematically using social media for strategic advantage. However, little is known about how competitiveness affects the ways candidates communicate online. Our study analyzes how race competitiveness as measured by polling performance influences candidates’ strategies on Twitter and Facebook. We analyze all social media messages of Republican and Democratic candidates in states that held gubernatorial elections in 2014 using supervised automated content analysis. We find that position in the polls and that race competitiveness are correlated with the ways candidates communicate on social media, and that candidates use Twitter and Facebook in different ways to communicate with the public.; Citizen Deliberation Online -- Political conversation is at the heart of democratic societies, and it is an important precursor of political engagement. As society has become intertwined with the communication infrastructure of the Internet, we need to understand its uses and the implications of those uses for democracy. This chapter provides an overview of the core topics of scholarly concern around online citizen deliberation, focusing on three key areas of research: the standards of quality of communication and the normative stance on citizen deliberation online; the impact and importance of digital platforms in structuring political talk; and the differences between formal and informal political talk spaces. After providing a critical review of these three major areas of research, we outline directions for future research on online citizen deliberation.; Exploring the Relationship Between Campaign Discourse on Facebook and the Public’s Comments -- Social media is now ubiquitously used by political campaigns, but less attention has been given to public discussions that take place on candidates’ free public accounts on social media. Also unclear is whether there is a relationship between campaign messaging and the tone of public comments. To address this gap, this article analyzes public comments on Facebook accounts of candidates Trump and Clinton during the US election presidential debates in 2016. We hypothesize that attack messages posted by the candidates predict uncivil reactions by the public and that the public is more likely to be uncivil when attacking candidates. We use content analysis, supervised machine learning, and text mining to analyze candidates’ posts and public comments. Our results suggest that Clinton was the target of substantially more uncivil comments. Negative messages by the candidates are not associated with incivility by the public, but comments are significantly more likely to be uncivil when the public is attacking candidates. These results suggest that the public discourse around political campaigns might be less affected by what campaigns post on social media than by the public’s own perceptions and feelings toward the candidates.; Dysfunctional information sharing on WhatsApp and Facebook -- In this study, we investigate dysfunctional information sharing on WhatsApp and Facebook, focusing on two explanatory variables—frequency of political talk and cross-cutting exposure—and potential remedies, such as witnessing, experiencing, and performing social corrections. Results suggest that dysfunctional sharing is pervasive, with nearly a quarter reporting sharing misinformation on Facebook and WhatsApp, but social corrections also occur relatively frequently. Platform matters, with corrections being more likely to be experienced or expressed on WhatsApp than Facebook. Taken together, our results suggest that the intimate nature of WhatsApp communication has important consequences for the dynamics of misinformation sharing, particularly with regard to facilitating social corrections.; Modeling leadership behavior of players in virtual worlds -- In this article, we describe our method of modeling sociolinguistic behaviors of players in massively multi-player online games. The focus of this paper is leadership, as it is manifested by the participants engaged in discussion, and the automated modeling of this complex behavior in virtual worlds. We first approach the research question of modeling from a social science perspective, and ground our models in theories from human communication literature. We then adapt a two-tiered algorithmic model that derives certain mid-level sociolinguistic behaviors--such as Task Control,Topic Control and Disagreement from discourse linguistic indicators--and combines these in a weighted model to reveal the complex role of Leadership. The algorithm is evaluated by comparing its prediction of leaders against ground truth – the participants’ own ratings of leadership of themselves and their conversation peers. We find the algorithm performance to be considerably better than baseline. ; Serious Efforts at Bias Reduction -- As research on serious games continues to grow, we investigate the efficacy of digital games to train enhanced decision making through understanding cognitive biases. This study investigates the ability of a 30-minute digital game as compared with a 30-minute video to teach people how to recognize and mitigate three cognitive biases: fundamental attribution error, confirmation bias, and bias blind spot. We investigate the effects of character customization on learning outcomes as compared with an assigned character. We use interviews to understand the qualitative differences between the conditions. Experimental results suggest that the game was more effective at teaching and mitigating cognitive biases than was the training video. Although interviews suggest players liked avatar customization, results of the experiment indicate that avatar customization had no significant effect on learning outcomes. This research provides information future designers can use to choose the best medium and affordances for the most effective learning outcomes on cognitive processes.; Analyzing iterative training game design -- That games can be used to teach specific content has been demonstrated numerous times. However, although specific game features have been conjectured to have an impact on learning outcomes, little empirical research exists on the impact of iterative design on learning outcomes. This article analyzes two games that have been developed to train an adult audience to recognize and avoid relying on six cognitive biases (three per game) in their decision making. The games were developed iteratively and were evaluated through a series of experiments. Although the experimental manipulations did not find a significant impact of the manipulated game features on the learning outcomes, each game iteration proved more successful than its predecessors at training players. Here, we outline a mixed-methods approach to postmortem game design analysis that helps us understand what might account for the improvement across games, and to identify new variables for future experimental training game studies.; User-centered design and experimentation to develop effective software for evidence-based reasoning in the intelligence community -- Improving reasoning in intelligence analysis is of vital national importance. The trackable reasoning and analysis for crowdsourcing and evaluation project takes a user-centered design approach combined with rigorous experimentation to ascertain effective structured techniques to support high-quality reasoning. Results suggest a light structure is more effective than a rigid structure.; Context and Medium Matter -- ; Deliberative e-rulemaking decision facilitation -- This article describes the challenges facing a federal government–funded initiative to promote online deliberation to improve the public comment process by federal and state government agencies in the United States. The three year project met several difficulties. Some have been technical, but our primary obstacle has been in securing partnerships with government agencies. Due to institutional, legal, and organizational challenges, many government agencies are resistant to opening up the public comment process to a deliberative structure, although some change occurred following the Obama administration’s Open Government Initiative. This article describes the objectives of the original research project and details the challenges faced with the hope of guiding future deliberation research projects that aim to work with federal agencies in the U.S.; Vulgar Eloquence in the Digital Age -- Power Shift? Political Leadership and Social Media examines how political leaders have adapted to the challenges of social media, including Facebook, Instagram, Twitter, and memes, among other means of persuasion. Established political leaders now use social media to grab headlines, respond to opponents, fund raise, contact voters directly, and organize their election campaigns. Leaders of protest movements have used social media to organize and galvanize grassroots support and to popularize new narratives: narratives that challenge and sometimes overturn conventional thinking. Yet each social media platform provides different affordances and different attributes, and each is used differently by political leaders.In this book, leading international experts provide an unprecedented look at the role of social media in leadership today. Through a series of case studies dealing with topics ranging from Emmanuel Macron and Donald Trump's use of Twitter, to Justin Trudeau's use of selfies and Instagram, to how feminist leaders mobilize against stereotypes and injustices, the authors argue that many leaders have found additional avenues to communicate with the public and use power. This raises the question of whether this is causing a power shift in the relationship between leaders and followers. Together the chapters in this book suggest new rules of engagement that leaders ignore at their peril.The lack of systematic theoretically informed and empirically supported analyses makes Power Shift? Political Leadership and Social Media an indispensable read for students and scholars wishing to gain new understanding on what social media means for leadership.; Changing Campaign Tactics in the Age of Digital Media -- The age of digital media has given rise to a new social world. It is a world in which the transmission of information from the few to the many is steadily being supplanted by the multi-directional flow of facts, lies, and ideas. It is a world in which hundreds of millions of people are voluntarily depositing large amounts of personal details in publicly accessible databases. It is a world in which interpersonal relationships are increasingly being conducted in the virtual sphere. Above all, this is a world that seems to be veering off in unpredictable ways from the trends of the immediate past. This book is a probing examination of that world, and of the changes that it has ushered into our lives.In more than thirty essays by a wide range of scholars, this must-have second edition examines the impact of digital media in six areas – information, persuasion, community, gender and sexuality, surveillance and privacy, and cross-cultural communication – and offers an invaluable guide for students and scholars alike. With one exception, all essays are completely new or revised for this volume.; Political Deliberation Online -- An incisive, broad-based overview of political communication, the Oxford Handbook for Political Communication assembles the leading scholars in the field of political communication to answer the question: What do we know and need to know about the process by which humans claim, lose, or share power through symbolic exchanges? Its sixty-three essays address the following five themes: contexts for viewing the field of political communication, political discourse, media and political communication, interpersonal and small group political communication, and the altered political communication landscape. This comprehensive review of the political communication literature is designed to become the first reference for scholars and students interested in the study of how, why, when, and with what effect humans make sense of symbolic exchanges about sharing and shared power. ; Flexible versus structured support for reasoning -- Structured analytic techniques (SATs) help the intelligence community reduce flaws in cognition that lead to faulty reasoning. To ascertain whether SATs provide benefits to reasoning we conducted an experiment within a web-based application, comparing three conditions: 1) unaided reasoning, 2) a prototypical order-based SAT and 3) a flexible, process-based SAT that we call TRACE. Our findings suggest that the more flexible SAT generated higher quality reasoning compared to the other conditions. Consequently, techniques and training that support flexible analytical processes rather than those that require a set sequence of steps may be more beneficial to intelligence analysis and complex reasoning.  Keywords: structured analytical techniques, Analysis of Competing Hypotheses, tradecraft, cognitive biases, experiments.; Understanding discourse acts -- To understand political campaign messages in depth, we developed automated classification models for classifying categories of political campaign Twitter and Facebook messages, such as calls-to-action and persuasive messages. We used 2014 U.S. governor’s campaign social media messages to develop models, then tested these models on a randomly selected 2016 U.S. presidential campaign social media dataset. Our classifiers reach.75 micro-averaged F value on training sets and.76 micro-averaged F value on test sets, suggesting that the models can be applied to classify English-language political campaign social media messages. Our study also suggests that features afforded by social media help improve classification performance in social media documents.; Strategic temporality on social media during the general election of the 2016 u.s. presidential campaign -- To date, little attention has been paid to the temporal nature of campaigns as they respond to events or react to the different stages of a political election - what we define as strategic temporality. This article seeks to remedy this lack of research by examining campaign Facebook and Twitter messaging shifts during the 2016 U.S. Presidential general election. We used supervised machinelearning techniques to predict the types of messages that campaigns employed via social media and analyzed time-series data to identify messaging shifts over the course of the general election. We also examined how social media platforms and candidates' party affiliation shape campaign messaging. Results suggest differences exist in the types of campaign messages produced on different platforms during the general election. As election day drew closer, campaigns generated more calls-To-Action and informative messages on both Facebook and Twitter. This trend existed in advocacy campaign messages as well, but only on Twitter. Both advocacy and attack tweets were posted more frequently around Presidential and Vice-Presidential debate dates."
Jian Qin,"Transforming the data landscape -- This panel examines the state of research in the areas of data practices, behaviors, infrastructure, and policies through a series of five recently completed and in-progress studies. At their core these investigations seek to examine strategies for better connecting data, policies, and research communities. Often data and their related practices, policies, and infrastructure lack connection and cohesiveness to support data sharing among various communities. To better understand the current situation these connections will be explored through an assessment of emerging research. It is hoped that this research can be utilized to transform and better connect data practices, policies, and communities of practice.; A content analysis of institutional data policies -- The newly issued requirement for a data management plan in proposals submitted to the U.S. National Science Foundation and other federal funding agencies prompted many institutions to develop their own policies to conform to this new requirement as well as to more effectively manage, share, publish, and provide access to research data. While the need for guidelines or a framework in developing such data policies is imminent, research is lacking in this area. The study reported here addresses this need by using a content analysis of 58 policy documents from 20 institutions. Our preliminary findings reveal an uneven distribution of data policies among the institutions and disciplines included in this study. We are currently analyzing our results.; A Closer Look at Data Co-authorship -- ; Research networks in data repositories -- This paper reports our ongoing work investigating the structural features of scientific collaboration based on metadata collected from a scientific data repository (SDR). The background literature is reviewed in supporting our claim that metadata collected from SDRs offer a complimentary data source to traditional publication metadata collected from digital libraries. Methodological considerations are discussed in association with using metadata from SDRs, including author name disambiguation and data parsing. Initial findings show that the network has some unique macro-level structural features while also in agreement with existing networks theories. Challenges due to inconsistent metadata quality control procedures are also discussed in an attempt to reinforce claims that metadata should be designed to support both domain specific retrieval and evaluation and assessment needs.; Analysis of networks in cyberinfrastructure-enabled research communities -- ; Emergence of collaboration networks around large scale data repositories -- The advent of large data repositories and the necessity of distributed skillsets have led to a need to study the scientific collaboration network emerging around cyber-infrastructure-enabled repositories. To explore the impact of scientific collaboration and large-scale repositories in the field of genomics, we analyze coauthorship patterns in NCBIs big data repository GenBank using trace metadata from coauthorship of traditional publications and coauthorship of datasets. We demonstrate that using complex network analysis to explore both networks independently and jointly provides a much richer description of the community, and addresses some of the methodological concerns discussed in previous literature regarding the use of coauthorship data to study scientific collaboration.; Indicators for analyzing institutional repositories' performance -- This paper presents preliminary findings which examines the statistical correlation among and within micro and macro-level variables associated with Institutional Repositories (IRs), in order to explore potential indicators for the study of IRs activity and growth performance.; Towards a model for research data reuse behavior -- This poster reports a qualitative exploratory study of data reuse processes, and factors scientists consider when deciding whether or not to reuse data. Findings from this study revealed six core theoretical variables along with 28 influential factors that were salient across interviews and supported by research literature. The synthesis of findings led to the development of a model that draws upon the Unified Theory of Acceptance and Use of Technology (UTAUT) to investigate scientists' intentions and behavior towards the reuse of research data. The proposed model offers a novel approach to the current base of knowledge that has been essentially exploratory and atheoretical in nature. It also serves as the foundation for a future larger scale research that expects to provide guidelines for policymakers, open data advocates, and data repository stakeholders to better attune policies and repositories to scientists' expectations and needs.; Untangling data sharing and reuse in social sciences -- The discipline of social science has unique research norms and cultures regarding data sharing and reuse that can be affected by complex factors related to context, time and dependence on human subjects. Compared with STEM disciplines, social sciences emphasize the protection of study participants and observees. Extra effort is required from reusers to preserve data interconnectedness in order to guarantee the data's understandability and informative value. In this panel, the panelists will present their research findings and provide perspective on social science data sharing and reuse, including factors that may influence data reuse behavior, researchers' trust judgment in data for data reuse, and infrastructural barriers and incentives for data sharing among social scientists. This panel aims to provide an overview of the current state of social science data reuse and sharing, and, in collaboration with panel participants, elicit topics for future research. It also proposes a practical agenda to develop alternative incentives for individual researchers, and potential ways in which data sharing and reuse can be improved, coordinated, and encouraged among social scientists.; Using internship experience to evaluate a new program in eScience librarianship -- This research project explores the role of internships in a new curriculum designed to educate eScience librarians. Experiential learning was identified early on in the IMLS-funded project as a necessary aspect to give students field exposure to information-related developments of cyberinfrastructure-enabled science. Nine students were tasked to fill out a daily survey that captured their experience at academic and research libraries, field research stations, and national and discipline-based research centers. Analysis of these accumulated ""diary"" entries is underway to identify learning outcomes of the eSLib program, particularly two required, data-oriented courses the students mastered in the first year of the program. The analysis will also aggregate and trace longitudinally student skill application throughout the summer. Evaluation of student experience should enhance understanding of the relation between the eScience Librarianship program and what is needed by institutions tasked with managing data produced by computer and network-enabled scientists.; A novel research approach to enhance research group-level science data management -- This poster will report an alternative approach compared with large-scale collection, technology development, or discipline informatics projects by exploring the enhancement of science data management at the research group level. An academic-year-long project involving both information and technical analysts demonstrated that flexible introduction of IT in the form of a relational database solution presents an opportunity to incorporate data-related practices, behavior, and schemes into a tool. The project team used cognitive work analysis and participatory design research methods to sensitively analyze research practice and then design and introduce a prototype tool. Iterative analysis and design cycles captured and incorporated the complex practices of researchers who struggle with the accumulation of samples and related digital data files from years of research. Design research processes will be analyzed according to project developments and research group reaction to the proposed data management tool design and preliminary attempt at implementation.; Remodeling archival metadata descriptions for linked archives -- Though archival resources may be valued for their uniqueness, they do not exist in isolation from each other, and stand to benefit from linked data treatments capable of exposing them to a wider network of resources and potential users. To leverage these benefits, existing, item-level metadata depicting physical materials and their digitized surrogates must be remodeled as linked data. A number of solutions exist, but many current models in this domain are complex and may not capture all relevant aspects of larger, heterogeneous collections of media materials. This paper presents the development of the Linked Archives model, a linked data approach to making item-level metadata available for archival collections of media materials, including photographs, sound recordings, and video recordings. Developed and refined through an examination of existing collection and item metadata alongside comparisons to established domain ontologies and vocabularies, this model takes a modular approach to remodeling archival data as linked data. Current efforts focused on a simplified, user discovery focused module intended to improve access to these materials and the incorporation of their metadata into the wider web of data. This project contributes to work exploring the representation of the range of archival and special collections and how these materials may be addressed via linked data models.; Beyond the data management plan -- Support for research data management (RDM) has become a popular focus for library services, and many training opportunities in RDM exist for librarians. However, fewer opportunities exist for librarians to develop the more advanced skills and expertise necessary to support data science and open science. To better understand how to develop a library workforce prepared to develop services in the emerging areas of data science and open science, the National Library of Medicine convened a workshop of 15 librarians and information professionals with a range of expertise in data and open science. This session will present the workshop's recommendations and use participatory facilitation methods to engage attendees in conversation about how to prepare information professionals to meet the evolving challenges of data science and open science.; Understanding metadata functional requirements in genome curation work -- The proliferation of genomic data and their widespread data reuse pose new challenges to effectively manage and curate genomic data. This study contributes towards better understanding of 156 genomics scientists' perception and priorities for metadata functional requirements in genome curation work. Our study was guided by previously identified twenty two metadata functional requirements (Willis, Greenberg, & White, 2012), and intended to define a context-sensitive model of groupings for metadata goals in genome curation. Analysis of the results revealed that genomics scientists recognize specific sets of metadata functional requirements in the genome-curation context. These metadata goals were reduced to six factor constructs. The rankings of these constructs in decreasing order are Portability, Reusability, Manipulability, Sufficiency, Interoperability, and Modularity. The findings indicated that genomics scientists need both domain independent and dependent metadata functional requirements that are primarily related to data comparison, integration, and reuse across platforms and databases. The constructs defined by this study advance the understanding of metadata requirements and their relationships. In addition, the resulting metadata requirement model can serve as a valuable resource to genome scientists, data curators and administrators for designing metadata schemes and developing data-curation policies.; An interactive metadata model for structural, descriptive, and referential representation of scholarly output -- The scientific metadata model proposed in this article encompasses both classical descriptive metadata such as those defined in the Dublin Core Metadata Element Set (DC) and the innovative structural and referential metadata properties that go beyond the classical model. Structural metadata capture the structural vocabulary in research publications; referential metadata include not only citations but also data about other types of scholarly output that is based on or related to the same publication. The article describes the structural, descriptive, and referential (SDR) elements of the metadata model and explains the underlying assumptions and justifications for each major component in the model. Scholar- Wiki, an experimental system developed as a proof of concept, was built over the wiki platform to allow user interaction with the metadata and the editing, deleting, and adding of metadata. By allowing and encouraging scholars (both as authors and as users) to participate in the knowledge and metadata editing and enhancing process, the larger community will benefit from more accurate and effective information retrieval. The ScholarWiki system utilizes machine-learning techniques that can automatically produce self-enhanced metadata by learning from the structural metadata that scholars contribute, which will add intelligence to enhance and update automatically the publication of metadata Wiki pages.; ScholarWiki system for knowledge indexing and retrieval -- The goal of this research is to develop a tri-dimensional metadata model and implement this model through the ScholarWiki system to combine the machine-induced, user-enhanced metadata for more effective knowledge discovery and information retrieval. The tri-dimensional model captures the Structural, Descriptive, and Referential (SDR) metadata and incorporates them into a social media platform-ScholarWiki system. By allowing low-barrier participation, scholars (both as authors and users) can participate in the knowledge and metadata editing and enhancing process and benefit from more accurate and effective information retrieval. The ScholarWiki system utilizes machine-learning techniques that can automatically produce self-enhanced metadata through learning the structural metadata that scholars contribute. The cumulated machine learning will add intelligence to automatically enhance and update the publication metadata Wiki pages.; Interlinking cross language metadata using heterogeneous graphs and wikipedia -- Cross-language metadata are essential in helping users overcome language barriers in information discovery and recommendation. The construction of cross-language vocabulary, however, is usually costly and intellectually laborious. This paper addresses these problems by proposing a Cross-Language Metadata Network (CLMN) approach, which uses Wikipedia as the intermediary for cross-language metadata linking. We conducted a proof-of-concept experiment with key metadata in two digital libraries and in two different languages without using machine translation. The experiment result is encouraging and suggests that the CLMN approach has the potential not only to interlink metadata in different languages with reasonable rate of precision and quality but also to construct cross-language metadata vocabulary. Limitations and further research are also discussed.; The central role of metadata in a science data literacy course -- Science research is increasingly computer and network enabled and referred to as e-science. The change has had an impact on the information environment in which scientists across disciplines operate to conduct their research. This paper reports on an NSF funded project at the Syracuse University School of Information Studies (2007-2009) that examined this changing environment and directed specific attention to digital data management practices. A local faculty survey of data management practices and attitudes was conducted, as was a scan of related courses at peer institutions. Knowledge about data management in e-science was used to design a new course addressing data-related literacy for science students and teach them skills for managing data created as part of the scientific research process. Through out the project, metadata proved to have a central role in how scientists operate in the e-science information environment and to be a key component of data literacy in the e-science environment.; Institutional policies on science research data -- Institutions are increasingly feeling the pressure to develop strategies and policies to address these issues in science data management. Policies for data management, archiving, sharing, publishing, and use have sprouted on institutional and research centers' websites. The purpose of our pilot analysis was to collect policy examples for content analysis so that we have a better understanding of what types of policies exist and what issues they address. The poster will present an analysis of institutional policies on science research data management, archiving, sharing and publishing, and use.; Metadata and reproducibility: A case study of gravitational wave data management. -- The complexity of computationally-intensive scientific research poses great challenges for both research data management and research reproducibility. What metadata needs to be captured for tracking, reproducing, and reusing computational results is the starting point in developing metadata models to fulfill these functions of data management. This paper reports the findings from interviews with gravitational wave (GW) researchers, which were designed to gather user requirements to develop a metadata model. Motivations for keeping documentation of data and analysis results include trust, accountability and continuity of work. Research reproducibility relies on metadata that represents code dependencies and versions and has good documentation for verification. Metadata specific to GW data, workflows and outputs tend to differ from those currently available in metadata standards. The paper also discusses the challenges in representing code dependencies and workflows.; Enhancing scientific data literacy in college students -- Data literacy education is a new service territory for many academic libraries. This paper reports our experience from a two-year Science Data Literacy (SDL) project through four areas of activities: (1) survey on faculty’s perceptions and practices in data management, (2) design of SDL learning modules, (3) delivery of the course, and (4) assessment of learning outcomes. We found from the faculty survey that there was a low level of awareness of research data management importance, methods, and tools in general and that the data management practice is associated with the size and complexity of the data produced by their research. Science data literacy training was difficult to be integrated into formal curricula due to their structure, even though the need for such training was on the rise. The lessons learned from the two-year project and how libraries and library and information science education might turn this challenge into opportunities are discussed. ; From data to knowledge: -- This presentation addresses the research question of how the changing climate of science research has affected scientific capacity, the aggregation of the knowledge, skills, abilities, and technical facilities of individual scientists [referred to as Scientific and Technical (S&T) Human Capital], as well as their networks ofcollaborative relationships. By presenting a theoretical framework of concepts and relationships between scientific capacity and knowledge diffusion, the presentation reports findings from a two-year big metadata mining project and discusses the measures of impact assessment of CI-enabled collaboration and knowledge diffusion.  ; Stories from research frontline concerning data management and services. -- ; Scientific data management services and practices. -- This is an invited lecture to a one-week workshop for training librarians and information professionals who will be engaged in managing research data in their organizations. The workshop was held at the National Science and Technology Library of China, May 23-27, 2016, Beijing, China.; Transformation from Digital Libraries to Digital Repositories: -- This presentation discuses the emerging digital repository types and their implications to digital scholarship services in academic libraries. ; Pursuing Best Performance in Research Data Management by Using the Capability Maturity Model and Rubrics -- ; Collaboration Capacity -- This paper reports a study of the incremental impact of evolving cyberinfrastructure (CI)-enabled collaboration networks on scientific capacity and knowledge diffusion. While ample research shows how collaboration contributes to greater productivity, higher-quality scientific outputs, and increased probability of breakthroughs, it is unclear how the early stages of collaboration on data creation supports knowledge generation and diffusion. Further, it is not known whether the ability to garner larger inputs increases collaboration capacity and subsequently accelerates the rate of knowledge diffusion. Given that the collaboration capacity of a science team is largely dependent upon the Scientific and Technical (S&T) Human Capital, the greater a researcher’s S&T human capital, the greater the opportunity to collaborate and access resources. We use “Collaboration Capacity” to refer to this measure of S&T human capital. In this study, we collected metadata for molecular sequences in GenBank from 1990-2013. The data contain details about sequences, submission date, submitter(s), and associated publications and authors. Based on the collaboration capacity framework, we focused on the relationship between collaboration network size and research productivity and the role of CI-enabled data repositories in accelerating collaboration capacity. Our preliminary results show that the size of CI-enabled collaboration networks at data creation stage was positively related to research productivity as measured by sequence data production, and the extent and rate of knowledge diffusion, represented by patent applications. Shrinking time gaps between data submissions and patent applications support the hypothesis that CI-enabled data repositories are an accelerating factor in incremental collaboration capacity.; Metadata -- Metadata remains the solution for describing the explosively growing, complex world of digital information, and continues to be of paramount importance for information professionals. Providing a solid grounding in the variety and interrelationships among different metadata types, Zeng and Qin's thorough revision of their benchmark text offers a comprehensive look at the metadata schemas that exist in the world of library and information science and beyond, as well as the contexts in which they operate. Cementing its value as both an LIS text and a handy reference for professionals already in the field, this book    --lays out the fundamentals of metadata, including principles of metadata, structures of metadata vocabularies, and metadata descriptions;    --surveys metadata standards and their applications in distinct domains and for various communities of metadata practice;    --examines metadata building blocks, from modeling to defining properties, and from designing application profiles to implementing value vocabularies;    --describes important concepts as resource identification, metadata as linked data, consumption of metadata, interoperability, and quality measurement; and   -- offers an updated glossary to help readers navigate metadata's complex terms in easy-to-understand definitions.An online resource of web extras, packed with exercises, quizzes, and links to additional materials, completes this definitive primer on metadata.; Structures and Relations of Knowledge Nodes: -- The vast amount of DNA sequence and protein data are being explored and linked to diseases as causative factors to support clinical and healthcare decision making. These developments in data-intensive biological sciences and clinical practices raised new questions for knowledge organization systems (KOS), and taxonomies in particular. Sitting at the center of these questions is the lagging of KOS’s capabilities in responding to the rapidly changing and emerging  biomedical and disease terms due to the static, hierarchical structures and disconnection with new disease data fin traditional KOSs. This paper reports a pilot study that is designed to uncover and identify the types of knowledge nodes and relationships that can help generalize a framework or model for building a Knowledge Network of Disease, or the New Taxonomy envisaged by theNational Academy of Science. This pilot study examined a sample of biomedicalpublications and drew a knowledge map to lay out the main knowledge nodes and their relationships. A preliminary framework for constructing the Knowledge Network of Disease is discussed.; A relation typology in knowledge organization systems: -- Relations between concepts (and/or entities, events, and other things) vary depending on the criteria by which relations are defined or viewed. In the domain of research data management, different types of research generate different types of data and terminologies vary between practitioners and basic science researchers even within the same disciplinary domain. Interactions between datasets, between datasets and documentation, and between datasets and computing code can result in different types of relations. This paper employs a framework of analysis to study concept relation types in the research data management domain.  By using two cases – one is the GenBank annotation records and the other is the data and artifact collection from a gravitational wave search, this paper demonstrates the types of relations existing in and between datasets, publications, computing codes, and workflows. The analysis and generalization of these relations references the research in AI’s knowledge representation and knowledge organization systems (KOS), including both ad hoc subject categories and formal KOS, because in the next AI era, relations as one of the key components of AI applications will be required to function not only as part of KOS for indexing data and publications, but more importantly, to function as codifiable knowledge for machine consumption. ; Special Issue: Visualizing the (Data) Future. -- As libraries and academic institutions evolve into “data-driven” organizations, they are looking for meaningful ways in which to convey their data to funding and regulatory agencies, licensing and accreditation boards, and institutional students, faculty and staff. This data-driven culture is being integrated into all facets of library operations, and data visualization services is emerging as a distinct library research and service development area.; Detection of Knowledge Nodes and Relations -- A bottleneck problem in detecting knowledge nodes and their relations is how to extract accurately and correctly and codify the complex knowledge assertions from full-text documents (human intelligence) into the format of “machine intelligence” (computer-processable knowledge assertions). This paper reports a preliminary study that aims at this bottleneck problem by starting from the fundamentals of KR—representing knowledge from full-text documents by using knowledge node and rela-tion recognition methods and tools. We collected data from full-text biomedical research publications and used manual and automatic tools to investigate the strengths and limitations of these methods. The findings show that MetaMap did a better job in detecting concepts from texts while SemRep is capable of extract relations between k-nodes. The paper presents the findings from the perspectives of degree of abstraction, types of k-nodes and relations, and linguistic structures and the eval-uation results using the BLEU and cosine similarity measures. ; Knowledge node and relation detection -- A bottleneck problem in detecting knowledge nodes and their relations is how to extract accurately and correctly and codify the complex knowledge assertions from full-text documents (human intelligence) into the format of ""machine intelligence"" (computer-processable knowledge assertions). This paper reports a preliminary study that aims at this bottleneck problem by starting from the fundamentals of KR-representing knowledge from full-text documents by using knowledge node and relation recognition methods and tools. We collected data from full-text biomedical research publications and used manual and automatic tools to investigate the strengths and limitations of these methods. The findings show that MetaMap did a better job in detecting concepts from texts while SemRep is capable of extract relations between k-nodes. The paper presents the findings from the perspectives of degree of abstraction, types of k-nodes and relations, and linguistic structures and the evaluation results using the BLEU and cosine similarity measures.; Technical and policy underpinnings of FAIR data principles -- At the trajectory of exponential data growth and FAIR (Findable, Accessible, Interoperable and Re-usable) requirements, organizations face the data management and publishing challenges in support of effective data discovery and publishing activities. This panel brings researchers and practitioners who have researched and practiced in managing datasets and providing discovery services to share their experience and expertise in addressing the challenges and proactively responding to trends in research data management, curation, sharing, and reuse.; How portable are the metadata standards for scientific data? A proposal for a metadata infrastructure -- The one-covers-all approach in current metadata standards for scientific data has serious limitations in keeping up with the ever-growing data. This paper reports the findings from a survey to metadata standards in the scientific data domain and argues for the need for a metadata infrastructure. The survey collected 4400+ unique elements from 16 standards and categorized these elements into 9 categories. Findings from the data included that the highest counts of element occurred in the descriptive category and many of them overlapped with DC elements. This pattern also repeated in the elements co-occurred in different standards. A small number of semantically general elements appeared across the largest numbers of standards while the rest of the element co-occurrences formed a long tail with a wide range of specific semantics. The paper discussed implications of the findings in the context of metadata portability and infrastructure and pointed out that large, complex standards and widely varied naming practices are the major hurdles for building a metadata infrastructure.; Functional and architectural requirements for metadata -- The tremendous growth in digital data has led to an increase in metadata initiatives for different types of scientific data, as evident in Ball's survey (2009). Although individual communities have specific needs, there are shared goals that need to be recognized if systems are to effectively support data sharing within and across all domains. This paper considers this need, and explores systems requirements that are essential for metadata supporting the discovery and management of scientific data. The paper begins with an introduction and a review of selected research specific to metadata modeling in the sciences. Next, the paper's goals are stated, followed by the presentation of valuable systems requirements. The results include a base-model with three chief principles: principle of least effort, infrastructure service, and portability. The principles are intended to support ""data user"" tasks. Results also include a set of defined user tasks and functions, and applications scenarios.; Linking entities in scientific metadata -- Linked entity data in metadata records builds a foundation for the Semantic Web. Even though metadata records contain rich entity data, there is no linking between associated entities such as persons, datasets, projects, publications, or organizations. We conducted a small experiment using the dataset collection from the Hubbard Brook Ecosystem Study (HBES), in which we converted the entities and their relationships into RDF triples and linked the URIs contained in RDF triples to the corresponding entities in the Ecological Metadata Language (EML) records. Through the transformation program written in XML Stylesheet Language (XSL), we turned a plain EML record display into an interlinked semantic web of ecological datasets. The experiment suggests a methodological feasibility in incorporating linked entity data into metadata records. The paper also argues for the need for change in the scientific as well as the general metadata paradigm.; Knowledge Organization and Representation under the AI Lens -- This paper compares the paradigmatic differences between knowledge organization (KO) in library and information science and knowledge representation (KR) in AI to show the convergence in KO and KR methods and applications. The literature review and comparative analysis of KO and KR paradigms is the primary method used in this paper. A key difference between KO and KR lays in the purpose of KO is to organize knowledge into certain structure for standardizing and/or normalizing the vocabulary of concepts and relations, while KR is problem-solving oriented. Differences between KO and KR are discussed based on the goal, methods, and functions. This is only a preliminary research with a case study as proof of concept. The paper articulates on the opportunities in applying KR and other AI methods and techniques to enhance the functions of KO. Ontologies and linked data as the evidence of the convergence of KO and KR paradigms provide theoretical and methodological support to innovate KO in the AI era.; Conceptual models and ontological schemas for semantically sustainable digital libraries -- Semantic frameworks build foundations for digital libraries and repositories to enable structured data and information representation and interoperability in today's interlinked information systems. Conceptual modeling and ontological schemas provide effective communication and powerful tools for creating shared understanding and sustainable systems in various digital libraries. This panel will present cases in which conceptual modeling and ontologies are used to enrich content representation and reach consensus among communities of practice, especially in fast changing digital society and emerging application domains. Four experts in knowledge organization will first give a brief introduction for their research in conceptual modeling and ontology building and then engage the audience with question answering interactions.; Data management -- This poster presents the preliminary results from a survey on the data management practices of graduate students. We investigate what graduate students know about data management from the technical aspects such as the familiarity and use of tools and technologies along with their participation and familiarity with data standards and policies. Preliminary data shows that graduate students lack awareness of data management policies, technologies, and practices when it comes to storing, accessing, and sharing data. The aim of this work is to provide insight on the data literacy needs of graduate students."
Joon S Park,"Enhancing risk-based decisions by leveraging cyber security automation -- Due to the large scale, complex and dynamic state of cyber environments, the exponential growth of vulnerabilities and the advanced persistent threat to information systems, automation is indispensable to support cyber security. Although automation is already an integral part of many cyber security operations, there still are challenges to overcome to fully achieve Information Security Continuous Monitoring (ISCM) capabilities: real-time threat detection, incident response and risk-based decision making capabilities. Our ongoing research seeks to further refine our ISCM framework with specific emphasis to enhance risk-based decision making by leveraging security automation.; Security Automation for Information Security Continuous Monitoring -- Although automation is already an integral part of many cyber security operations, there still are challenges to overcome to fully achieve Information Security Continuous Monitoring (ISCM) capabilities: real-time threat detection, incident response and risk-based decision making capabilities. Our ongoing research seeks to further refine our framework to enhance ISCM capabilities by leveraging security automation.; Leveraging information security continuous monitoring for cyber defense -- Cyber infrastructures are constantly under siege by attackers attempting to exploit vulnerabilities. Despite efforts and significant resources expended to protect cyber systems, attackers continue to launch attacks and compromise information systems. Attacks often go unnoticed or security professionals are unable to fully determine the extent of the compromise at the time of attack. Therefore, an earlier awareness and remediation of a security condition can narrow the window of opportunity for an adversary to attack. Considering the large scale of cyber infrastructure, the use of technology in security operations is a critical component for cyber defense. In this research, as part of technology enabled security operation, we analyze the information security continuous monitoring mechanisms and discuss how to leverage them more effectively with extension for cyber defense. In particular, we focus on security controls, security automation, security data, risk scoring, security measurement and situational awareness. Based on our analyses, we will compare the tradeoffs, discuss the challenges for improvements, and present the future strategies for information security continuous monitoring.; Security challenges and countermeasures for trusted virtualized computing environments -- Today, virtualization technology is ubiquitously woven into nearly every technical field and conversation, taking place in the world of Information Technology (IT), because it can provide various benefits in terms of cost effectiveness, availability, hardware utilization, resource protection, remote access, and other capability enhancements. As a result, the implications of virtual computing environments become profound and drive a shift in the fundamentals of information systems design, operation, and management. However, virtualization also introduces new challenges and concerns related to implementing secure virtualized computing environments. Therefore, in this paper we first discuss common exploits of security properties in virtualized computing environments and analyze their security vulnerabilities from the perspective of attackers. Consequently, we identify and discuss the main areas of virtualized information system design and operation in which security concerns must be addressed. Finally, we present our recommendations and future trends for trusted virtualized computing environments.; Cyber-Assurance Through Embedded Security for the Internet of Things -- The Internet of Things (IoT) comprises billions of Internet-connected devices (ICD) or ""things"", each of which can sense, communicate, compute, and potentially actuate and can have intelligence, multimodal interfaces, physical/virtual identities, and attributes. Cyber-assurance is the justified confidence that networked systems are adequately secure to meet operational needs, even in the presence of attacks, failures, accidents, and unexpected events. The cyber-assurance recognition strategy is to define only the service-level interfaces and leave out domain-specific implementation details. Once the recognition of a cyber-attack has been identified from the recognition process, the fortification process takes place. Reestablishment is a means to return the ICDs to its operational condition after the cyber-attack through remapping to a different route since the ICD was under attack. When the IoT technologies are used as part of mission critical systems, the IoT services should be survivable in order to support the important missions.; The strategies for critical cyber infrastructure (CCI) protection by enhancing software assurance -- Modern organizations are becoming more reliant on complex, interdependent, integrated information systems. Key national industries are the critical infrastructure (CI) and include telecommunications, energy, healthcare, agriculture, and transportation. These CI industries are becoming more dependent on a critical cyber infrastructure (CCI) of computer information systems and networks, which are vital to the continuity of the economy. Organized attackers are increasing in number and power with more powerful computing resources that increasingly threaten CCI software systems. The motivations for attacks range from terrorism, fraud, identity theft, espionage, and political activism. Government and industry research have found that most cyber attacks exploited known vulnerabilities and common software programming errors. Software publisher vendors have been unable to agree or implement a secure coding standard for two main reasons. The on-technical consumer is ill informed to demand secure quality products. These current conditions perpetuate preventable risk. As a result, software vendors do not implement security unless specifically required by the customer, leaving many systems full of gaps. Since most of exploited vulnerabilities are preventable, the implementation of a minimum level of software quality is one of the key countermeasures for protecting the critical information infrastructure. Government and industry can improve the resilience of the CI in an increasingly interdependent network of information systems by protecting the CCI with stronger software assurance practices and policies and strengthening product liability laws and fines for non-compliance. In this paper we discuss the increasing software and market risks to CCI and address the strategies to protect the CCI through enhancing software assurance practices and policies.; A security analysis on apple pay -- Although the new mobile payment service can provide users with various benefits, it also introduces new security concerns and vulnerabilities. In this paper we analyze the security features in one of the most popular mobile payment services, Apple Pay, and discuss possible ways to make it more reliable. Furthermore, once we delve into security vulnerabilities in Apple Pay we propose the possible solutions along with their implementation to overcome the security concerns in the service.; Towards trusted mobile payment services: a security analysis on Apple Pay -- ; A binary vote based comparison of simple majority and hierarchical decision for survivable networks -- Nodes are replicated in fault-tolerant networks not only to increase the aggregate decision reliability but also to survive the failure of a subset of those nodes. A simple majority rule is the most common aggregate decision rule. One may believe that a simple majority rule may not be optimal when node replication is performed in organization following a hierarchical structure like a corporation or a military command. This research shows that if the node's observations are better than random, then a simple majority rule is better than a hierarchical decision. Moreover, even though there are a few compromised nodes that falsify their vote, a simple majority rule will still be superior. However, a hierarchical decision process is more scalable and the vote can be aggregated faster. This paper also proposed a technique based on the law of diminishing marginal utility to calculate the optimum number of nodes in a decision process.; Game theoretic modeling of security and interdependency in a public cloud -- As cloud computing thrives, many small organizations are joining a public cloud to take advantage of its multiple benefits. Cloud computing is cost efficient, i.e., cloud user can reduce spending on technology infrastructure and have easy access to their information without up-front or long-term commitment of resources. Moreover, a cloud user can dynamically grow and shrink the resources provisioned to an application on demand. Despite those benefits, cyber security concern is the main reason many large organizations with sensitive information such as the Department of Defense have been reluctant to join a public cloud. This is because different public cloud users share a common platform such as the hypervisor. A common platform intensifies the well-known problem of cyber security interdependency. In fact, an attacker can compromise a virtual machine (VM) to launch an attack on the hypervisor which if compromised can instantly yield the compromising of all the VMs running on top of that hypervisor. Therefore, a user that does not invest in cyber security imposes a negative externality on others. This research uses the mathematical framework of game theory to analyze the cause and effect of interdependency in a public cloud platform. This work shows that there are multiple possible Nash equilibria of the public cloud security game. However, the players use a specific Nash equilibrium profile depending on the probability that the hypervisor is compromised given a successful attack on a user and the total expense required to invest in security. Finally, there is no Nash equilibrium in which all the users in a public cloud will fully invest in security.; Replication and diversity for survivability in cyberspace -- An effective defense-in-depth avoids a large percentage of threats and defeats those threats that turn into attacks. When an attack evades detection, it may disrupt the systems and networks, and then the need for survivability is more critical. In this context, mission assurance seeks to ensure that critical mission essential functions (MEFs) survive and fight through the attacks against the underlying cyber infrastructure. Survivability represents the quantified ability of a system, subsystem, equipment, process, or procedure to function continually during and after a disturbance. US Air Force systems carry varying survivability requirements depending on MEF's criticality and protection conditions. Almost invariably, however, replication of a subsystem, equipment, process, or procedure is necessary to meet a system's survivability requirements. Therefore, the degree of replication within a system can be paramount for MEF's survival. Moreover, diversity will prevent the same fault or attack from damaging all the replicas so that they can continue the mission. This research shows that the more dangerous vulnerabilities (that affect more replicas) in a system are sometimes less likely to be exploited. The attacker may be better off when exploiting small vulnerabilities because they will be less protected by the defender. In fact, diversity always gives extra challenges to attackers. This work uses the mathematical framework of game theory to show the significance of replica diversity for mission survival in cyberspace.; A game theoretic approach for modeling optimal data sharing on Online Social Networks -- Today, Online Social Network (OSN) services have evolved as the highest-growing medium, enabling various online activities on one platform. However, they also bring new threats and privacy issues to the community. In a reliable OSN service, a user should be able to set up his or her desired level of information sharing with a certain group of other users. Unfortunately, there are attackers that may attempt to expose OSN users' private information or conceal the information that the user would like to share with other users. Therefore, in this paper, we propose a game theoretic approach for helping OSN users determine their optimum policy on OSNs in terms of data sharing, based on a two-player (i.e., agent and opponent) zero-sum Markov game model.; Surviving in cyberspace -- As information systems become ever more complex and the interdependence of these systems increases, a mission-critical system should have the fight-through ability to sustain damage yet survive with mission assurance in cyberspace. To satisfy this requirement, in this paper we propose a game theoretic approach to binary voting with a weighted majority to aggregate observations among replicated nodes. Nodes are of two types: They either vote truthfully or are malicious and thus lie. Voting is strategically performed based on a node's belief about the percentage of compromised nodes in the system. Voting is cast as a stage game model that is a Bayesian Zero-sum game. In the resulting Bayesian Nash equilibrium, if more than a critical proportion of nodes are compromised, their collective decision is only 50% reliable; therefore, no information is obtained from voting. We overcome this by formalizing a repeated game model that guarantees a highly reliable decision process even though nearly all nodes are compromised. A survival analysis is performed to derive the total time of mission survival for both a one-shot game and the repeated game. Mathematical proofs and simulations support our model.; Security and interdependency in a public cloud -- As cloud computing thrives, many organizations - both large and small - are taking advantage of the multiple benefits of joining a public cloud. Public cloud computing is cost-effective: a cloud user can reduce spending on technology infrastructure and have easy access to their information without an up-front or long-term commitment of resources. Despite such benefits, concern over cyber security deters many large organizations with sensitive information to use a public cloud such as the Department of Defense. This is because different public cloud users share a common platform such as the hypervisor. An attacker can compromise a virtual machine (VM) to launch an attack on the hypervisor which, if compromised, can instantly yield the compromising of all the VMs running on top of that hypervisor. In this paper we evaluate the cloud user-attacker dynamic using game theory, which models competition among rational agents. This work will show that there are multiple Nash equilibria of the public cloud game. The Nash equilibrium profile that results will be shown to depend on several factors, including the probability that the hypervisor is compromised given a successful attack on a user and the total expense required to invest in security.; Wearable IoT Computing -- By 2020, consumer data collected from wearable devices are estimated to drive 5% of sales from the Global 1000 and the number of smartphone applications (apps) requesting to share consumer data will increase twofold by 2015, indicating a rise in the number of marketers or proprietors who seek access to customer profile data. As human computer interaction (HCI) emerged as a recognized field of study, the philosophical cognition structure was thought to be sufficient. It was assumed that we could apply computational terms to a model of how the mind works. Emotions also play a role in users' level of sharing of data via social networking. Voluntarily, developers and applications publishers should change the opt-out standard to one that depends on a user opting in. As crime increasingly penetrates the wearable mobile computing market, efforts to crack down comprehensively may produce widespread active collaboration with other sorts of pernicious hackers.; Towards trusted data management in online social network (OSN) services -- In this research, we analyze the privacy and security vulnerabilities in current OSN services. Furthermore, we develop a framework that can provide trusted data management in OSN services.; Trusted Online Social Network (OSN) services with optimal data management -- Online Social Network (OSN) services have rapidly grown into a wide network and offer users a variety of benefits. However, they also bring new threats and privacy issues to the community. Unfortunately, there are attackers that attempt to expose OSN users' private information or conceal the information that the user desire to share with other users. Therefore, in this research we develop a framework that can provide trusted data management in OSN services. We first define the data types in OSN services and the states of shared data with respect to Optimal, Under-shared, Over-shared, and Hybrid states. We also identify the facilitating, detracting, and preventive parameters that are responsible for the state transition of the data. In a reliable OSN service, we address that a user should be able to set up his or her desired level of information sharing with a certain group of other users. However, it is not always clear to the ordinary users how to determine how much information they should reveal to others. In order to support such a decision, we propose an approach for helping OSN users to determine their optimum levels of information sharing, taking into consideration the payoffs (potential Reward or Cost) based on the Markov decision process (MDP). As an extension of the MDP-based approach, we also introduce a game theoretic approach, considering the interactions of OSN users and attackers with conflicting interests whose decisions affect each other's. Finally, after developing the framework for the optimal data sharing on OSNs, we conduct several experiments with attack simulation based on the proposed ideas and discuss the results. Our proposed approach has the capability to allow a large amount of variables to be altered to suit particular setups that an organization might have.; Near-real-time cloud auditing for rapid response -- Due to the rapid emergence of Information Technology, cloud computing provides assorted advantages to service providers, developers, organizations, and customers with respect to scalability, flexibility, cost-effectiveness, and availability. However, it also introduces new challenges and concerns, especially in terms of security and privacy. One of the major security obstacles to widespread adoption of cloud computing is the lack of near-real-time audit ability. In particular, near-real-time cloud auditing, which provides timely evaluation results and rapid response, is the key to assuring the cloud. In this paper, we discuss security and privacy concerns in cloud computing and the current status of cloud auditing efforts. Next, we address the strategies for reliable cloud auditing and analyze the deficiencies of current approaches. We then discuss the summary of our case study with Amazon Cloud Watch, which is one of the most developed cloud-monitoring APIs.; Component survivability at runtime for mission-critical distributed systems -- As information systems develop into larger and more complex implementations, the need for survivability in mission-critical systems is pressing. Furthermore, the requirement for protecting information systems becomes increasingly vital, while new threats are identified each day. It becomes more challenging to build systems that will detect such threats and recover from the damage. This is particularly critical for distributed mission-critical systems, which cannot afford a letdown in functionality even though there are internal component failures or compromises with malicious codes, especially in a downloaded component from an external source. Therefore, when using such a component, we should check to see if the source of the component is trusted and that the code has not been modified in an unauthorized manner since it was created. Furthermore, once we find failures or malicious codes in the component, we should fix those problems and continue the original functionality of the component at runtime so that we can support survivability in the mission-critical system. In this paper, we define our definition of survivability, discuss the survivability challenges in component-sharing in a large distributed system, identify the static and dynamic survivability models, and discuss their trade-offs. Consequently, we propose novel approaches for component survivability. Finally, we prove the feasibility of our ideas by implementing component recovery against internal failures and malicious codes based on the dynamic model.; Optimal state management of data sharing in Online Social Network (OSN) services -- Although Online Social Network (OSN) services offer users a variety of benefits, they also bring new threats and privacy issues to the community. In this paper, we first define the data types in OSN services and the states of shared data with respect to Optimal, Under-shared, Over-shared, and Hybrid states. We also identify the facilitating, detracting, and preventive parameters that are responsible for the state transition of the data. We address that, in a reliable OSN service, a user should be able to set up his or her desired level of information sharing with a certain group of other users. However, it is not always clear to the ordinary users how to decide how much information they should reveal to others. Therefore, we propose an approach for helping OSN users determine their optimum levels of information sharing, taking into consideration the payoffs (potential Reward or Cost) based on the Markov decision process (MDP).; Active access control (AAC) with fine-granularity and scalability -- Strong access control mechanisms become most critical when we need security services in large-scale computing environments of sensitive organizations. Furthermore, if users join or leave such computing environment frequently, requiring different access control decisions based on their current job responsibilities and contexts, the need for advanced access control is pressing. Although the currently available access control approaches have a great potential for providing reliable service, there are still critical obstacles to be solved, especially in large-scale, dynamic computing environments. In this paper we introduce an advanced access control mechanism, Active Access Control (AAC), which accounts for the ability to make dynamic access control decisions based not only on pre-defined privileges, but also on the current situation of the user. The framework of the proposed AAC approach provides fine-grained access control, by considering a variety of attributes about the user and the current computing environment, especially, when the users contexts are frequently changed. Although the outputs of the AAC approach can be integrated with any other existing access control mechanisms and improve the overall fine-granularity, as a full demonstration of our approach for fine-granularity as well as scalability, in this particular paper we focus on large-scale computing environments and integrate the AAC results with the role-based approach. Finally, in order to prove the feasibility of our proposed idea we implement the AAC approach with roles and discuss the evaluation results with existing approaches.; Active Access Control System and Method -- A method of dynamically assigning a role to a user in a distributed computing environment can comprise the steps of: defining one or more roles and their respective threshold trust values; defining one or more attributes and their respective weight coefficients; determining current values of the attributes for the user; calculating a current level of trust for the user, based on the attribute values and the weight coefficients; and assigning a role to the user based on the current level of trust and the threshold values.; Role-Based Access Control to Computing Resources in an Inter-Organizational Community -- A method for controlling access to a plurality of computing resources in a distributed computing environment can comprise the steps of: an application role server, responsive to receiving a certificate request, authenticating the requester and issuing a digital certificate to the requester; an access control node, responsive to receiving a resource access request, granting access to the computing resource to the requester upon ascertaining the requestor's access privileges, or forwarding the resource access request to another access control node.; System and Apparatus for Storage and Transfer of Secure Data on the Web -- ; An analysis of security features on web browsers -- Today, while Web browsers are widely used to access the Internet resources, there are constant attempts to find exploits and vulnerabilities that can compromise the user’s security and privacy. In this paper, we analyze the security features provided by the most popular browsers, including Chrome, Internet Explorer, Firefox, Safari, and Opera, with our hands-on experiments and discuss how these features can enhance the security and privacy for users. We identify and analyze the security features in the browsers, considering the concept of sandbox isolation, plug-ins, password storage/synchronization, Google Safe Browsing, private browsing, cookie management, and other security/privacy related features. We believe our work will help users to choose a right browser for their purposes as well as protect their sensitive data and personal information on the Web. Furthermore, our findings and comparison will help the browser developers to improve the quality and security of their future products and services.; Online Behavioral Advertising (OBA) with privacy protection -- The introduction of Online Behavioral Advertising (OBA) to the world of Internet advertising has considerably increased the revenues of advertising companies. Prospectively, it is being considered as an approach that will be used for a long-term strategy by the industry. Therefore, the privacy protection of consumers should be one of the core building blocks for the framework that is employed in the process of collecting and aggregating the information regarding the users. However, this is not the case in the current OBA environment and hence concerns are being raised surrounding this issue. In this paper we propose a generic, secure OBA framework that can be applied to the industry, promoting the online market under the criteria of preserving the privacy of the users.; Game theoretic attack analysis in Online Social Network (OSN) services -- In the social media era, the ever-increasing utility of Online Social Networks (OSN) services provide a variety of benefits to users, organizations, and service providers. However, OSN services also introduce new threats and privacy issues regarding the data they are dealing with. For instance, in a reliable OSN service, a user should be able to set up his desired level of information sharing and securely manage sensitive data. Currently, few approaches exist that can model OSNs for the purpose, let alone model the effects that attackers can have on these networks. In this work a novel OSN modeling approach is presented to fill the gap. This model is based on an innovative game theoretical approach and it is analyzed both from a theoretical and simulation-oriented view. The game theoretic model is implemented in order to analyze several attack scenarios. As the results show, there are several scenarios where OSN services are very vulnerable and hence more protection mechanisms should be provided in order to secure the data contained across these networks.; Social network attack simulation with honeytokens -- In the social media era, the ever-increasing utility of Online Social Networks (OSN) services provide a variety of benefits to users, organizations, and service providers. However, OSN services also introduce new threats and privacy issues regarding the data they are dealing with. For instance, in a reliable OSN service, a user should be able to set up his desired level of information sharing and securely manage sensitive data. Currently, few approaches exist that can model OSNs for the purpose, let alone a model the effects that attackers can have on these networks. In this work a novel OSN modeling approach is presented to fill the gap. This model is based on an innovative game-theoretic approach and it is analyzed both from a theoretical and simulation-oriented view. The game-theoretic model is implemented to analyze several attack scenarios. Honeytokens, which are an information security tool based upon deception, are defined and identified as a security tool that could help in OSN security. As the results show, there are several scenarios where OSN services are very vulnerable and hence more protection mechanisms should be provided to secure the data contained across these networks, including the use of honeytokens. In this work we introduce a novel OSN modeling approach for optimal data sharing based on innovative game theories, considering the states/optimal policies of data sharing on OSNs and possible confrontations between the attacker and the user. After we develop the theoretical framework, we conduct experiments, integrating our ideas with honeytokens in several attack scenarios. Finally, we analyze our experimental results and discuss recommendations based on the results."
Joshua Introne,"Wisdom of stakeholder crowds in complex social–ecological systems -- Sustainable management of natural resources requires adequate scientific knowledge about complex relationships between human and natural systems. Such understanding is difficult to achieve in many contexts due to data scarcity and knowledge limitations. We explore the potential of harnessing the collective intelligence of resource stakeholders to overcome this challenge. Using a fisheries example, we show that by aggregating the system knowledge held by stakeholders through graphical mental models, a crowd of diverse resource users produces a system model of social–ecological relationships that is comparable to the best scientific understanding. We show that the averaged model from a crowd of diverse resource users outperforms those of more homogeneous groups. Importantly, however, we find that the averaged model from a larger sample of individuals can perform worse than one constructed from a smaller sample. However, when averaging mental models within stakeholder-specific subgroups and subsequently aggregating across subgroup models, the effect is reversed. Our work identifies an inexpensive, yet robust way to develop scientific understanding of complex social–ecological systems by leveraging the collective wisdom of non-scientist stakeholders.; Harnessing the collective intelligence of stakeholders for conservation -- Incorporating relevant stakeholder input into conservation decision making is fundamentally challenging yet critical for understanding both the status of, and human pressures on, natural resources. Collective intelligence (CI), defined as the ability of a group to accomplish difficult tasks more effectively than individuals, is a growing area of investigation, with implications for improving ecological decision making. However, many questions remain about the ways in which emerging internet technologies can be used to apply CI to natural resource management. We examined how synchronous social-swarming technologies and asynchronous “wisdom of crowds” techniques can be used as potential conservation tools for estimating the status of natural resources exploited by humans. Using an example from a recreational fishery, we show that the CI of a group of anglers can be harnessed through cyber-enabled technologies. We demonstrate how such approaches – as compared against empirical data – could provide surprisingly accurate estimates that align with formal scientific estimates. Finally, we offer a practical approach for using resource stakeholders to assist in managing ecosystems, especially in data-poor situations.; A sociotechnical mechanism for online support provision -- Social support can significantly improve health outcomes for individuals living with disease, and online forums have emerged as an important vehicle for social support. Whereas research has focused on the delivery and use of social support, little is known about how these communities are sustained. We describe one sociotechnical mechanism that enables sustainable communities to provide social support to a large number of people. We focus upon thirteen disease-specific discussion forums hosted by the WebMD online health community. In these forums, small, densely connected cores of members who maintain strong relationships generate the majority of support for others. Through content analysis we find they provide informational support to a large number of more itinerant members, but provide one another with community support. Based on these observations, we describe a sociotechnical mechanism of online support that is distinct from nonsupport oriented communities, and has implications for the design of self-sustaining online support systems.; Designing sustainable online support -- Online social support communities can significantly improve health outcomes for individuals living with disease. Although they are well studied in the literature, little research examines how sociotechnical design changes influence the sustainability of support communities for different medical conditions. We compare the impact of a single design change on 49 disease-specific health support forums hosted on the WebMD platform, a popular online health information service. A statistical analysis showcases changes in posting patterns before and after the design intervention; a subsequent interpretive examination of forum content reveals how the design change affected members' perceived affordances of the platform. Our findings suggest that, despite differences between communities, the design change triggered a common set of cascading effects: it made it difficult for core users to create and maintain relationships, that led them to ultimately leave the site, and, in turn, reduced the activity drawing newcomers to the platform. Using these findings, we argue that the design of sustainable and robust online communities must account for systemic, sociotechnical dynamics.; Mapping the Narrative Ecosystem of Conspiracy Theories in Online Anti-vaccination Discussions -- Recent research on conspiracy theories labels conspiracism as a distinct and deficient epistemic process. However, the tendency to pathologize conspiracism obscures the fact that it is a diverse and dynamic collective sensemaking process, transacted in public on the web. Here, we adopt a narrative framework to introduce a new analytical approach for examining online conspiracism. Narrative plays an important role because it is central to human cognition as well as being domain agnostic, and so can serve as a bridge between conspiracism and other modes of knowledge production. To illustrate the utility of our approach, we use it to analyze conspiracy theories identified in conversations across three different anti-vaccination discussion forums. Our approach enables us to capture more abstract categories without hiding the underlying diversity of the raw data. We find that there are domit narrative themes across sites, but that there is also a tremendous amount of diversity within these themes. Our initial observations raise the possibility that different communities play different roles in the collective construction of conspiracy theories online. This offers one potential route for understanding not only cross-sectional differentiation, but the longitudinal dynamics of the narrative in future work. In particular, we are interested to examine how activity within the framework of the narrative shifts in response to news events and social media platforms' nascent efforts to control different types of misinformation. Such analysis will help us to better understand how collectively constructed conspiracy narratives adapt in a shifting media ecosystem."
Kevin G Crowston,"Lightning talk -- Software is fundamental to academic research work, both as part of the method and as the result of research. In June 2016 25 people gathered at Schloss Dagstuhl for a week-long Perspectives Workshop and began to develop a manifesto which places emphasis on the scholarly value of academic software and on personal responsibility. Twenty pledges cover the recognition of academic software, the academic software process and the intellectual content of academic software. This is still work in progress. Through this lightning talk, we aim to get feedback and hone these further, as well as to inspire the WSSSPE audience to think about actions they can take themselves rather than actions they want others to take. We aim to publish a more fully developed Dagstuhl Manifesto by December 2016.; Alternative genres of IS research -- The potential value of alternative genres in IS research is the core question that drives this panel discussion. The term ""Alternative Genres"" refers to unconventional forms of thinking, doing, and communicating scholarship and practice. It relates to innovation with respect to epistemological perspectives, research methods, semantic framing, literary styles, and media of expression. Overall, the application of alternative genres is considered to be a generative act that provides an opportunity to take a fresh look and to gain deeper understanding of the subject matter. Nonetheless, paradoxically the prevailing genres have much inertia, in spite of the inherent boundary spanning nature of alternative genres. Building on their own recent empirical research, the panelists will debate the potential value of alternative genres as unconventional modality of IS scholarship and how alternative genres might be utilized to support the discipline's the next leap forward.; Stigmergic coordination in FLOSS development teams -- The vast majority of literature on coordination in team-based projects has drawn on a conceptual separation between explicit (e.g. plans, feedback) and implicit coordination mechanisms (e.g. mental maps, shared knowledge). This analytic distinction presents some limitations in explaining how coordination is reached in organizations characterized by distributed teams, scarce face to face meetings and fuzzy and changing lines of authority, as in free/libre open source software (FLOSS) development.Analyzing empirical illustrations from two FLOSS projects, we highlight the existence of a peculiar model, stigmergic coordination, which includes aspects of both implicit and explicit mechanisms. The work product itself (implicit) and the characteristics under which it is shared (explicit) play an under-appreciated role in helping software developers manage dependencies as they arise. We develop this argument beyond the existing literature by working with an existing coordination framework, considering the role that the codebase itself might play at each step. We also discuss the features and the practices to support stigmergic coordination in distributed teams, as well as recommendations for future research.; GitLab -- GitLab is a software company that works “all remote” at the scale of more than 1000 employees located in more than 60 countries. GitLab has no physical office and its employees can work from anywhere they choose. Any step of the organizational life of a GitLab employee (e.g., hiring, onboarding and firing) is performed remotely, except for a yearly companywide gathering. GitLab strongly relies on asynchronous coordination, allowing employees to work anytime they want. After highlighting some of the main practices implemented by GitLab to effectively work all remotely and asynchronously, I asked renowned organizational scientists their thoughts on this interesting case and to question the generalizability of the all remote asynchronous model. Understanding whether and under what conditions this model can succeed can be of guidance for organizational designers that are now considering different remote models in response of the COVID-19 shock and its aftermath.; Classifying the unknown -- The observation of gravitational waves from compact binary coalescences by LIGO and Virgo has begun a new era in astronomy. A critical challenge in making detections is determining whether loud transient features in the data are caused by gravitational waves or by instrumental or environmental sources. The citizen-science project Gravity Spy has been demonstrated as an efficient infrastructure for classifying known types of noise transients (glitches) through a combination of data analysis performed by both citizen volunteers and machine learning. We present the next iteration of this project, using similarity indices to empower citizen scientists to create large data sets of unknown transients, which can then be used to facilitate supervised machine-learning characterization. This new evolution aims to alleviate a persistent challenge that plagues both citizen-science and instrumental detector work: the ability to build large samples of relatively rare events. Using two families of transient noise that appeared unexpectedly during LIGO's second observing run, we demonstrate the impact that the similarity indices could have had on finding these new glitch types in the Gravity Spy program.; A capability maturity model for scientific data management -- In this poster, we propose a capability-maturity model (CMM) for scientific data management that includes a set of process areas required for data management, grouped at three levels of organizational capability maturity. The goal is to provide a framework for comparing and improving project and organizational data management practices.; Is Wikipedia inefficient? Modelling effort and participation in Wikipedia -- Concerns have been raised about the decreased ability of Wikipedia to recruit editors and in to harness the effort of contributors to create new articles and improve existing articles. But, as [1], [2] explained, in collective projects, in the initial stage of the project, people are few and efforts costly; in the diffusion phase, the number of participants grows as their efforts are rewarding; and in the mature phase, some inefficiency may appear as the number of contributors is more than the work requires. In this paper, thanks to original data we extract from 36 of the main language projects, we compare the efficiency of Wikipedia projects in different languages and at different states of development to examine this effect.; Introduction to JAIS special issue on empirical research on free/libre open source software -- ; Minitrack introduction -- ; Wikisym doctoral symposium -- The WikiSym 2010 Doctoral Symposium was held immediately after WikiSym and offered invited Ph.D. students an unparalleled opportunity to present their ongoing work on wikis and open collaboration research. Students received supportive feedback from their peers and a panel of faculty mentors, to help them envision new, added-value contributions to their current research. The symposium also offered a perfect environment for the exchange of information, methodologies, practical experiences and advice that may help Ph.D. students on their way, unleashing potential interactions and opportunities for collaboration.; Shifting boundaries -- The IS field was born as a new discipline of artificial science out of an intellectual chaos at the time when information and communication technologies were beginning to transform modern organizations. Our discipline is now at another pivotal moment as the scope of digital technology grows beyond the organizational realm. The expansion of the influence of digital technology in everyday life provides a critical opportunity-and challenge-to expand the intellectual boundaries of the IS research community beyond the traditional focus of organizational computing. This panel will explore the challenges and potential faced by the IS community as IS researchers seek to explore these emerging uses of information and communications technologies.; Analyzing leadership dynamics in distributed group communication -- We apply social network analysis (SNA) to examine the dynamics of leadership in distributed groups, specifically Free/Libre Open Source Software development projects, and its relation to group performance. Based on prior work on leadership in distributed groups, we identify leaders with those who make the highest level of contribution to the group and assess the degree of leadership by measuring centralization of communications. We compare the dynamics of leadership in two FLOSS projects, one more and one less effective. We find that in both projects, centralization was higher in developer-oriented communications venues than in user-oriented venues, suggesting higher degrees of leadership in developer venues. However, we do not find a consistent relation between centralization and effectiveness. We suggest that SNA can instead be useful for identifying interesting periods in the history of the project, e.g., periods where the leadership of the project is in transition.; Machine learning and rule-based automated coding of qualitative data -- Large volumes of textual data pose considerable challenges for manual qualitative analysis. We explore semi-automatic coding of textual data by leveraging Natural Language Processing (NLP). We compare the performance of human-developed NLP rules to those inferred by machine learning (ML) algorithms. The results suggest that NLP with ML may be useful to support researchers coding qualitative data.; Amazon mechanical turk -- Amazon Mechanical Turk (AMT), a system for crowdsourcing work, has been used in many academic fields to support research and could be similarly useful for information systems research. This paper briefly describes the functioning of the AMT system and presents a simple typology of research data collected using AMT. For each kind of data, it discusses potential threats to reliability and validity and possible ways to address those threats. The paper concludes with a brief discussion of possible applications of AMT to research on organizations and information systems.; Using natural language processing technology for qualitative data analysis -- Social researchers often apply qualitative research methods to study groups and their communications artifacts. The use of computer-mediated communications has dramatically increased the volume of text available, but coding such text requires considerable manual effort. We discuss how systems that process text in human languages (i.e. natural language processing [NLP]) might partially automate content analysis by extracting theoretical evidence. We present a case study of the use of NLP for qualitative analysis in which the NLP rules showed good performance on a number of codes. With the current level of performance, use of an NLP system could reduce the amount of text to be examined by a human coder by an order of magnitude or more, potentially increasing the speed of coding by a comparable degree. The paper is significant as it is one of the first to demonstrate the use of high-level NLP techniques for qualitative data analysis.; Lessons from volunteering and free/libre open source software development for the future of work -- In this paper, we review research on voluntary organizations to identify key features of and problems in volunteer work and organizations. We then use the example of free/libre open source software (FLOSS) development teams to examine how those features and problems apply in this situation and how they might be affected by the use of information and communications technologies (ICT). We suggest that understanding volunteer organizations can illuminate the changing nature of all knowledge work, paid as well as unpaid.; Introduction to the documenting work and working documents minitrack -- ; Free/Libre Open-Source Software development -- We review the empirical research on Free/Libre and Open-Source Software (FLOSS) development and assess the state of the literature.We develop a framework for organizing the literature based on the input-mediatoroutput- input (IMOI) model from the small groups literature. We present a quantitative summary of articles selected for the review and then discuss findings of this literature categorized into issues pertaining to inputs (e.g., member characteristics, technology use, and project characteristics), processes (software development practices, social processes, and firm involvement practices), emergent states (e.g., social states and taskrelated states), and outputs (e.g. team performance, FLOSS implementation, and project evolution). Based on this review, we suggest topics for future research, as well as identify methodological and theoretical issues for future inquiry in this area, including issues relating to sampling and the need for more longitudinal studies.; Introduction to the open movements minitrack -- ; Introduction to digital and social media track -- ; Motivation and data quality in a citizen science game -- Citizen science is a form of social computation where members of the public are recruited to contribute to scientific investigations. Citizen-science projects often use web-based systems to support collaborative scientific activities. However, finding ways to attract participants and ensure the accuracy of the data they produce are key issues in making such systems successful. In this paper we describe the design and preliminary evaluation of a simple game that addresses these two concerns for the task of species identification.; Rejoinder to open access -- This is a commentary as part of the debate on Open Access.; Perceived discontinuities and continuities in transdisciplinary scientific working groups -- We examine the DataONE (Data Observation Network for Earth) project, a transdisciplinary organization tasked with creating a cyberinfrastructure platform to ensure preservation of and access to environmental science and biological science data. Its objective was a difficult one to achieve, requiring innovative solutions. The DataONE project used a working group structure to organize its members. We use organizational discontinuity theory as our lens to understand the factors associated with success in such projects. Based on quantitative and qualitative data collected from DataONE members, we offer recommendations for the use of working groups in transdisciplinary synthesis. Recommendations include welcome diverse opinions and world views, establish shared communication practices, schedule periodic synchronous face-to-face meetings, and ensure the active participation of bridge builders or knowledge brokers such as librarians who know how to ask questions about disciplines not their own.; Social Networks and the Success of Market Intermediaries -- Market intermediaries are usually thought of as bringing together buyers and sellers. However, intermediaries may also connect these principals with other professionals who can provide assistance with and support for the transaction. We address the question of which set of ties—to buyers and sellers or to other professionals—are more important to the success of market intermediaries, using data from the U.S. residential real estate industry. From a national survey of 525 real estate agents, we find that ties to other professionals are more important than ties to buyers and sellers as predictors of the market intermediary's income, counter to the general wisdom about real estate in particular and market intermediaries more generally. We suggest that the professional networks around market intermediaries may behave like “quasi-firms” helping buyers and sellers navigate complex market transactions.; Introduction to the digital and social media track -- ; Response to “ideational influence, connectedness, and venue representation -- I respond to Cueller, Takeda, Vidgen & Truex (2016), who proposes three measures of scholarly output: “1) the extent to which other scholars take up the scholar’s work (ideational influence), 2) who the scholar works with (connectedness), and 3) how well the scholar publishes in venues in the scholar’s field (venue representation)” (p. 3). These are not novel and valid measures of research output. Ideational influence is operationalized as counting citations, which improve current practice but is not novel. Connectedness assesses position in a co-authorship network and rewards the cronies of central players without assessing their output. Venue representation involves counting papers in a different basket, which commits an ecological fallacy. Connectedness and venue representation are based on a common misinterpretation of network centrality measures. Adopting either of these measures in practice would distract from actual impact and so be negative for our field.; Core-periphery communication and the success of free/libre open source software projects -- We examine the relationship between communications by core and peripheral members and Free/Libre Open Source Software project success. The study uses data from 74 projects in the Apache Software Foundation Incubator. We conceptualize project success in terms of success building a community, as assessed by graduation from the Incubator. We compare successful and unsuccessful projects on volume of communication by core (committer) and peripheral community members and on use of inclusive pronouns as an indication of efforts to create intimacy among team members. An innovation of the paper is that use of inclusive pronouns is measured using natural language processing techniques. We find that core and peripheral members differ in their volume of contribution and in their use of inclusive pronouns, and that volume of communication is related to project success.; The future of open source research -- ; Gravity spy -- Gravity Spy is a citizen science project that draws on the contributions of both humans and machines to achieve its scientific goals. The system supports the Laser Interferometer Gravitational Observatory (LIGO) by classifying ""glitches"" that interfere with observations. The system makes three advances on the current state of the art: explicit training for new volunteers, synergy between machine and human classification and support for discovery of new classes of glitch. As well, it provides a platform for humancentred computing research on motivation, learning and collaboration. The system has been launched and is currently in operation.; Inter-team coordination in large-scale agile development -- We draw on Organizational Discontinuity Theory (ODT) to identify factors that increase communication and coordination problems between teams working on large software development projects. ODT posits that faced with a disruption in the expected flow of communication, called a discontinuity, individuals must make sense of the disruption to address the problem. They may be motivated to pay more attention to the situation and consider alternative actions to deal with the discontinuity, leading to the emergence of continuities, which are new behaviors, group practices and expectations. Continuities reduce or eliminate the attention and effort required to understand and manage the situation associated with problematic discontinuities. We propose a mixed-method study based on this model to examine the effects of discontinuities and the development of continuities on interteam coordination in large-scale agile software development.; Stages of motivation for contributing user-generated content -- User-generated content (UGC) projects involve large numbers of mostly unpaid contributors collaborating to create content. Motivation for such contributions has been an active area of research. In prior research, motivation for contribution to UGC has been considered a single, static and individual phenomenon. In this paper, we argue that it is instead three separate but interrelated phenomena. Using the theory of helping behaviour as a framework and integrating social movement theory, we propose a stage theory that distinguishes three separate sets (initial, sustained and meta) of motivations for participation in UGC. We test this theory using a data set from a Wikimedia Editor Survey (Wikimedia Foundation, 2011). The results suggest several opportunities for further refinement of the theory but provide support for the main hypothesis, that different stages of contribution have distinct motives. The theory has implications for both researchers and practitioners who manage UGC projects.; Blending Machine and Human Learning Processes -- Citizen science projects face a dilemma in relying on contributions from volunteers to achieve their scientific goals: providing volunteers with explicit training might increase the quality of contributions, but at the cost of losing the work done by newcomers during the training period, which for many is the only work they will contribute to the project. Based on research in cognitive science on how humans learn to classify images, we have designed an approach to use machine learning to guide the presentation of tasks to newcomers that help them more quickly learn how to do the image classification task while still contributing to the work of the project. A Bayesian model for tracking volunteer learning is presented.; Levels of Trace Data for Social and Behavioural Science Research -- ; Work features to support stigmergic coordination in distributed teams -- When work products are shared via a computer system, members of distributed teams can see the work products produced by remote colleagues as easily as those from local colleagues. Drawing on coordination theory and work in computer-supported cooperative work (CSCW), we theorize that these work products can provide information to support team coordination, that is, that work can be coordinated through the outcome of the work itself, a mode of coordination analogous to the biological process of stigmergy. Based on studies of documents and work, we postulate three features of work products that enable them to support team coordination, namely having a clear genre, being visible and mobile, and being combinable. These claims are illustrated with examples drawn from free/libre open source software development teams. We conclude by discussing how the proposed theory might be empirically tested.; Open Source Technology Development -- ; “Personas” to Support Development of Cyberinfrastructure for Scientific Data Sharing -- ; Impacts of machine learning on work -- The increased pervasiveness of technological advancements in automation makes it urgent to address the question of how work is changing in response. Focusing on applications of machine learning (ML) that automate information tasks, we present a simple framework for identifying the impacts of an automated system on a task. From an analysis of popular press articles about ML, we develop 3 patterns for the use of ML--decision support, blended decision making and complete automation--with implications for the kinds of tasks and systems. We further consider how automation of one task might have implications for other interdependent tasks. Our main conclusion is that designers have a range of options for systems and that automation of tasks is not the same as automation of work.; Coordinating Advanced Crowd Work: Extending Citizen Science -- ; Knowledge Tracing to Model Learning in Online Citizen Science Projects -- We present the design of a citizen science system that uses machine learning to guide the presentation of image classification tasks to newcomers to help them more quickly learn how to do the task while still contributing to the work of the project. A Bayesian model for tracking volunteer learning for training with tasks with uncertain outcomes is presented and fit to data from 12,986 volunteer contributors. The model can be used both to estimate the ability of volunteers and to decide the classification of an image. A simulation of the model applied to volunteer promotion and image retirement suggests that the model requires fewer classifications than the current system.; Socio-technical affordances for stigmergic coordination implemented in MIDST, a tool for data-science teams -- We present a conceptual framework for socio-technical affordances for stigmergic coordination, that is, coordination supported by a shared work product. Based on research on free/libre open source software development, we theorize that stigmergic coordination depends on three sets of socio-technical affordances: the visibility and combinability of the work, along with defined genres of work contributions. As a demonstration of the utility of the developed framework, we use it as the basis for the design and implementation of a system, MIDST, that supports these affordances and that we thus expect to support stigmergic coordination. We describe an initial assessment of the impact of the tool on the work of project teams of three to six data-science students that suggests that the tool was useful but also in need of further development. We conclude with plans for future research and an assessment of theory-driven system design.; FLOSS Project effectiveness measures -- ; MIDST -- We demonstrate MIDST, a system we developed to support stigmergic coordination in data-science teams, that is, coordination supported by a shared work product. To improve coordination, the system supports modularization of an analysis as a workflow, distributed code development and sharing and tracking of task status through a web application.; Effects of Stigmergic and Explicit Coordination on Wikipedia Article Quality -- ; Lessons for supporting data science from the everyday automation experience of spell-checkers -- We apply two theoretical frameworks to analyze spell-checkers as a form of automation and apply the lessons learned to analyze opportunities to support data science. The analysis distinguishes between automation of analysis to suggest actions and automation of implementation of actions. Having the automation work in the same space as users (e.g., editing the same document) supports stigmergic coordination between the two, but attention is needed to ensure that the contributions can be combined and have a recognizable form that indicates their purpose.; Attitudes and norms affecting scientists’ data reuse -- The value of sharing scientific research data is widely appreciated, but factors that hinder or prompt the reuse of data remain poorly understood. Using the Theory of Reasoned Action, we test the relationship between the beliefs and attitudes of scientists towards data reuse, and their self-reported data reuse behaviour. To do so, we used existing responses to selected questions from a worldwide survey of scientists developed and administered by the DataONE Usability and Assessment Working Group (thus practicing data reuse ourselves). Results show that the perceived efficacy and efficiency of data reuse are strong predictors of reuse behaviour, and that the perceived importance of data reuse corresponds to greater reuse. Expressed lack of trust in existing data and perceived norms against data reuse were not found to be major impediments for reuse contrary to our expectations. We found that reported use of models and remotely-sensed data was associated with greater reuse. The results suggest that data reuse would be encouraged and normalized by demonstration of its value. We offer some theoretical and practical suggestions that could help to legitimize investment and policies in favor of data sharing.; Sharing open deep learning models -- We examine how and why trained deep learning (DL) models are shared, and by whom, and why some developers share their models while others do not. Prior research has examined sharing of data and software code, but DL models are a hybrid of the two. The results from a Qualtrics survey administered to GitHub users and academics who publish on DL show that a diverse population shares DL models, from students to computer/data scientists. We find that motivations for sharing include: increasing citation rates; contributing to the collaboration of developing new DL models; encouraging to reuse; establishing a good reputation; receiving feedback to improve the model; and personal enjoyment. Reasons for not sharing include: lack of time; thinking that their models would not be interesting for others; and not having permission for sharing. The study contributes to our understanding of motivations for participating in a novel form of peer-production.; Factors Influencing Approval of Wikipedia Bots -- ; Functional and Visionary Leadership in Self-Managing Virtual Teams -- In this conceptual article, we present a theory of leadership in self-managing virtual teams. We describe leadership in this setting as a process that results in the creation, reinforcement, and evolution of shared mental models and shared norms that influence team member behavior toward the successful accomplishment of shared goals. We distinguish two types of leadership. We identify leadership that works within and reinforces existing models and norms to influence team contributions as “functional” leadership. We identify leadership that results in changes in models and norms as “visionary” leadership. We propose that successful self-managing virtual teams require both types of leadership and that they will exhibit a paradoxical combination of shared, distributed functional leadership complemented by strong, concentrated, and centralized visionary leadership and that visionary leadership is enabled by functional leadership in the form of substantive team member contributions.; Open IS -- The collective intelligence and collective action of ""open"" communities have produced a variety of complex knowledge goods and radical social change. The Information Systems (IS) community has invested significant effort into researching open communities and the ecosystems in which they operate, seeking to better understand these emerging forms of organization, production, innovation, knowledge, and value creation. Ironically, the IS discipline itself has, on the whole, failed to embrace the principles that its own research has repeatedly identified as generative and powerful. This panel therefore seeks to stimulate a thoughtful and dynamic discussion around the proposition that becoming a more open community will enhance the IS discipline's scholarly inquiry and global impact.; How to Write a Collaboration Plan -- Collaboration plans are written documents that investigators may use as a “roadmap” for future collaborations. Funding agencies may ask investigators to submit Collaboration Plans as part of their funding applications, analogous to submitting research plans. Submitted collaboration plans can then be used by reviewers to help assess the capacity of a proposed team to collaboratively execute its scientific objectives. Collaboration plans address a range of issues relevant to laying the foundation for the collaboration, implementing and managing the collaboration, and engaging in quality improvement activities specific to collaborative interactions. These plans identify existing supports and challenges relevant to the collaboration, and describe a program of action that will be implemented to help support smooth collaboration. This working document, called “How to Write a Collaboration Plan” is a product of a federal subcommittee on Collaboration and Team Science. The document provides guidance for writing a collaboration plan. It identifies ten key aspects of collaboration planning, and highlights specific issues for investigators to consider related to each of the ten aspects of planning. Collaboration planning may benefit any scientific endeavor that includes two or more investigators working together. Though as a proposed scientific collaboration grows in scope and size, such plans become increasingly important. More information on the origins of this document: The White House Office of National Science and Technology Policy’s (OSTP) NITRD Program (Networking and Information Technology Research and Development Program) provides a forum where many federal agencies come together to coordinate their networking and information technology (IT) research and development (R&D) efforts. (More information at: https://www.nitrd.gov.) Team Science is of particular interest, given the prevalence of virtual collaboration in IT R&D. In response, the NITRD Coordination Group on Social, Economic, and Workforce Implications of IT and IT Workforce Development (NITRD-SEW), developed a subcommittee on Collaboration and Team Science. The subcommittee includes members from the National Institutes of Health (NIH), National Science Foundation (NSF), Department of Justice (DOJ), NASA, and other federal agencies. In 2014, the subcommittee hosted a series of topical meetings on enhancing support for collaboration in science, which resulted in this document, “How to Write a Collaboration Plan”, authored by subcommittee co-chairs Dr. Kara Hall (NIH) and Dr. Kevin Crowston (NSF), along with subcommittee member Dr. Amanda Vogel (Leidos Biomed).; Collaboration Planning: Planning for Success in Team Science -- While team science has the potential to successfully achieve complex and sophisticated research goals, it can also introduce unique costs, in terms of fices, time, and effort related to the management of large, complex teams. Written collaboration plans help to maximize the likelihood of success in scientific collaborations by laying out a plan for maximizing effective team functioning. These documents aid in building a strong foundation for a scientific collaboration; identifying facilitating factors and challenges that are likely to influence the success of the collaboration, and developing related strategies to work within these influences; executing the collaboration; and engaging in quality improvement specific to team functioning. Collaboration planning may benefit any scientific endeavor that includes two or more investigators working together, but such planning becomes increasingly important as a proposed scientific collaboration grows in scope and size. Poor management of large scientific collaborations may negatively impact the quality of the science that is produced, whereas effective management has the potential to foster innovation, creativity, and productivity. Funding agencies currently emphasize evaluation of the technical and scientific merit of funding applications. But for team science applications, the merit of the proposed collaboration plan may be equally important to the success of the science. We propose that funding agencies consider requiring collaboration plans as part of funding applications, in parallel to research plans. Reviewers can then use submitted collaboration plans to assess the capacity of a proposed team to collaboratively execute its proposed scientific work. This poster identifies ten components that we recommend as the core content for collaboration plans. It describes in detail the ten components for collaboration planning, which range from providing a rationale for the proposed team composition to identifying what technologies are needed to support communication and workflow coordination, to planning for conflict prevention and management, to budgeting for the planned resources and activities. The poster also highlights key elements for investigators, funders, and reviewers to consider related to each component. These collaboration planning guidelines provide a strong starting point for investigators and funding agencies interested in collaboration planning. Future research directions may include study of the impact that collaboration planning has on both the collaborative functioning and scientific success of science teams. For additional information see: https://www.teamsciencetoolkit.cancer.gov/public/TSResourceBiblio.aspx?tid=3&rid=3119 ; Comprehensive Collaboration Plans: Practical Considerations Spanning Across Individual Collaborators to Institutional Supports -- ; General chairs’ foreword -- ; Talking the talk in citizen science -- Increasingly, citizen scientists do work beyond the primary goal of the project coordinated via the discussion board. These activities often take place in discussion boards and have a set of terminologies norms for contributing. For newcomers, learning new terminologies presents a challenge since there are no formal opportunities for them to learn the terms and volunteers who join later need to learn more than volunteers who join earlier in a project life-cycle. In this poster, we examine how newcomers terminology uses shifts over the course of two citizen science projects. We find that, although, newcomers joining later might face obstacles, terminology use among newcomers associated with advanced work increase over the project’s life-cycle. The analysis can help the science team assess whether newcomers on the talk page have either adopted advanced terminologies and if they need to have a more formal resource such as tutorial or blog posts.; The Genie in the Bottle: Different Stakeholders, Different Interpretations of Machine Learning -- ; Validity issues in the use of social network analysis with digital trace data -- There is an exciting natural match between social network analysis methods and the growth of data sources produced by social interactions via information technologies, from online communities to corporate information systems. Information Systems researchers have not been slow to embrace this combination of method and data. Such systems increasingly provide ""digital trace data"" that provide new research opportunities. Yet digital trace data are substantively different from the survey and interview data for which network analysis measures and interpretations were originally developed. This paper examines 10 validity issues associated with the combination of digital trace data and social network analysis methods, with examples from the IS literature, to provide recommendations for improving the validity of future research.; Collaboration through open superposition -- This paper develops and illustrates the theory of collaboration through open superposition: the process of depositing motivationally independent layers of work on top of each other over time. The theory is developed in a study of community-based free and open source software (FLOSS) development, through a research arc of discovery (participant observation), replication (two archival case studies), and theorization. The theory explains two key findings: (1) the overwhelming majority of work is accomplished with only a single programmer working on any one task, and (2) tasks that appear too large for any one individual are more likely to be deferred until they are easier rather than being undertaken through structured team work. Moreover, the theory explains how working through open superposition can lead to the discovery of a work breakdown that results in complex, functionally interdependent, work being accomplished without crippling search costs. We identify a set of socio-technical contingencies under which collaboration through open superposition is likely to be effective, including characteristics of artifacts made from information as the objects being worked on. We demonstrate the usefulness of the theory by using it to analyze difficulties in learning from FLOSS in other domains of work and in the IS function of for-profit organizations.; Motivations for sustained participation in crowdsourcing -- The paper explores the motivations of volunteers in a large crowd sourcing project and contributes to our understanding of the motivational factors that lead to deeper engagement beyond initial participation. Drawing on the theory of legitimate peripheral participation (LPP) and the literature on motivation in crowd sourcing, we analyze interview and trace data from a large citizen science project. The analyses identify ways in which the technical features of the projects may serve as motivational factors leading participants towards sustained participation. The results suggest volunteers first engage in activities to support knowledge acquisition and later share knowledge with other volunteers and finally increase participation in Talk through a punctuated process of role discovery.; Which way did they go? Newcomer movement through the Zooniverse -- Research on newcomer roles in peer production sites (e.g., Wikipedia) is characterized by a broad and relatively wellarticulated set of functionally and culturally recognizable roles. But not all communities come with well-defined roles that newcomers can aspire to occupy. The present study explores activity clusters newcomers create when faced with few recognizable roles to fill and limited access to other participants' work that serves as an exemplar. Drawing on a mixed method research design, we present findings from an analysis of 1,687 newcomers' sessions in an online citizen science project. Our analysis revealed three major findings: (1) newcomers' activities exists across six session types; (2) newcomers toggle between light work sessions and more involved types of production or community engagement; (3) high-level contributors contribute large volumes of work but comment very little and another group contributes large volumes of comments, but works very little. The former group draws heavily on posts contributed by the latter group. Identifying shifts and regularities in contribution facilitate improved mechanisms for engaging participants and for the design of online citizen science communities.; Encouraging work in citizen science -- This paper describes the results of an online field experiment where we designed and analyzed the effects of a goal-setting tracker in an online citizen science project-Floating Forest. The design of our tracker was influenced by psychology theories of anchoring and goal-setting. Our results of our experiment revealed: (1) setting goals increases annotations in a session; (2) numeric anchors influence goals; and (3) participants in the treatment who saw a prompt but did not set a goal, contributed more annotations than the participants in the control group. Our research shows how goal-setting and anchoring combine to increase work in online communities.; ""Guess what! You're the first to see this event"" -- In this paper, we describe the results of an online field experiment examining the impacts of messaging about task novelty on the volume of volunteers' contributions to an online citizen science project. Encouraging volunteers to provide a little more content as they work is an attractive strategy to increase the community's output. Prior research found that an important motivation for participation in online citizen science is the wonder of being the first person to observe a particular image. To appeal to this motivation, a pop-up message was added to an online citizen science project that alerted volunteers when they were the first to annotate a particular image. Our analysis reveals that new volunteers who saw these messages increased the volume of annotations they contributed. The results of our study suggest an additional strategy to increase the amount of work volunteers contribute to online communities and citizen science projects specifically.; Folksonomies to Support Coordination and Coordination of Folksonomies -- ; Did they login? Patterns of anonymous contributions in online communities -- Researchers studying user behaviors in online communities often conduct analyses of user interaction data recorded in system logs e.g., an edit in Wikipedia. Such analysis relies on collating interactions by a unique identifier such as a user ID. However, if users can contribute without being logged-in (i.e., anonymously) analysis of interaction data omit part of a user’s experience. Problematically, anonymous traces are unlikely to be randomly distributed, so their omission can change statistical conclusions, with implications for both research and practice. To understand the impacts on conclusions of leaving out anonymous traces, we conducted an analysis of system logs from two online citizen science projects. Attributing anonymous traces with user IDs, we found that (1) many users contribute anonymously, though with varied patterns; and (2) attributing anonymous traces diminishes empirical evidence used to support theory and change the results of system algorithms. These results suggest anonymous traces have implications for research on user behaviors and the practices associated with using such data to tailor user experiences in online communities.; Teaching citizen scientists to categorize glitches using machine learning guided training -- Existing literature points to scaffolded training as an effective yet resource-intensive approach to help newcomers learn and stay motivated. Experts need to select relevant learning materials and continuously assess learners' progress. Peer production communities such as Wikipedia and Open Source Software Development projects face the additional problem of turning volunteers into productive participants as soon as possible. To address these challenges, we designed and tested a training regime combining scaffolded instruction and machine learning to select learning materials and gradually introduces new materials to individuals as their competences improve. We evaluated the training regime on 386 participants that contribute to Gravity Spy, an online citizen science project where people are asked to categorize glitches to assist scientists in the search for gravitational waves. Volunteers were assigned to one of two conditions; (1) a machine learning guided training (MLGT) system that continuously assesses volunteers skill level and adjusts the learning materials or (2) an unscaffolded training program where all learning materials were administered at once. Our analysis revealed that volunteers in the MLGT condition were more accurate on the categorization task (an average accuracy of 90% vs. 54%), executed more tasks (an average of 228 vs. 121 tasks), and were retained for a longer period (an average of 2.5 vs. 2 sessions) than volunteers in the unscaffolded training. The results suggest that MLGT is an effective pedagogical approach for training volunteers in categorization tasks and increases volunteers’ motivation.; Linguistic adoption in online citizen science -- For peer-production projects to be successful, members must develop a specific and universal language that enables them to cooperate. Complicating the development of language in some projects is the lack of formalized structures (e.g., roles) that communicate to members the norms and practices around language. We address the question of how do role differences among participants interact with the adoption and dissemination of new terminologies in open peer production communities? Answering this question is crucial because we want communities to be productive even when self-managed, which requires understanding how shared language emerges. We examine this question using a structurational lens in the setting of a citizen science project. Exploring the use of words in the Gravity Spy citizen science project, we find that many words are reused and that most new words that are introduced are not picked up, showing a reproduction of structure. However, some novel words are used by others, showing an evolution of the structure. Participants with roles closer to the science are more likely to have their words reused, showing the mutually reinforcing nature of structures of signification, legitimation, and domination.; Shifting forms of Engagement -- Peer production projects involve people in many tasks, from editing articles to analyzing datasets. To facilitate mastery of these practices, projects offer a number of learning resources, ranging from project-defined FAQsto individually-oriented search tools and communal discussion boards. However, it is not clear which project resources best support participant learning, overall and at different stages of engagement. We draw onSørensen's framework of forms of presence to distinguish three types of engagement with learning resources:authoritative, agent-centered and communal. We assigned resources from the Gravity Spy citizen-science into these three categories and analyzed trace data recording interactions with resources using a mixed-effects logistic regression with volunteer performance as an outcome variable. The findings suggest that engagement with authoritative resources (e.g., those constructed by project organizers) facilitates performance initially. However, as tasks become more difficult, volunteers seek and benefit from engagement with their own agent-centered resources and community-generated resources. These findings suggest a broader scope for the design of learning resources for peer production.; A pragmatic approach to managing enterprise IT infrastructures in the era of consumerization and individualization of IT -- Historically, organizations owned and controlled the information technologies (IT) their employees used: telephone, inter-office memos, mainframes and timesharing systems. Today, employees often want to use their own IT: not only personal smart phones and tablets, but also Twitter and Google Docs. This new trend can diversify and extend enterprise IT infrastructure, but leaves organizations struggling with technology uses that they cannot control. With the emergence of new technological paradigms in consumer markets and organizations, the management of IT infrastructure requires a more pragmatic and holistic approach that goes beyond simple technological considerations. In this paper, we present a three-part framework—technology, people and practice—that helps managers understand and mitigate these tensions. Drawing on two empirical studies of European executives and consultants form multiple management consulting firms, the paper further outlines changes taking place along the three aspects of the framework. It concludes by discussing three distinct approaches to the management of organizational IT infrastructure (passive, reactive, and pragmatic), and by offering greater insight regarding a pragmatic approach.; The rise and fall of an online project. Is bureaucracy killing efficiency in open knowledge production? -- We evaluate the efficiency of an online knowledge production project and identify factors that affect efficiency. To assess efficiency, we used the Data Envelopment Analysis (DEA) modelling methodology. We apply DEA to data from more than 30 Wikipedia language projects over three years. We show that the main Wikipedia projects were indeed less efficient that smaller ones, an effect that can be attributed in part to decreasing returns to scale.; Open Source ERP adoption -- This research-in-progress aims to indentify the salient factors explaining adoption of open source software (OSS), as a technological innovation. The theoretical background of the paper is based on the technological innovation literature. We choose to focus on the open ERP case, as it is considered as a promising innovation for firms - especially medium firms - but open ERP also faces numerous challenges. The paper provides a framework and a method for investigation that has to be implemented.; Alignment in an inter-organisational network: The case of ARC Transistance -- ; Technology adoption and use theory review for studying scientists' continued use of cyber-infrastructure -- In this paper, we seek to identify factors that might increase the likelihood of adoption and continued use of cyberinfrastructure by scientists. To do so, we review the main research on Information and Communications Technology (ICT) adoption and use by addressing research problems, theories and models used, findings, and limitations. We focus particularly on the individual user perspective. We categorize previous studies into two groups: Adoption research and post-adoption (continued use) research. In addition, we review studies specifically regarding cyberinfrastructure adoption and use by scientists and other special user groups. We identify the limitations of previous theories, models and research findings appearing in the literature related to our current interest in scientists' adoption and continued use of cyber-infrastructure. We synthesize the previous theories and models used for ICT adoption and use, and then we develop a theoretical framework for studying scientists' adoption and use of cyber-infrastructure. We also proposed a research design based on the research model developed. Implications for researchers and practitioners are provided.; Recruiting messages matter -- Although participation of citizen scientists is critical for a success of citizen science projects (a distinctive form of crowdsourcing), little attention has been paid to what types of messages can effectively recruit citizen scientists. Derived from previous studies on citizen scientists' motivations, we created and sent participants one of four recruiting messages for a new project, Gravity Spy, appealing to different motivations (i.e., learning about science, social proof, contribution to science, and altruism). Counter to earlier studies on motivation, our results showed that messages appealing to learning, contribution and social proof were more effective than a message appealing to altruism. We discuss the inconsistency between the present and prior study results and plans for future work.; Appealing to different motivations in a message to recruit citizen scientists: results of a field experiment -- This study examines the relative efficacy of citizen science recruitment messages appealing to four motivations that were derived from previous research on motives for participation in citizen-science projects. We report on an experiment (N=36,513) that compared the response to email messages designed to appeal to these four motives for participation. We found that the messages appealing to the possibility of contributing to science and learning about science attracted more attention than did one about helping scientists but that one about helping scientists generated more initial contributions. Overall, the message about contributing to science resulted in the largest volume of contributions and joining a community, the lowest. The results should be informative to those managing citizen-science projects.; Which motives are most effective in recruiting citizen scientists? Results of a field experiment -- ; Knowledge portals -- Knowledge Portals (KPs) are highly integrative Knowledge Management Systems (KMSs) that promise to synthesize widely dispersed knowledge and to interconnect individuals in order to provide a 'one-stop knowledge shop'. Yet, KPs face major challenges in practice, as the intricacies of knowledge exchange are subject to varied individual and social factors. At the same time, growing anecdotal evidence from case studies indicates KPs' enormous potential. In this paper, we take some initial steps towards a theory for KPs that more distinctly conceptualizes KPs and emphasizes a KP's role to unify networking and repository KMS features. We describe three major challenges to successful KP deployment: (1) sufficient contribution, (2) favorable organizational culture, and (3) knowledge integration-and validate these as applicable to KPs through a review of 42 empirical papers.; Planet hunters and seafloor explorers -- Making visible the process of user participation in online crowdsourced initiatives has been shown to help new users understand the norms of participation [2]. However, in many settings, participants lack full access to others' work. Merging the theory of legitimate peripheral participation [18] with Erickson and Kellogg's theory of social translucence [10, 11, 16] we introduce the concept of practice proxies: traces of user participation in online environments that act as resources to orient newcomers towards the norms of practice. Through a combination of virtual [14] and trace ethnography [12] we explore how new users in two online citizen science projects engage with these traces of practice as a way of compensating for a lack of access to the process of the work itself. Our findings suggest that newcomers seek out practice proxies in the social features of the projects that highlight contextualized and specific characteristics of primary work practice.; Being present in online communities -- How online community members learn to become valuable contributors constitutes a long-standing concern of Community & Technology researchers. The literature tends to highlight participants' acceb to practice, feedback from experienced members, and relationship building. However, not all crowdsourcing environments offer participants opportunities for acceb, feedback, and relationship building (e.g., Citizen Science). We study how volunteers learn to participate in a citizen science project, Planet Hunters, through participant observation, interviews, and trace ethnography. Drawing on Sørensen's sociomaterial theories of presence, we extend the notion of situated learning to include several modes of learning. The empirical findings suggest that volunteers in citizen science engage more than one form of acceb to practice, feedback, and relationship building. Communal relations characterize only one form of learning. Equally important to their learning are authority-subject and agent-centered forms of acceb, feedback, and relationship building.; The future of Citizen science -- Citizen science creates a nexus between science and education that, when coupled with emerging technologies, expands the frontiers of ecological research and public engagement. Using representative technologies and other examples, we examine the future of citizen science in terms of its research processes, program and participant cultures, and scientific communities. Future citizen-science projects will likely be influenced by sociocultural issues related to new technologies and will continue to face practical programmatic challenges. We foresee networked, open science and the use of online computer/video gaming as important tools to engage non-traditional audiences, and offer recommendations to help prepare project managers for impending challenges. A more formalized citizen-science enterprise, complete with networked organizations, associations, journals, and cyberinfrastructure, will advance scientific research, including ecology, and further public education.; Collective problem solving -- Panelists will discuss how collective intelligence can be applied to large-scale problems through collaborative online systems. The features and affordances of several such systems will be described, inviting discussion about how such systems can be better designed by the CSCW community.; The impact of is research -- ; Assessing IS research impact -- Based on the International Conference on Information Systems’ (ICIS) 2013 senior scholars’ forum, this paper shares insights on IS research impact assessment. We define research impact as conducting research that makes a difference to individuals, businesses, industries, and societies. While assessment groups like the Association to Advance Collegiate Schools of Business (AACSB) want scholars to make an impact, sometimes they operationalize impact in ways that may encourage scholars to pursue research goals tangential to making a difference. With this paper, we hope to stimulate thinking in the IS community on creating research assessment techniques that encourage our scholars to make a difference.; What characterize documents that bridge boundaries compared to documents that do not? An exploratory study of documentation in FLOSS teams -- Organizations bring together people with various access to and understanding of the work at hand. Despite their different stocks of background knowledge, most of them engage in documentation, whether as writers or readers. This paper explores how documents serve such diverse users by building a framework articulating the characteristics of documents supporting collaborators with asymmetric access to knowledge versus people with symmetric knowledge. Drawing on document-centric approaches we hypothesize that documents supporting asymmetric groups are likely to be more prescriptive and explicate their own use compared to documents supporting symmetric groups. Through exploratory analysis of two kinds of documents, used across three FLOSS projects, we find that documents supporting collaborators with asymmetric knowledge do appear to explicate their own use in more detail. They do so by prescribing their own 1) purpose, 2) context of use, 3) content and form in greater detail than documents used by core community members with symmetric access to project knowledge.; Boundary-spanning documents in online FLOSS communities -- Online communities bring together people with varied access to and understanding of the work at hand, who must collaborate through documents of various kinds. We develop a framework articulating the characteristics of documents supporting collaborators with asymmetric access to knowledge versus those with symmetric knowledge. Drawing on theories about document genre, boundary objects and provece, we hypothesize that documents supporting asymmetric groups are likely to articulate or prescribe their own 1) purpose, 2) context of use, 3) content and form and 4) provece in greater detail than documents used by people with symmetric access to knowledge. We test these hypotheses through content analysis of documents and instructions from a variety of free/libre open source projects. We present findings consistent with the hypotheses developed as well as results extending beyond our theory derived assumptions. The study suggests new directions for research on communications in online communities, as well as advice for those supporting such communities.; Documentation and access to knowledge in online communities: Know your audience and write appropriately? -- ; Gaming for (citizen) science -- Citizen Sort, currently under development, is a web-based social-computational system designed to support a citizen science task, the taxonomic classification of various insect, animal, and plant species. In addition to supporting this natural science objective, the Citizen Sort platform will also support information science research goals on motivation for participation in social-computation and citizen science. In particular, this research program addresses the use of games to motivate participation in social-computational citizen science, and explores the effects of system design on motivation and data quality. A design science approach, where IT artifacts are developed to solve problems and answer research questions is described. Research questions, progress on Citizen Sort planning and implementation, and key challenges are discussed.; Citizen science system assemblages -- We explore the nature of technologies to support citizen science, a method of inquiry that leverages the power of crowds to collect and analyze scientific data. We evaluate these technologies as system assemblages, collections of interrelated functionalities that support specific activities in pursuit of overall project goals. The notion of system assemblages helps us to explain how different citizen science platforms may be comprised of widely varying functionalities, yet still support relatively similar goals. Related concepts of build vs. buy and web satisfiers vs. web motivators are used to explore how different citizen science functionalities may lead to successful project outcomes. Four detailed case studies of current citizen science projects encompassing a cross-section of varying project sizes, resource levels, technologies, and approaches to inquiry help us to answer the following research questions: 1) What do typical system assemblages for citizen science look like? 2) What factors influence the composition of a system assemblage for citizen science? 3) What effect does the assemblage composition have on scientific goals, participant support, motivation, and satisfaction? and 4) What are the design implications for the system assemblage perspective on citizen science technologies?; Purposeful gaming & socio-computational systems -- Citizen science is a form of social computation where members of the public are recruited to contribute to scientific investigations. Citizen-science projects often use web-based systems to support collaborative scientific activities, making them a form of computer-supported cooperative work. However, finding ways to attract participants and confirm the veracity of the data they produce are key issues in making such systems successful. We describe a series of web-based tools and games currently under development to support taxonomic classification of organisms in photographs collected by citizen-science projects. In the design science tradition, the systems are purpose-built to test hypotheses about participant motivation and techniques for ensuring data quality. Findings from preliminary evaluation and the design process itself are discussed.; Gamers, citizen scientists, and data -- Two key problems for crowd-sourcing systems are motivating contributions from participants and ensuring the quality of these contributions. Games have been suggested as a motivational approach to encourage contribution, but attracting participation through game play rather than intrinsic interest raises concerns about the quality of the contributions provided. These concerns are particularly important in the context of citizen science projects, when the contributions are data to be used for scientific research. To assess the validity of concerns about the effects of gaming on data quality, we compare the quality of data obtained from two citizen science games, one a “gamified” version of a species classification task and one a fantasy game that used the classification task only as a way to advance in the game play. Surprisingly, though we did observe cheating in the fantasy game, data quality (i.e., classification accuracy) from participants in the two games was not significantly different. As well, data from short-time contributors was also at a usable level of accuracy. Finally, learning did not seem to affect data quality in our context. These findings suggest that various approaches to gamification can be useful for motivating contributions to citizen science projects.; Stigmergic coordination in Wikipedia -- We look for evidence of stigmergic coordination (i.e., coordination mediated by changes to a shared work product) in the context of Wikipedia. Using a novel approach to identifying edits to the same part of a Wikipedia article, we show that a majority of edits to two example articles are not associated with discussion on the article Talk page, suggesting the possibility of stigmergic coordination. However, discussion does seem to be related to article quality, suggesting the limits to this approach to coordination.; The FOSS 2010 community report -- The purpose of this panel is to disseminate the findings from the related FOSS workshop, a CCC-sponsored exploratory workshop held at University of California, Irvine in February 2010. At the OSS conference we will give first a report of what was learned at the FOSS workshop, and then we will glean important feedback from community members who were unable to be at the FOSS workshop. The four conveners of the FOSS workshop will be the panelists at the OSS conference.; Perceived discontinuities and constructed continuities in virtual work -- Boundaries such as time, distance, organisation and culture have been a useful conceptual tool for researchers to unpack changes in the virtual work environment, moving from a dichotomous perspective that contrasts face-to-face and virtual work to a more nuanced hybrid perspective. However, researchers may tacitly assume that all members of a virtual team and virtual teams collectively will respond to a boundary in a similar way. We posit instead that boundaries are a dynamic phenomenon and may have different consequences under different circumstances. We offer organisational discontinuity theory as a tool for more focused investigation of the virtual work environment. Discontinuities and continuities describe the setting in which individuals in a virtual team operate, both actual work practices and the perceptions of the individuals in the virtual work environment. The terms offer a starting point to identify and understand what may otherwise seem to be paradoxical differences in how virtual team members respond to boundaries.; Understanding group maintenance behavior in Free/Libre Open-Source Software projects -- In this paper, we investigate group maintece behavior in community-based Free/Libre Open-Source Software (FLOSS) development teams. Adopting a sociolinguistic perspective, we conceptualize group maintece behavior as interpersonal communication tactics - specifically, social presence and politeness tactics - that help maintain relationships among group members. Developer email messages were collected from two FLOSS projects with different development statuses, and their content was analyzed to identify frequently used group maintece tactics. We then compared the group maintece tactics used in the two projects, finding differences that reflect changes in the project work practices. Our work theoretically contributes to FLOSS research and has practical implications for FLOSS practitioners.; Roles and politeness behavior in community-based free/libre open source software development -- Community-based Free/Libre Open Source Software (FLOSS) development relies on contributions from both core and peripheral members. Prior research on core–periphery has focused on software coding-related behaviors. We study how core–periphery roles are related to social-relational behavior in terms of politeness behavior. Data from two FLOSS projects suggest that both core and peripheral members use more positive politeness strategies than negative strategies. Further, core and peripheral members use different strategies to protect positive face in positive politeness, which we term respect and intimacy, respectively. Our results contribute to FLOSS research and politeness theory.; Editorial -- ; Mechanisms for data quality and validation in citizen science -- Data quality is a primary concern for researchers employing a public participation in scientific research (PPSR) or ""citizen science"" approach. This mode of scientific collaboration relies on contributions from a large, often unknown population of volunteers with variable expertise. In a survey of PPSR projects, we found that most projects employ multiple mechanisms to ensure data quality and appropriate levels of validation. We created a framework of 18 mechanisms commonly employed by PPSR projects for ensuring data quality, based on direct experience of the authors and a review of the survey data, noting two categories of sources of error (protocols, participants) and three potential intervention points (before, during and after participation), which can be used to guide project design.; Goals and tasks -- Citizen science is a form of research collaboration involving members of the public in scientific research projects to address real-world problems. Often organized as a virtual collaboration, these projects are a type of open movement, with collective goals addressed through open participation in research tasks. We conducted a survey of citizen science projects to elicit multiple aspects of project design and operation. We then clustered projects based on the tasks performed by participants and on the project's stated goals. The clustering results group projects that show similarities along other dimensions, suggesting useful divisions of the projects.; Reclassifying success and tragedy in FLOSS projects -- This paper presents the results of a replication of English & Schweik's 2007 paper classifying FLOSS projects according to their stage of growth and indicators of success. We recreated their analysis using a comparable data set from 2006. We also expanded upon the original results by analyzing data from an additional point in time and by applying different criteria for evaluating the rate of new software releases for sustainability of project activity. We discuss the points of convergence and divergence from the original work from these extensions of the classification and their implications for studying FLOSS development using archival data. The paper contributes new analysis of operationalizing success in FLOSS projects, with discussion of implications of the findings.; Surveying the citizen science landscape -- Citizen science has seen enormous growth in recent years, in part due to the influence of the Internet, and a corresponding growth in interest. However, the few stand-out examples that have received attention from media and researchers are not representative of the diversity of the field as a whole, and therefore may not be the best models for those seeking to study or start a citizen science project. In this work, we present the results of a survey of citizen science project leaders, identifying sub-groups of project types according to a variety of features related to project design and management, including funding sources, goals, participant activities, data quality processes, and social interaction. These combined features highlight the diversity of citizen science, providing an overview of the breadth of the phenomenon and laying a foundation for comparison between citizen science projects and to other online communities.; From conservation to crowdsourcing -- Citizen science is a form of research collaboration involving members of the public in scientific research projects to address real-world problems. Often organized as a virtual collaboration, these projects are a type of open movement, with collective goals addressed through open participation in research tasks. Existing typologies of citizen science projects focus primarily on the structure of participation, paying little attention to the organizational and macrostructural properties that are important to designing and managing effective projects and technologies. By examining a variety of project characteristics, we identified five types - Action, Conservation, Investigation, Virtual, and Education - that differ in primary project goals and the importance of physical environment to participation.; Decision-making Processes in Community-based Free/Libre Open Source Software-development Teams with Internal Governance: An Extension to Decision-making Theory -- ; Coordination in OSS 2.0: ANT Approach -- Open source software projects are increasingly driven by a combination of independent and professional developers, the former volunteers and the later hired by a company to contribute to the project to support commercial product development. This mix of developers has been referred to as OSS 2.0. However, we do not fully understand the multi-layered coordination spanning individuals, teams, and organizations. Using Actor-Network Theory (ANT), we describe how coordination and power dynamics unfold among developers and how different tools and artifacts both display activities and mediate coordination efforts. Internal communication within an organization was reported to cause broken links in the community, duplication of work, and political tensions. ANT shows how tools and code can exercise agency and alter a software development process as an equivalently active actor of the scene. We discuss the theoretical and practical implications of the changing nature of open source software development."
LaVerne Gray,"An “owning up” of white-IST trends in LIS to further real transformations -- In the shadow of a uniquely American struggle for racial equality, who were we historically in the library and information science (LIS) professions and how has it shaped who we are in the present? An honest acceptance is important to realistically move forward in the future. On the occasion to commemorate Library Quarterly’s tenth decade, this article reflects on “owning up” of historical and contemporary White-IST trends considered “normative” in LIS for authentic transformations to expand diversity and social justice within its privileged canon and ranks. The representational form of the term “White [dash] IST” (in ALL CAPS) is coined in the article as an amalgamation of “White 1 Elitist” practices during six phases in LIS of the past and the present. An owning up of historical lapses and identifying limitations in contemporary LIS practices is important for reconciliation, retribution, and overcoming White-IST tendencies that exist even today."
Lee W McKnight,"A Steady-State Framework for Assessing Security Mechanisms in a Cloud-of-Things Architecture -- The ability to process large amounts of data with the integration of the Internet of Things (IoT) and cloud computing environments means organizations can trade sophisticated security estimation techniques for more accurate and simple models. By determining tactical and technical parameters of Cloud-of-Things (CoT) wireless equipment and systems, discovering irregularities of electronic tags and their threat levels and analyzing tags/readers strong and weak APs provide the interoperability for organizing and carrying out CoT defense. The basic task of the steady-state model for the CoT will be to support the defense for the CoT network through detecting technical loopholes and topographic structures from the various CoT networks and the data/information stored inside the system. The CoT system will possess a function of automatic identity recognition and needs a steady-state framework for measuring security components and mechanisms of computing devices, communication networks, and sensing devices.; Dynamic emergency response communication -- Situation management has traditionally been based on iterative planning activities that call for a high level of coordination between multiple stakeholders: first responders, citizens, volunteers, subject matter experts, scientists, technicians and managers with different yet important responsibilities. In a crisis event existing systems and communications infrastructures may not provide necessary information in a timely fashion due to damage, incompatible media, geographically limited coverage, fragmented technology or social and policy issues. The effective coordination of multiple response units/resources is stymied by incompatible communication technologies and social/policy incongruences. Crisis events are characterized by initial and ongoing uncertainty with regard to scale, location, direction and magnitude. More and better information sharing and cooperation is needed. The Intelligent Deployable Augmented Wireless Gateway (iDAWG) technology creates direct communication networks between remote coordinators, local response teams, volunteers and others on location by using or replacing existing communication or network infrastructures. Remotely sensed information and communications can be shared in real time via iDAWG-enabled devices that can be configured on the fly using edgeware (a new class of software developed for the wireless grid) applications. Existing web, cellular and radio communications network devices are bridged to build dynamically scalable heterogeneous wireless grids. Technical, social, goverce and policy issues are addressed to facilitate this paradigm change in emergency response.; Sustainable Development by Internet Backpack in the Democratic Republic of the Congo, Liberia and Costa Rica -- Wireless grid research and innovation - what we now call cloud to edge or Internet of Things cyberphysical systems research - spearheaded by Syracuse University School of Information Studies (iSchool) with diverse partners and with support from the National Science Foundation's (NSF) Division of Engineering, and Computer and Information Science and Engineering (CISE) has led to the invention of an Internet Backpack which is capable of bringing connectivity anywhere, sustainably. The Internet Backpack is also a microgrid with a solar panel and battery included. This paper focuses on preliminary findings from ongoing Internet Backpack pilot deployments which were initiated in the Democratic Republic of the Congo in 2017, in Liberia in 2018 and in Costa Rica in 2019. We find that by design, the Internet Backpack's cloud to edge cyberphysical platform is capable of flexible and affordable connectivity across more than 11 physical and software-defined/cyberphysical networks, for over 90% of the planet. Further, we find that Internet Backpacks as a service can significantly contribute to accelerating the availability of affordable Internet access for the 3.5 Billion people presently excluded from full participation in realizing their individual human development due to, among other things, lack of Internet access. The paper concludes that Internet Backpacks and other Community Network platforms will likely become more readily available for education, disaster preparedness and other humanitarian uses because of their paradigm-shifting potential for connectivity cost reductions and service enhancements for many people and regions around the world presently largely excluded from sustainable development.; Cognitive Cloud to Edge Systems for Remote Real Time Monitoring -- Cloud technologies and edge (Internet of Things) devices and services have been widely utilized to improve safety and community resiliency. However, in regions with low Internet penetration or even in well-connected communities temporarily 'off-grid,' accessing and coordinating these tools can be a challenge. The Conflict Zone volcano monitoring application explored in this paper may be considered an extreme case. The authors argue that the successful approach assessed in this paper may apply not only to uncommon circumstances. This paper focuses on the use of the Internet Backpack technology as a core part of a cloud to edge communication and information systems for monitoring sensors for early detection of CO2 levels in the city of Goma, in the Democratic Republic of the Congo. The authors describe testing, implementation and challenges in the mountainous terrain encountered and overcome with the Internet Backpack, in cooperation with the Goma Volcano Observatory (OVG). ; Wireless grids for cultural self-preservation -- The role of wireless grids for distributed coordination and their suitability for sustainable cultural self preservation was assessed through a series of focus groups conducted in cooperation with a Native American Nation. After providing contextual information and definitions for key concepts in our research (wireless grid technologies, indigenous knowledge and the right to culture preservation in indigenous cultures) we discuss cases of indigenous communities using ICT as a tool for preserving their traditions. The paper then discusses the findings from focus groups on readiness for innovation in a Native American Nation. We report on the urgency of the felt need for taking positive steps toward cultural self- preservation as well as the interest in ICTs as tools to assist in this effort. We conclude that the focus groups validated our expectations that the application of wireless grid technologies and their potential wider use can be a valuable tool for cultural self preservation.; Collaborative learning through wireless grids -- In this paper, we describe wireless grids, an emerging technology that enables ad hoc sharing of resources (such as screen, services and microphone) on edge devices (such as mobile Internet devices, laptops and mobile phones). As wireless devices have become common, and ""smart,"" wireless grids have become practical. To highlight the capabilities of wireless grids to support collaborative learning, projects at the K-12 and undergraduate levels illustrate that wireless grid theory is transitioning into practice. We hypothesize that wireless grids can transform how students learn, the content of courses, learning-related practices, classroom dynamics and relationships among students and faculty. The authors conclude that applications of this technology will bring about fundamental changes in the ways that students, schools and universities create and disseminate ideas, knowledge, and understanding. The mobile phone is no longer banned in the classroom; it becomes a tool for instruction and learning.; Interoperability by 'edgeware' -- 'Edgeware' for wireless grid connectivity, utilizes open specifications developed by the National Science Foundation (NSF) Partnerships for Innovation (PFI) 'Wireless Grid Innovation Testbed' (WiGiT) to enable greater interoperability across devices, networks, applications, content and services. A wide range of new 'edgeware' applications is emerging for businesses, education, government agencies and individuals. Challenges in emergency response include interoperability, social and human factors. 'Edgeware,' a new class of software designed to share resources across people, devices, services and content has the potential capacity to solve problems of interoperability and control over resources, by the creation of wireless grids. This will allow people to access programs and data on disparate devices, across available wired and wireless networks and provide greater access to resources. Emergency services applications of wireless grids will empower citizens through their devices to contribute to their own community response. The authors describe 'Neighborhood Notification System' gridlets, now in development, which are just the first examples of use of wireless grids for emergency response. The authors conclude that police, fire, EMS, hospitals, municipal services, utilities, gas companies, media, and community residents will benefit from enhanced information sharing in emergencies based on this interoperability by 'edgeware' solution.; Collaboration in a wireless grid innovation testbed by virtual consortium -- This paper describes the formation of the Wireless Grid Innovation Testbed (WGiT) coordinated by a virtual consortium involving academic and non-academic entities. Syracuse University and Virginia Tech are primary university partners with several other academic, government, and corporate partners. Objectives include: 1) coordinating knowledge sharing, 2) defining key parameters for wireless grids network applications, 3) dynamically connecting wired and wireless devices, content and users, 4) linking to VT-CORNET, Virginia Tech Cognitive Radio Network Testbed, 5) forming ad hoc networks or grids of mobile and fixed devices without a dedicated server, 6) deepening understanding of wireless grid application, device, network, user and market behavior through academic, trade and popular publications including online media, 7) identifying policy that may enable evaluated innovations to enter US and international markets and 8) implementation and evaluation of the international virtual collaborative process."
Lu Xiao,"Incorporating Values Sensitive Design into Crowdsourcing Methodologies for Knowledge Collaboration -- In recent years, we have seen a dramatic increase in crowdsourcing approaches to solve problems and engage in other types of knowledge work in many domains, including genetics, health, cultural heritage, digital preservation and design. Crowdsourcing initiatives offer many potential benefits, including engaging individuals of diverse backgrounds in collaborative meaning-making and production. And yet, the potential challenges and dangers, such as issues related to quality and false confidence, can hardly escape our attention. This panel will explore how human-centered approaches to crowdsourcing can help minimize its challenges. In particular, this panel will ask how we implement crowdsourcing methods, what our outcomes should be, and how we should go about developing and defining our outcomes in relationship to the workers. The first half of the session will be devoted to an introduction to crowdsourcing initiatives and associated critical issues. Each presentation will drill progressively deeper into the mechanisms and implications of crowdsourcing. In the second half of the session, we invite session attendees to engage with us in a collaborative activity employing techniques from the value sensitive design approach to design crowdsourcing initiatives that are sensitive to the communities with whom we engage and thereby endeavor to realize humanistic goals. It is our hope that the panel session will result in new collaborations and spark the development of more thoughtful, reflexive and productive crowdsourcing activities.; Twitter Users’ Privacy Concerns: What do Their Accounts’ First Names Tell Us? -- ; Twitter users' privacy concerns -- Purpose: In this paper, we describe how gender recognition on Twitter can be used as an intelligent business tool to determine the privacy concerns among users, and ultimately offer a more personalized service for customers who are more likely to respond positively to targeted advertisements. Design/methodology/approach: We worked with two different data sets to examine whether Twitter users' gender, inferred from the first name of the account and the profile description, correlates with the privacy setting of the account. We also used a set of features including the inferred gender of Twitter users to develop classifiers that predict user privacy settings. Findings: We found that the inferred gender of Twitter users correlates with the account's privacy setting. Specifically, females tend to be more privacy concerned than males. Users whose gender cannot be inferred from their provided first names tend to be more privacy concerned. In addition, our classification performance suggests that inferred gender can be used as an indicator of the user's privacy preference. Research limitations: It is known that not all twitter accounts are real user accounts, and social bots tweet as well. A major limitation of our study is the lack of consideration of social bots in the data. In our study, this implies that at least some percentage of the undefined accounts, that is, accounts that had names non-existent in the name dictionary, are social bots. It will be interesting to explore the privacy setting of social bots in the Twitter space. Practical implications: Companies are investing large amounts of money in business intelligence tools that allow them to know the preferences of their consumers. Due to the large number of consumers around the world, it is very difficult for companies to have direct communication with each customer to anticipate market changes. For this reason, the social network Twitter has gained relevance as one ideal tool for information extraction. On the other hand, users' privacy preference needs to be considered when companies consider leveraging their publicly available data. This paper suggests that gender recognition of Twitter users, based on Twitter users' provided first names and their profile descriptions, can be used to infer the users' privacy preference. Originality/value: This study explored a new way of inferring Twitter user's gender, that is, to recognize the user's gender based on the provided first name and the user's profile description. The potential of this information for predicting the user's privacy preference is explored.; Multi-channel convolutional neural network for twitter emotion and sentiment recognition -- The advent of micro-blogging sites has paved the way for researchers to collect and analyze huge volumes of data in recent years. Twitter, being one of the leading social networking sites worldwide, provides a great opportunity to its users for expressing their states of mind via short messages which are called tweets. The urgency of identifying emotions and sentiments conveyed through tweets has led to several research works. It provides a great way to understand human psychology and impose a challenge to researchers to analyze their content easily. In this paper, we propose a novel use of a multi-channel convolutional neural architecture which can effectively use different emotion and sentiment indicators such as hashtags, emoticons and emojis that are present in the tweets and improve the performance of emotion and sentiment identification. We also investigate the incorporation of different lexical features in the neural network model and its effect on the emotion and sentiment identification task. We analyze our model on some standard datasets and compare its effectiveness with existing techniques.; A lexicon-based approach for detecting hedges in informal text -- Hedging is a commonly used strategy in conversational management to show the speaker's lack of commitment to what they communicate, which may signal problems between the speakers. Our project is interested in examining the presence of hedging words and phrases in identifying the tension between an interviewer and interviewee during a survivor interview. While there have been studies on hedging detection in the natural language processing literature, all existing work has focused on structured texts and formal communications. Our project thus investigated a corpus of eight unstructured conversational interviews about the Rwanda Genocide and identified hedging patterns in the interviewees' responses. Our work produced three manually constructed lists of hedge words, booster words, and hedging phrases. Leveraging these lexicons, we developed a rule-based algorithm that detects sentence-level hedges in informal conversations such as survivor interviews. Our work also produced a dataset of 3000 sentences having the categories Hedge and Non-hedge annotated by three researchers. With experiments on this annotated dataset, we verify the efficacy of our proposed algorithm. Our work contributes to the further development of tools that identify hedges from informal conversations and discussions.; What's in the content of Wikipedia's article for deletion discussions? -- As a successful decentralized online peer production system, Wikipedia has a large number of users participating in self-assigned tasks based on their interest. Participants often coordinate on the tasks about editing an article through the article's talk page discussions. Researchers analyze Wikipedia talk page discussions for various aspects such as coordination [13], conflict management [1], emotion [8], leadership [12], the relationship between Wikipedia article's talk page discussion and the article editing activity [5], etc.; Understanding Privacy Dichotomy in Twitter -- ; Writing to Persuade: Analysis and Detection of Persuasive Discourse -- ; Syrapropa at semeval-2020 task 11 -- This paper describes the BERT-based models proposed for two subtasks in SemEval-2020 Task 11: Detection of Propaganda Techniques in News Articles. We first build the model for Span Identification (SI) based on SpanBERT, and facilitate the detection by a deeper model and a sentence-level representation. We then develop a hybrid model for the Technique Classification (TC). The hybrid model is composed of three submodels including two BERT models with different training methods, and a feature-based Logistic Regression model. We endeavor to deal with imbalanced dataset by adjusting cost function. We are in the seventh place in SI subtask (0.4711 of F1-measure), and in the third place in TC subtask (0.6783 of F1-measure) on the development set.; Characterizing susceptible users on Reddit's changemyview -- In the study of persuasion, little attention is paid to understanding features that indicate one's level of susceptibility. In this work, we examine features that are indicative of an individual's susceptibility on Reddit's changemyview. Specifically, we explore attributes about the author of the post, the interactions between an author and other users, and the author's language style.We first categorize authors of posts on changemyview into two groups: susceptible and non-susceptible. We perform a test of significance on different features between susceptible and non-susceptible authors. Experiments showed that an individual's language style can be indicative of one's susceptibility to a change of opinion. Also, an author's prior position on a subject and their way of interacting with other users can indicate the likelihood of an author having an opinion change.; Characterizing the Evolution of Communities on Reddit -- One of the most important structures in social networks is communities. Communities in social networks evolve over time. Understanding the evolution of communities is useful in many applications, such as building successful communities, maintaining the success of communities, etc. There have been some works on studying online communities such as understanding the life cycle of users and understanding the loyalty of members in a community. An aspect of online community studies that has not been sufficiently studied is the evolution of communities over time. In this work, we investigate factors that significantly differentiate the different parts of the evolution of communities. Firstly, we identify the different patterns that can exist in the evolution of communities. Next, we examine how different features differentiate parts of the patterns identified. Experimental results showed that the linguistic style of users who make posts and the interaction dynamics of members in a community are related to different parts of communities' evolution with respect to the number of active users.; Needs assessment of ASIS&T publications -- This study reports the results of a 2016 online survey on perceptions and uses of ASIS&T publications. The 190 survey respondents represented 26 countries and 5 continents, with 77% of participants coming from academia rather than practitioners. Among the emerging themes were calls for a wider scope of research from information science to be reflected in the publications (including JASIS&T and the ASIS&T Proceedings), and ongoing challenges in the role of the Bulletin as a bridge between research and practice. The study provides insights into the scholarly publishing practices of the ASIS&T community and highlights key issues for the future direction of ASIS&T's scholarly communication.; CKM -- Our access to human rights violation data has increased with the growing number and size of data collections. We have been combining text-mining and visualization techniques to facilitate big data analysis in human rights research. Taking a user-centered approach, we first surveyed the human rights research literature to understand reported data analysis practices in the field, and then taking a participatory design approach working with oral history researchers to develop a visual analytical tool that facilitates the analysis of collections of audio-video interviews oral history research projects. In this paper we present our current prototype - Clock-based Keyphrase Map (CKM). CKM utilizes Keyphrase technique to identify important topics in the collection and a clock-based visualization to present them in a temporal order. CKM also enables the users to further analyze the collections and share their analysis process with other researchers. We discuss the tool in details including its architecture, the computational and visualization techniques, and the interaction features. Our future plan on evaluation and further development are also discussed in the paper.; Toward the Automated Detection of Individuals’ Rationales in Large-Scale Online Open Participative Activities -- In large-scale online open participative (LSOOP) activities, participants can join and leave at any time, and they often do not have a history of working together. Although the communication history is usually accessible to the participants in the environment, it is time consuming for them to process the communication data because of the large volume of messages. These characteristics make it difficult for one to keep track of, identify, and interpret the others’ ideas, opinions, and their rationales in LSOOP activities. We argue for a computational approach that automatically identifies and extracts the rationales from LSOOP communication data and presents them to the participants through rationale-based awareness tools. In this paper we bring together different and hitherto independent lines of research, and propose to use them in a conceptual framework integrating three analytical aspects related to the detection of rationales: linguistic, informational, and argumentative and communicative. We also review the design effort on offering rationale-based awareness in the LSOOP activities.; Discourse relations in rationale-containing text-segments -- Offering one's perspective and justifying it has become a common practice in online text-based communications, just as it is in typical, face-to-face communication. Compared to the face-to-face communications, it can be particularly more challenging for users to understand and evaluate another's perspective in online communications. On the other hand, the availability of the communication record in online communications offers a potential to leverage computational techniques to automatically detect user opinions and rationales. One promising approach to automatically detect the rationales is to detect the common discourse relations in rationale texts. However, no empirical work has been done with regard to which discourse relations are commonly present in the users’ rationales in online communications. To fill this gap, we annotated the discourse relations in the text segments that contain the rationales (N = 527 text segments). These text segments are obtained from five datasets that consist of five online posts and the first 100 comments. We identified 10 discourse relations that are commonly present in this sample. Our finding marks an important contribution to this rationale detection approach. We encourage more empirical work, preferably with a larger sample, to examine the generalizability of our findings.; A Message’s Persuasive Features in Wikipedia’s Article for Deletion Discussions -- ; Online Persuasion Mechanisms and Processes – A Research Agenda -- ; Sentiments in wikipedia articles for deletion discussions -- Wikipedia provides a discussion forum, namely, Article for Deletion forum, for people to deliberate about whether or not an article should be deleted from the site. In this paper, we present interesting correlation between outcomes of the discussion and number of sentiments in the comments with different intensity. We performed sentiment analysis on 37,761 AfD discussions with 156,415 top-level comments and explored relationship between outcomes of the discussion and sentiments in the comments. Our preliminary work suggests: discussion that have keep or other outcomes have more than expected positive sentiment, whereas discussions that have delete outcomes have more than expected negative and neutral sentiment. This result shows that there tends to be positive sentiment in the comment when Wikipedia users suggest not to delete the article. This observation of differences in sentiments also encourages to further study influence of sentiments in decision making or outcome of the discussions. Our future analysis will include threaded comments, and examine the relationship between a discussion’s sentiment and its other properties such as topic of the article and the characteristics of the participating users.; Authority Claim in Rationale-Containing Online Comments -- We examined whether the existence of authority claims signifies one’s rationales in online communication content, potentially contributing to the research on rationale identification and rationale generation. Authority claims are statements that reveal the writer’s intention to bolster the writer’s credibility. In open online communications, the anonymity and the dynamic participation make it challenging to establish the credibility of their viewpoints and reasoning. Therefore, we hypothesize these online participants will tend to use authority claims to bolster their credibility when presenting their justifications. We annotated authority claims in 271 text segments that contain online users’ rationales. These text segments are adapted from the open access corpora provided by Rutgers’ Argument Mining group. Contrary to our hypothesis, we found that in our dataset the users scarcely attempted to bolster their credibility when presenting their reasoning to the others in these activities. We call for more investigations to explore the role of activity context affects participants’ use of authority claims in their reasoning traces. We further state that the effects of communication medium on individuals’ cognitive and meta-cognitive processes are important to consider in argument mining research.; Changing others' beliefs online -- Achieving social welfare and success is heavily reliant on our ability to persuade and influence others, yet this capacity is known to be one of the most challenging social skills to develop and possess. With social networking websites becoming a crucial platform for routine social activities, gaining insight into the strategies and mechanisms behind online persuasion is of great interest and value to a variety of disciplines. Hence, in this study, we aim to study written comments in online deliberations and understand what makes people change their beliefs. We explore different dimensions of the language, the order of the comments, as well as the attributes of the participating users and their relation to the persuasion process. In addition, we investigate the factors that persuaded users (the ones who have already changed their beliefs) perceived to be the reasons that led to their opinion change. We link our findings to earlier research on persuasion and belief change in traditional forms, hoping to uncover when and how they apply to online persuasion.; Misinformation in the chinese weibo -- Social media users are increasingly influenced by misinformation and disinformation as the techniques offer affordances to rapidly spread information to large groups of people. Most of the existing studies about misinformation and disinformation are in the context of Western cultures, the influence of misinformation in Chinese context is underexplored. To fill this research gap, this study analyzed 26,138 Weibo posts that are marked as containing misinformation. We performed a frequency analysis of these posts’ metadata and the top 50 frequent nouns, verbs, and adjectives in the dataset, and examined the sentiment in the content. Our results show that many posts that contain misinformation tactically target topics that Chinese people are already concerned about. The persuasion literature implies that these characteristics increase the persuasive power of the posts. With the forward-asking verbs are frequently used in the posts, one behavior that the receivers are persuaded to perform is to share these posts with the others, which can contribute to the virality of the misinformation. Another alarming finding is that a large proportion of our collected posts asked the receivers for help and the posts showed gratitude to acknowledge the forwarding and helping behavior. Based on the trust literature and the notion that trust as a social reality, we discuss the potentially severe negative impact these posts can impose on the society as they undermine Weibo users’ trustfulness to others and to the social media platform.; TV-AfD -- In this study, we created an imperative corpus with speech conversations from dialogues in The Big Bang Theory and with the written comments in Wikipedia's Articles for Deletion discussions. For the TV show data, 59 episodes containing 25,076 statements are used. We manually annotated imperatives based on the annotation guideline adapted from Condoravdi and Lauer's study (2012) and used the retrieved data to assess the performance of syntax-based classification rules. For the Wikipedia AfD comments data, we first developed and leveraged a syntax-based classifier to extract 10,624 statements that may be imperative, and we manually examined the statements and then identified true positives. With this corpus, we also examined the performance of the rule-based imperative detection tool. Our result shows different outcomes for speech (dialogue) and written data. The rule-based classification performs better in the written data in precision (0.80) compared to the speech data (0.44). Also, the rule-based classification has a low-performance overall for speech data with the precision of 0.44, recall of 0.41, and f-1 measure of 0.42. This finding implies the syntax-based model may need to be adjusted for a speech dataset because imperatives in oral communication have greater syntactic varieties and are highly context-dependent.; CEW-DTW: A New Time Series Model For Text Mining -- ; CEW-DTW -- The keyword information is usually applied to describe answers. In most of the previous studies, researchers usually rank answers according to keyword retrieval, which fails to consider the importance of the time sequence of keywords in answers. In this paper, we propose CEW-DTW, a new time series model for answer ranking. This model considers the importance of the time sequence of keywords as well as the amount of keywords. CEW-DTW is developed from a carefully designed model, Dynamic Time Warping-Delta (DTW-D). We choose Amazon question/answer data as our evaluation dataset. We apply Entropy to remove noise in answer vectors. In experiments, we apply normalized discounted cumulative gain (nDCG) as the assess rule to test models. CEW-DTW is proven to have a better performance than Dynamic Time Warping (DTW) and Dynamic Time Warping-Delta (DTW-D) in answer ranking. An extensive set of evaluation results demonstrates the effectiveness of the CEW-DTW model for answer ranking.; Augmented Tension Detection in Communication -- Tension in communication often prevents effective flows of information among members in the conversation and thus can negatively influence practices in teams and learning efficiency at school. Interested in developing a computational technique that automatically detects tension in communication, we explore features that signal the existence of tension in human-human communications and investigate the potential of a supervised learning approach. While there is no tension-annotated dataset available, there are language resources that have distress annotated. Although tension may occur during the communication as a result of various factors, distress creates discomfort and tension. Leveraging an interview dataset that has marked the presence/absence of distress, we investigated the prosodic features and LIWC features that indicate tension. Specifically, we compare 23 prosodic features and LIWC features extracted from 186 interviews in terms of how effective they are to indicate the speaker’s distress in a one-to-one conversation. Our analysis shows that there are seven prosodic features and one LIWC features that differ between distress and non-distress interviews. The seven prosodic features are mean intensity, jitter, shimmer, longest silence duration, longest silence position, standard deviation of interviewee speaking rate, and hesitation. And the one effective LIWC feature is health.; The effect of prediscussion note-taking in hidden profile tasks -- Prior research has discovered that groups tend to discuss shared information while failing to discuss unique information in decision-making processes. In our study, we conducted a lab experiment to examine the effect of prediscussion note-taking on this phenomenon. The experiment used a murder-mystery hidden profile task. In all, 192 undergraduate students were recruited and randomly assigned into 48 four-person groups with gender being the matching variable (i.e., each group consisted of four same-gender participants). During the decision-making processes, some groups were asked to take notes while reading task materials and had their notes available in the following group discussion, while the other groups were not given this opportunity. Our analysis results suggest that (a) the presence of an information piece in group members' notes positively correlates with its appearance in the subsequent discussion and note-taking positively affects the group's information repetition rate; (b) group decision quality positively correlates with the group's information sampling rate and negatively correlates with the group's information sampling/repetition bias; and (c) gender has no statistically significant moderating effect on the relationship between note-taking and information sharing. These results imply that prediscussion note-taking could facilitate information sharing but could not alleviate the biased information pooling in hidden profile tasks."
Marilyn Arnone,"Curiosity, interest and engagement in technology-pervasive learning environments -- This paper identifies the need for developing new ways to study curiosity in the context of today's pervasive technologies and unprecedented information access. Curiosity is defined in this paper in a way which incorporates the concomitant constructs of interest and engagement. A theoretical model for curiosity, interest and engagement in new media technology-pervasive learning environments is advanced, taking into consideration personal, situational and contextual factors as influencing variables. While the path associated with curiosity, interest, and engagement during learning and research has remained essentially the same, how individuals tackle research and information-seeking tasks and factors which sustain such efforts have changed. Learning modalities for promoting this theoretical model are discussed leading to a series of recommendations for future research. This article offers a multi-lens perspective on curiosity and suggests a multi-method research agenda for validating such a perspective.; Are self-perception measures used in school library research transferable to the context of public library summer reading programs? -- Several instruments previously validated for use in school library research were tested for their appropriateness in the context of public libraries’ summer reading programs for youth. The researchers were also interested in whether the connection between perceived competence in one’s own information skills and perceived competence in one’s own reading skills, as found in school library research, might also exist for participants in public library summer reading programs. In addition, a separate research question explored whether youth participants connected the summer reading program to increased confidence and improvement in their reading abilities. Findings suggest that reliable measures that can be used in the context of both school and public libraries may be beneficial for future collaboration and coordination in youth programming both in and out of school. Findings also suggest that summer reading programs foster self-perceptions of improved reading ability.; A blended instructional design approach to cyberlearning that supports persons with disabilities -- ; Acting on curiosity: what's changed and what hasn't, and what educators can do about it -- ; Supporting inquiry by identifying gaps in student confidence: Development of a measure of perceived competence -- ; How do school librarians perceive dispositions for learning and social responsibility? -- ; Preface -- ; From the creative minds of 21st century librarians -- ; Design-based research -- Using an innovative, real-world approach that makes the research problem and method relevant and valuable to the reader, this book provides a broad overview of research methods used in library and information studies and associated fields.; Perceived competence in information skills (PCIS) -- ; A blended instructional design approach to accessible cyberlearning -- These are learning issues facing all persons with disabilities (PWDs). In some parts of the world, this problem is magnified because of the sheer numbers of PWDs, especially in the Asia-Pacific Region with one of the highest levels of disability in the world (Officer & Posarac, 2011; ESCAP 2012). Many are marginalized in their own countries, and face significant barriers in terms of transportation, information and communication technologies, employment, and most importantly, education. Without education that acknowledges their unique learning needs and that prepares them to be leaders on disability issues in their region and the world, they have few opportunities for political participation in which their voices can be heard.; Evaluating the role of face-to-face residencies in cross-national, accessible cyberlearning -- This paper provides an analysis of the role face-to-face residencies play in online, cross-national, graduate degree programs. In 2011, taking a cyberlearning approach, the IDPP developed the world's first fully online masters program in international and comparative disability policy, focused on students with disabilities in the ten countries of Southeast Asia. Using this online masters program as a case study, and incorporating pre-and post-residency survey data, the paper explores the impact of its face-to-face residency in building a sense of community, achieving learning outcomes, and highlight the role of culture and trust within the student cohort as a foundation for the online graduate learning experience. Finally, the paper discusses best practices in evaluating online graduate degree programs, emphasizing the importance of an evaluation committee and an iterative evaluation model. Using pioneering research on evaluating accessible cyberlearning, it identifies what works in such settings as well as identifying future research needs.; Developing and evaluating an accessible cyberteaching training (ACT) program for faculty via a virtual center for teaching and learning -- Many universities and faculty members are exploring the potential of online learning. However, while it is increasingly likely these faculty members will have students with disabilities, most instructors have little or no experience teaching such students. In addition, there are almost no models for training faculty to design and implement accessible cyber learning in higher education. This is especially true when classes include students from multiple disability communities simultaneously (e.g. Deaf and hard of hearing, blind and visually impaired, and mobility impaired), as well as students from multiple developing countries. This paper addresses those limitations by presenting the Accessible Cyber teaching Training (ACT) Model. Data come from the pilot developed for the first masters program focused on global disability policy in ASEAN. It also stems from the IDPP's commitment to designing, disseminating, and evaluating best practices in online learning for 'All'. The paper includes key evaluation components and recommendations for future research.; Accessible cyberlearning in practice -- ; Applying case-based method in designing self-directed online instruction -- This study investigated the case-based method (CBM) instructional-design theory and its application in designing self-directed online instruction. The purpose of this study was to validate and refine the theory for a self-directed online instruction context. Guided by formative research methodology, this study first developed an online tutorial based on 13 design assumptions synthesized from the CBM literature. The researchers then formatively evaluated the online tutorial as a design instance of CBM through two iterations of design, evaluation, and revision. The major findings included: (1) perceived value of various CBM design features, (2) benefits and limitations of applying CBM in the tutorial design, and (3) validation and revision of a set of generic and context-specific CBM design assumptions. These findings extend our understanding of CBM to the context of self-directed online instruction and provide useful insights and practical guidance to inform instructional design practices.; Ambient intelligence & information interactions -- The primary aim of this research study is to explore the social and human potential of technologies designed to support awareness and enable autonomy. The concepts of awareness and autonomy are reconceptualized for 21st century technology-pervasive environments. Using a case study approach, this study focuses on the use experience of faculty and students with an emerging and next generation technology. Multiple methods are employed for quantitative and qualitative data collection along with multiple data analysis techniques. This study makes several contributions to research and practice, including: the development of a conceptual framework for 21st century autonomies and awareness; an autonomies and awareness research agenda; a reframing of the intuition concept for 21st century technologies; proposed use of intuitive inquiry as a method for studying people-technology interactions; and a human-centered computing (HCC) approach in support of technology and people in balance, enabling more immediate engagement with social impact and social implications issues. More broadly, this paper provides a strategic and overarching perspective for building new systems within a research context for the 21st century.; Social interactions with wireless grids -- This study combines ambient intelligence with wireless grids to investigate social interactions in emerging and next generation technology-pervasive environments. The use experience of postsecondary students and faculty with WeJay social radio is explored in a virtual distributed environment. The research literature on 21st century social sciences, wireless grids, ambient intelligence, and futures studies provides a theoretical framework for the exploration of social interactions with emerging technologies. The research design incorporates a case study approach, employing multiple methods of inquiry and analysis. Focusing on information-based social interactions in technology-pervasive environments, this study proposes an interaction dynamic, a conceptual model, and a research agenda for a 21st century ambient learning and information society.; Ambient privacy with wireless grids: Forging new concepts of relationship in 21st century information society -- ; Emergent learning through playful interactions and serious games when combining ambient intelligence with wireless grids -- ; Application of the Consensual Assessment Technique in 21st Century Technology - Pervasive Learning Environments -- ; Ambient and emergent learning with wireless grid networks -- "
Martha A Garcia-Murillo,"Publishing IS research in and about Latin America panel proposal -- ; Virtual worlds in higher education -- The purpose of this paper is to explore whether virtual worlds can provide a setting for a rewarding learning experience for college students. The paper describes a policy-making simulation conducted within a virtual world and the results of an analysis conducted to assess its learning effectiveness. Our analysis, drawn from eight 'learning principles' advanced by Gee (2003), indicates that the levels of enthusiasm and learning that take place within a virtual world can differ considerably for different students: while some prefer traditional online methods, others are more enthusiastic about virtual world settings. Of the eight principles we considered, we found evidence to support 'identity and self knowledge', 'active learning', 'psychological moratorium' and 'content' principles. The 'affinity', 'transfer' and 'exploration' principles were not as well supported. In conclusion, we recommend that instructors give serious consideration to using virtual worlds as a tool to support interactive activities of students such as simulations.; Does a government web presence reduce perceptions of corruption? -- Researchers have found that corruption severely affects a country's development because it takes resources away from the economy, leads to uncertainty and impairs investment. The purpose of this study is, thus, to determine if a government's web presence can help to reduce perceptions of corruption. There is some empirical evidence that it helps, but there is also skepticism from some scholars who argue that technology is simply another tool that can be exploited for purposes of corruption. The statistical model we use in this article looks at goverce factors, specifically government effectiveness and accountability, as well as the focus variable of government web portals. Using data from a six-year panel (2002-2005 and 2008) for 208 countries, our analysis finds that governments' web presence has reduced perceptions of corruption around the world. We also provide case evidence from governments that have used Internet portals that have reduced perceptions of corruption. The author recommends that international agencies support and promote the use of the Internet by governments to supplement other anti-corruption measures that rely on improvements in goverce alone.; Theory construction -- Computers, digital libraries and the Internet in general have led to an explosion of research that is often difficult to keep up with our fields. The vast amount of academic papers available to researchers makes it difficult to determine what to read or even figure out where we can make a contribution. This workshop focuses on the process of theory development and how to find holes in the literature where a contribution can be made. Participants will be made aware of software applications (some of which are open), that can facilitate the theory development process with visualizations, citation analysis graphs and reference software for example. The workshop is unique because it falls in a niche that is not covered in either methodological or philosophy of science texts. Unlike other contributions on theory development which are much more formally presented, this workshop will be much more practical in nature. It is intended to guide the research and theory construction process to make it easier for scholars to be able to successfully and more effectively make a contribution to their fields. It provides a practical and systematic approach to the research process beyond traditional methods of research design or philosophy. Today, contributions are almost random given that they are, for the most part, relying on articles that scholars find in databases with little or no strategies to identify the most relevant or from papers that advisers recommend.; Innovation strategies under uncertain economic and political circumstances -- The purpose of this paper is to determine how innovation happens in countries that experience risks and uncertainty. We analyzed the Argentinean telecom sector with a focus on small and medium-size enterprises. The research relies on interviews with companies offering information and communication services in diverse regions of the country. Departing from Porter's identification of strategies, we find that economic and political uncertainties lead to significant differences in strategies. We were able to identify strategies that prevail under suboptimal regulatory conditions. These are: 1) survival; 2) slow modernization; 3) infrastructure capitalization; and 4) diversification and customization. We recommend that in order to channel the creativity and innovation capabilities of these entities, governments could help produce a less uncertain and risky environment if they had a more predictable regulatory environment.; ICTs and the informal economy -- Purpose: The purpose of this paper is to explore whether information and communication technologies (ICTs) can move people from the informal to the formal sector. ICTs being multipurpose technologies can provide people with information about education, employment opportunities and government services that may potentially allow them to migrate to the formal sector. Design/methodology/approach: The model includes variables that researchers have found to contribute to the growth of informality, such as the state of the economy, the impact of excessive taxes, the impact of regulation, the level of poverty and, of course, ICT metrics, specifically access to both cell phones and broadband as the main two mechanisms through which individuals in the informal sector can obtain information. The analysis relies on a multiple indicators and multiple causes statistical model, to evaluate the hard-to-measure informal economy. A panel data set of 170 countries covering a period of five years was used. Findings: It was found that ICTs empower people, but such empowerment is not always positive for society. So, while mobile phones reduce transaction costs of informal business, this leads to their growth, as they are only a coordination technology. The empowerment that comes from broadband, meaning greater and deeper access to information and resources, can help reduce this sector of the economy and potentially improve these individuals’ lives as well. Research limitations/implications: Measurement of the informal sector is a challenge to researchers precisely because it is hidden. This, like other work in this area, relies on estimates from indirect measures of the informal sector. The results are to be interpreted with caution. In addition, given that this research relies on country-level data, any specific policy decision will have to take particular circumstances into consideration to adapt these results to a specific context. Practical implications: This study is important because of the more nuanced effect found between narrow and broadband technologies with respect to the informal economy and because of its policy implications. Given the results, governments should consider broadband as an additional tool to help individuals make the transition from the informal to the formal sector. Social implications: Once an individual who works in the informal sector begins to realize the advantages of moving to the formal sector, it with the help of ICTs. This awareness could potentially lead to a slow but steady migration away from the informal economy that can improve the economic conditions of the population in these countries. Originality/value: Scholars up to this point have been quite enthusiastic about the benefits of ICTs. In this paper, it was found that the effects are not always positive; a mobile does not help people move away from poverty and, in fact, supports the informal sector. It was found that only broadband can help these entrepreneurs move into the formal sector.; Information and communication technologies as drivers of social unrest -- Information and communication technologies (ICTs) are alleviating frictions associated with the gathering and distribution of information, as well as reducing transaction costs related to the identifying, monitoring, and coordination of citizens dissatisfied with certain government policies. We conducted a random-effect logit tests based on a uniquely developed panel dataset of 138 countries from 2005 to 2014 to determine, ceteris paribus, whether or not ICTs play a role in facilitating changes to the status quo that gravitate against government policies. We found that ICTs although it can reduce hysteresis, the tendency to remain passive, inertia, is stronger. In addition, because ICTs are multi-purpose technologies they also support other beneficial economic and political activities which can explain why we don't see greater evidence of social unrest with these technologies. The literature on social unrest provide some clues about this phenomenon. People are willing to engage in these movements but it appears that only during a crisis.; Così fan tutte -- In this article, we argue in favor of a macro-societal approach to protect people from the potential harms of personal information online. In the tension between information and privacy, “the right to be forgotten” is not an appropriate solution. Such a micro, individual-based answer puts the burden of protection on each person instead of on external entities that can abuse such knowledge. The personal responsibility to delete personal data is challenging because of the leakage of data that happens through the connections we have with others, many of whom do not share the same privacy preferences. We show that effective deletion is almost impossible (the eternity effect), and is unfair due to the resource burden it entails when users try to achieve it, while at the same time ensuring the potential benefits we can derive in the future from having personal information online. In addition, deletion requests can negatively affect other people who are in the same location and time frame and may not want to have their information deleted. Collectively, we argue also that society is worse off because these circumstances lead people to construct sanitized personas while perpetuating a culture of distrust. Given that the harm is real, we describe technology, societal norms, and the implementation of an anti-discrimination directive for the right to a personal life, and we provide evidence on how anti-discrimination efforts in the past have succeeded when legislation leads to the development of infrastructures that help to enforce them. The dissemination of personal information through public sites and social media is, as Mozart suggested in Cosi fan tutte, gradually educating humanity about human weaknesses.; Asian alumni in America and their leadership skills -- In this chapter, we focus on international alumni-students from other countries who graduated from U.S. universities-and their leadership skills as they leave the university. The goals were, first, to identify the elements of leadership that international alumni found that they most needed after graduation, and second, to see how competent feel they were in these skills immediately after graduation. The research relied on both qualitative and quantitative data involving alumni from Asia. From the survey, we learned that no single skill is more important than the others, and in fact, all of the most highly rated skills represent the spectrum of soft skills that one would expect to have in a professional setting. Of these, the students wished they had learned more about communication skills, conflict resolution, and goal setting. From the interviews with Asian alumni who took a leadership program, we learned that the students had learned about themselves and had learned from each other about their different cultures. They mentioned the skills they had acquired for working in groups and the communication and interactions that helped them build confidence and take initiative, which also transferred to their workplaces after they graduated. The study results show that most of the skills alumni perceive to be important in the workplace can be learned more systematically in a leadership program. The benefits that students receive from these programs, as well as the benefits that the university can receive from graduating students with these skills, should give higher educational institutions a motivation to implement these programs, if not broadly, at least for the segments of their international population that need them the most.; Così fan tutte: A better approach than the right to be forgotten -- In this article, we argue in favor of a macro-societal approach to protect people from the potential harms of personal information online. In the tension between information and privacy, “the right to be forgotten” is not an appropriate solution. Such a micro, individual-based answer puts the burden of protection on each person instead of on external entities that can abuse such knowledge. The personal responsibility to delete personal data is challenging because of the leakage of data that happens through the connections we have with others, many of whom do not share the same privacy preferences. We show that effective deletion is almost impossible (the eternity effect), and is unfair due to the resource burden it entails when users try to achieve it, while at the same time ensuring the potential benefits we can derive in the future from having personal information online. In addition, deletion requests can negatively affect other people who are in the same location and time frame and may not want to have their information deleted. Collectively, we argue also that society is worse off because these circumstances lead people to construct sanitized personas while perpetuating a culture of distrust. Given that the harm is real, we describe technology, societal norms, and the implementation of an anti-discrimination directive for the right to a personal life, and we provide evidence on how anti-discrimination efforts in the past have succeeded when legislation leads to the development of infrastructures that help to enforce them. The dissemination of personal information through public sites and social media is, as Mozart suggested in Cosi fan tutte, gradually educating humanity about human weaknesses.; Techno-unemployment -- ; AI’s path to the present and the painful transitions along the way -- Purpose: Artificial intelligence (AI) is likely to have a significant impact on work. It will enhance, but also displace, some professions. This paper aims to look retrospectively at the impact that previous revolutionary computing technologies have had and the institutional values that have shaped the way workers were affected. Design/methodology/approach: This historical investigation relies on academic, government and trade publications of earlier periods in the development of computer technology. The analysis relies on the literature on institutional economics to understand societal outcomes. Within this framework, this paper explores both the ceremonial values associated with tradition and the instrumental values associated with the pursuit of knowledge. Findings: The AI revolution, like previous technological evolutions, will go through stages. Initial implementations will suffer from failures that will, however, generate employment; but, as the technology improves, the AI revolution is likely to enhance productivity but displace workers. Up to this point, the US Government has not been able to respond adequately to the challenge. This paper attributes this to the ceremonial values that public officials and society entertain about personal responsibility and small government. Practical implications: Given the differences in values, this study recommends fending off negative effects though education but also experimenting with other solutions at the local level. Originality/value: Through the lens of history, this study provides a glimpse of what may happen. It also provides a framework that helps understand the outcomes of earlier technological revolutions.; The effect of internet access on government corruption -- The purpose of this paper is to quantify the effect that internet access in a country has on the level of government corruption by studying a cross section of approximately 170 countries. The papers' main model includes political, economic and technological factors that can affect corruption perception. The technological factors focus on internet access. The weighted least square statistical results indicate that the internet is having a positive effect on reducing corruption perception around the world; political factors such as red tape, good goverce and freedom of the press appear to have a greater impact than economic factors, of which only the income level was significant. Corruption is a problem that needs to be controlled, if not completely eliminated. Because of the multiple causes of corruption, it is advisable that governments use the internet as one of the many tools available to them to fight corruption.; Process theory -- Because the IS field is grounded in its applications to organizations, the challenge is to develop a coherent theoretical body of scholarly research, while also remaining relevant to the needs of the practitioner community. In this effort, the purpose of this chapter is to provide scholars with a general understanding of process theories and a taxonomy to provide some direction about how to make contributions to the theoretical legacy, particularly through often-ignored process theories, which are also relevant to practice.; Conclusion -- This concluding chapter identifies a series of common themes discussed across the previous chapters in this book. We follow the life cycle of international students, from the time they begin considering their options for studying abroad to the time they complete their studies. What students seek prior to arrival is a highquality education and a global experience. Both goals are contingent upon successful integration into American universities, which is the focal inquiry of the second section. This section provides empirical evidence for the academic and social challenges that Asian international students experience, as well as some innovative solutions and strategies suggested by faculty and administrators to support international students. These innovative strategies also exemplify the spirit of the two-way street of learning between American universities and Asian international students. The final section looks ahead, after graduation. In sum, this book highlights that there is a lack of knowledge about and institutional support for international students from Asia. Thus, we hope that this book can inspire higher education institutions to make positive changes to the international student experience.; Understanding international students from Asia in American universities -- This book is about international students from Asia studying at American universities in the age of globalization. It explores significant questions, such as: Why do they want to study in America? How do they make their college choices? To what extent do they integrate with domestic students, and what are the barriers for intergroup friendship? How do faculty and administrators at American institutions respond to changing campus and classroom dynamics with a growing student body from Asia? Have we provided them with the skills they need to succeed professionally? As they are preparing to become the educational, managerial and entrepreneurial elites of the world, do Asian international students plan to stay in the U.S. or return to their home country? Asian students constitute over 70 percent of all international students. Almost every major American university now faces unprecedented enrollment growth from Asian students. However, American universities rarely consider if they truly understand the experiences and needs of these students. This book argues that American universities need to learn about their Asian international students to be able to learn from them. It challenges the traditional framework that emphasizes adjustment and adaptation on the part of international students. It argues for the urgency to shift from this framework to the one calling for proactive institutional efforts to bring about successful experiences of international students.; Do mobile phones help expand social capital? An empirical case study -- The rapid adoption of mobile phones, particularly in developing countries, has led a number of researchers to investigate their impact on socioeconomic activity in the developing world. However, until the recent advent of smart communication devices, mobile phones were primarily a relations management technology that enabled people to stay connected with each other. In this article, we focus on this basic function and analyze how people use this technology as a tool to expand their social capital. We use a dataset containing more than three billion call detail records from Rwanda’s largest telecommunication operator, covering the whole country during the period from 1 July 2014 to 31 March 2015, and combine these records with data from the fourth Integrated Household Living Conditions Survey conducted by the National Institute of Statistics of Rwanda in 2015. We found that people’s calling patterns significantly correlated with the income level of their region, which also dictated the destinations of their calls, with middle-income regions acting as a link between the richest and the poorest regions. From these results, we propose a framework for understanding the role of mobile phones in the development of social capital."
Megan Oakleaf,"AMSs -- ; Project RAILS -- Rubric assessment of information literacy is an important tool for librarians seeking to show evidence of student learning. The authors, who collaborated on the Rubric Assessment of Informational Literacy Skills (RAILS) research project, draw from their shared experience to present practical recommendations for implementing rubric assessment in a variety of institutional contexts. These recommendations focus on four areas: (1) building successful collaborative relationships, (2) developing assignments, (3) creating and using rubrics, and (4) using assessment results to improve instruction and assessment practices. Recommendations are discussed in detail and include institutional examples of emerging practices that can be adapted for local use.; 3,000 library users can’t be wrong: Using one open-ended survey question to demonstrate your library’s value -- ; Curricular and co-curricular collaborations to facilitate general education outcomes -- ; The ACRL Standards for Proficiencies for Assessment Librarians and Coordinators -- ; Student learning assessment and the academic library -- Urbana, IL: University for Illinois and Indiana University, National Institute for Learning Outcomes Assessment; The Library Assessment Conference - Past, Present, and Near Future! -- ; Sustainable progress through impact: The value of academic libraries project -- ; The Official (and Unofficial) Rules for Norming Rubrics Successfully -- ; Assessing the impact of the academic library -- ; Do the right (write) thing -- ; Building the Assessment Librarian Guildhall -- ; Notes from the field -- ; Instructional strategies for digital reference -- In today's climate of accountability in higher education, most colleges and universities-and therefore academic librariesconsider student learning the cornerstone of their missions. Reference service is one area in which libraries can demonstrate their commitment to support student learning. Are librarians using reference service to teach students? Or are they letting teachable moments pass by? This study identifies eight instructional strategies librarians can apply in digital reference transactions and analyzes the presence of these strategies in digital reference transcripts. The results suggest that librarians use a few instructional strategies, but could learn and employ several more in their efforts to create information-literate students. The authors hope that increased training in the use of these eight instructional strategies will allow librarians to maximize their impact on student learning. Portions of this article were presented at the RUSA Reference Research Forum at the 2009 ALA Annual Conference.; All together now -- Trinity University has established effective strategies for engaging faculty, administrators, and staff in information literacy instruction and assessment. Succeeding in an area in which many libraries struggle, the Coates Library at Trinity University offers a model for libraries seeking to actively engage their campuses through 1) establishing a common definition of information literacy; 2) developing workshops and grants; and 3) engaging in campus-wide information literacy assessment using rubrics. Furthermore, a survey of Trinity faculty, administrators, and staff reveals facilitators and impediments to campus acceptance of collaborative information literacy activities that can inform the evaluation efforts of librarians at other institutions.; What’s the Value of an Academic Library? the Development of the ACRL Value of Academic Libraries Comprehensive Research Review and Report -- This paper provides an overview of the process undertaken in the US during 2009/10 in developing a major report on the value of academic libraries. A summary of the key findings and recommendations from the report are also provided. While very much focused on the US situation, the author feels the findings may well have resoce elsewhere, including Australia.; Getting Ready & Getting Started -- ; The library's contribution to student learning -- ; Revisiting the Academic Library Value Research Agenda -- ; Correlating library services, expertise, and resources with student learning -- ; Choosing and using assessment management systems: what librarians need to learn -- ; Academic library value: The impact starter kit -- ""Includes 52 activities designed to help librarians as they define library value, assess existing library value, and expand library value in the context of institutional missions.""--How to Use this Book.; An essential partner: The librarian's role in student learning assessment -- ; Academic libraries & institutional learning analytics -- ; A roadmap for assessing student learning using the new framework for information literacy for higher education -- ; Data in the library is safe, but that’s not what data is meant for: Exploring the longitudinal, responsible use of library and institutional data to understand and increase student success -- ; Learning analytics, academic libraries, & institutional context: Getting started, gaining traction, going forward -- ; Learning analytics, academic libraries, and institutional context: Getting started, gaining traction, going forward -- ; Finding the missing piece: Communicating library value to complete the assessment puzzle -- ; Putting the ‘research’ in the Association of College and Research Libraries: 75 years of ‘college and research libraries’ and other ACRL research programs -- ; Snapshot or big picture: Assessing student learning using the framework for information literacy in higher education -- ; Library value communication: Conceptualizing impact, centering on stakeholders, crafting messages, and conveying the Story -- ; Getting started with academic library value: Strategies for initiating conversations, expanding thinking, and taking action -- ; Three years of RAILS research: The take-aways for information literacy teaching, learning, and assessment -- ; So what? The results and impact of a decade of IMLS-funded information literacy assessments -- ; Lessons for the librarian: 10 tips for teaching the one-shot instruction session -- ; 'Do or do not...there is no try': The quest for library value -- ; Choosing and using assessment management systems: What librarians need to know -- ; Riding the RAILS of rubric assessment to keep information literacy learning on track -- ; The one-shot mix tape: Lessons for planning, delivering, and integrating instruction -- ; Rubric Assessment: Results of a 10-institution study of information literacy skills -- Presented at Assessment Institute ; Project RAILS: Rubrics, results, & recommendations -- ; What do we want to know: Articulating a research agenda for the value of academic libraries -- ; A multi-institution study of rubric assessment: Lessons lived and learned -- ; Library contributions to well-rounded assessment practice: Research & recommendations -- ; 500 students, 50 raters, and 5 rubrics later: What we learned from an authentic, collaborative, and national assessment project -- ; From holistic to analytic: Adapting VALUE rubrics for individual campus contexts -- ; Getting information literacy assessment on track: The RAILS project -- ; Revolution or evolution? Strategies for demonstrating the library’s impact in a new world of assessment -- ; Teaching LIS students to teach: an ‘unconference’ session -- ; The ACRL value of academic libraries project: Implications for research, teaching, and learning in library and information science -- ; Supporting student learning and success: The role and impact of academic libraries -- ; The value of academic libraries: Findings and implications for the profession -- ; Linking academic libraries with student success: The environment, the status quo, & the way forward -- ; Work it! Own it! Gaining confidence in assessing the ACRL framework -- ; Learning analytics are coming! Get informed…get connected…get ready! -- ; ‘Gate goals: Learning, literacies, & institutional objectives -- ; Information literacy rubrics: Design and deployment -- ; Information literacy: Rubric design to support the assessment and improvement of student learning -- ; Teaching and learning information literacy -- ; Institutional learning analytics: How can academic libraries connect? -- ; Navigating the peaks and valleys: Assessment of libraries in higher education -- ; Big ideas, not big shots: Leadership through message, not messenger -- ; Library value and the institutional mission -- ; Introduction to library value -- ; Keeping in step: Libraries and the institutional mission -- ; Learning analytics and the academic library: The state of the art and the art of connecting the library with campus initiatives -- ; Teaching, learning, assessment, and analytics: Librarians as value-added partners -- ; Information literacy and learning outcomes -- ; The value of library-provided content: Assessing usage and demonstrating impact -- ; Connect the dots and reach for the stars: Aligning the academic library with institutional aspirations -- ; From passive to active: The impact of libraries and librarians on increasing student learning, improving faculty productivity, and achieving institutional mission -- ; Practical strategies for building assessment capacity in libraries -- ; Library value: Conceptualizing, capturing, and communicating impact -- ; The value of academic libraries: Making an institutional impact -- ; E-magine the possibilities: The role of the library in e-learning -- ; eBooks in academic libraries: Conceptualizing and communicating their value and impact -- ; Yellow book, blue book -- ; Academic library impact: Engaging stakeholders, building partnerships, and telling the story -- ; Update on the value of academic libraries initiative -- ; Value of academic libraries: Reframing, reflecting, research, and recommendations -- ; The importance of using data to drive innovation, improve services, and demonstrate value -- Presented at ProQuest Breakfast.; Library value: Conceptualizing, capturing, & communicating impact -- Presented at ARL workshop.; The value of academic libraries: Research and recommendations -- ; The value of academic libraries: Reflecting, reframing, and reporting results -- ; Assessing undergraduate student research -- ; Getting started with learning outcomes assessment: Purposes, practical options, and impact -- ; Using rubrics to assess student skills -- ; Assessments that scale: Information literacy rubrics and standardized tests -- ; Using rubrics to assess general education -- ; The right assessment tool for the job -- Presented at University of Nevada - Las Vegas Libraries in Las Vegas, NV.; The value of serials in academic and special libraries -- ; Value of academic libraries update forum -- ; Value of academic libraries research agenda -- ; Taking instruction to the next level: Creating evaluations to assess student learning via online tools -- Presented at ACRL Science & Technology Section (STS) Assessment Committee Program.; Evaluation of learning in the academic library: Past compulsory and straight on to compelling -- ; The value of academic libraries: Reframe, reflect, research, and report -- ; Using rubrics in single-shot instruction sessions & more -- Presented at University of Illinois at Urbana Champaign Libraries, Urbana-Champaign, IL; Rubrics and assessing information literacy: Results of a national comparative study -- ; What’s the library’s impact factor? Library value and the difference we make for students and faculty -- ; Play the ace: Assessing, communicating, and expanding the institutional impact of information literacy -- ; Staying on track with rubric assessment: Five institutions investigate information literacy learning -- ; Are they learning? Are we? Learning and the academic library -- ; Demonstrating the value of academic libraries -- ; Closing the 12-13 gap together: School and college librarians supporting 21st century learners -- ; Assessment agreement -- ; Learning analytics and libraries: A primer -- ; Assessment proficiencies in LIS education -- ; Closing the assessment loop: Lessons learned about managing the information literacy assessment cycle and acting on results -- ; Happy RAILS to you: Using rubrics for authentic, reliable, & convincing learning assessments -- ; Transition to college: Checking off skills for 12-13 success -- ; Educating eScience librarians -- ; On beyond zero: Strategies for demonstrating library value -- ; Assessing student learning using analytic rubrics: Initial results of a national study of information literacy skills -- ; Update on ACRL's value of academic libraries initiative -- ; The value of military libraries -- ; The case for librarians in the classroom: Communicating the value and assessing the impact -- ; Demonstrating academic library value: A national conversation -- Presented at Association of College and Research Libraries, Association of Public and Land-Grant Universities, Council of Independent Colleges, and Association of Institutional Researchers National Summit; Assessing the value of academic libraries: Strategies, tools, and techniques -- ; Demonstrating the value of the library: Assessment tools and techniques -- ; Determining the real value of staff development -- ; Information literacy assessment at Champlain College: A whole different plane -- ; Library assessment in the real world -- ; We're teaching and assessing--So why don't we know what they're learning? -- ; Higher education assessment: How do libraries measure up? -- ; Building capacity for demonstrating the value of academic libraries -- Presented at ACRL, AIR, APLU, and CIC Planning Meeting; Demonstrating impact: The quest for data, correlations, and a clear value proposition -- ; Strategies for ensuring valid and reliable assessments of authentic artifacts of student learning -- ; Evidence based practice for library instruction -- ; Assessing learning in the Five College Libraries: Tools, techniques, and the library value context -- ; Preparing Arizona’s college students of tomorrow, today -- ; Value of academic libraries panel -- ; Value of academic libraries exhibitor discussion forum -- ; The value of Syracuse University Libraries: A dialogue -- ; ACRL research coordinating committee value of academic libraries forum -- ; The value of the library in the teaching and learning process -- Presented at ARL Library Assessment Forum.; Teaching and assessing by design -- ; Integrative programmatic assessment for information literacy -- ; Learning outcomes and the academic library -- ; Academic library value: New perspectives for practice and research -- ; The value of academic libraries -- ; Information literacy assessment and Seton Hill University -- ; Question, find, evaluate, apply: Translating evidence based practice to information literacy instruction -- ; Yours, mine, and ours: Moving students through the information literacy ladder from high school through community college to the college/university level -- ; Norming an information literacy rubric -- ; Information literacy assessment in a 2.0 world: Changes and challenges -- ; Strategies for library assessment in the real world -- ; Library assessment and learning outcomes: Foundations, premises, and principles -- ; Using rubrics for library assessment -- ; Using evidence to make strategic decisions for your library -- ; Adapting and applying AAC&U’s information literacy rubric -- ; How do we stack up? Outcomes-based assessment for library instruction -- ; Puzzling out student learning: Using rubrics to assess information literacy at Trinity University -- ; The impact of academic libraries on student learning -- ; The value of academic Libraries: A comprehensive research review and report -- ; The academic library’s role in the next generation digital learning environment: Expanding support for student learning and success -- ; The problems and promise of learning analytics for increasing and demonstrating library value and impact -- ; Closing the data gap: Integrating library data into institutional learning analytics -- ; Closing the ‘data gap’ between libraries and learning: The future of academic library value creation, demonstration, and communication -- ; Assessing learning with rubrics -- ; Developing information literacy program goals; Using outcomes and methods to create and assess information literacy learning -- ; Faculty collaboration and outreach strategies: Developing your message; Teaching through reference services; Matching your teaching and learning approach with learner needs; Measuring our impact: Assessing teaching and learning; Creating your strategic teaching and learning plan; Promoting active learning through effective lesson plan design -- ; The value of academic libraries for community colleges -- ; Planning for assessment: Outcomes, questions, methods, & results -- ; Are they learning? Are we? Learning outcomes and the academic library -- Since the 1990s, the assessment of learning outcomes in academic libraries has accelerated rapidly, and librarians have come to recognize the necessity of articulating and assessing student learning outcomes. Initially, librarians developed tools and instruments to assess information literacy student learning outcomes. Now, academic librarians are moving to a larger scale assessment approach: the articulation and demonstration of library impact on institutions of higher education. This article considers six questions relevant to the assessment challenges librarians face in coming years: (1) How committed are librarians to student learning? (2) What do librarians want students to learn? (3) How do librarians document student learning? (4) How committed are librarians to their own learning? (5) What do librarians need to learn? (6) How can librarians document their own learning?.; Recruiting for results: Assessment skills and the academic library job market -- "
Michelle L Kaarst-Brown,"It's All a Matter of Choice: Understanding society's expectations of older adult ICT use from a birth cohort perspective -- ; What's so special about studying old people? The Ethical, Methodological, and Sampling Issues Surrounding the Study of Older Adults and ICTs -- ; Secure the edge? Understanding the risk towards wireless grids Edgeware technology -- This article contributes to the foundational understanding of the security vulnerabilities and risk towards wireless grid Edgeware technology. Since communication networks and devices are subject to becoming the target of exploitation by hackers (e.g., individuals who attempt to gain unauthorised access to computer systems), these individuals are gaining ever-increasing knowledge of the often widely-reported exploitable vulnerabilities in these types of innovative technologies; and thus are able to craft increasingly effective computer network attacks (CNA) against such technologies. This research responds to the overall proposition: what security vulnerability enumerations would contribute to the degradation and risk in using a wireless grid Edgeware application in a virtualised cloud environment? Using supporting research pertaining to cyber-attacks and vulnerabilities towards a wireless cloud (e.g., the integration of a cloud computing and a wireless grid architecture), security vulnerabilities in virtualisation environments and specific vulnerabilities exploited against a wireless grid Edgeware application, this research provides a greater understanding of the practical ways wireless grid Edgeware technology can be attacked and the risk in utilising this technology.; A failure to communicate -- Any communications network is subject to becoming the target of exploitation by criminal hackers looking to gain unauthorized access to an information system. As a computer information infrastructure, the wireless grid Edgeware technology model aims at aggregating ensembles of shared, heterogeneous and distributed wireless resources to provide transparent services of various applications, systems and devices. Currently, there is no research exploring the exploitation of technical vulnerabilities from a hacker's attack against a wireless grid Edgeware application. Using a quantitative research method from the theoretical perspective of an anatomy of a network attack, the central premise of this article is to compromise the confidentiality, integrity and availability of a wireless grid called the GridStreamX Edgeware application for vulnerability exploitation through a laboratory experiment within the Syracuse University Wireless Grid Innovation Testbed (WiGiT). The GridStreamX Edgeware application is cloud to 'worst case scenario' emergency response wireless Grid resource, which can be utilized as a data communication vehicle during an enterprise network catastrophe and/or failure. This research makes a meaningful theoretical and managerial contribution because it represents the first empirical examination of researching the technical requirements of the open specifications for wireless grid Edgeware technology.; Degrees and Me: Do I Need a PhD? -- ; Panel - Academic trends, challenges, and opportunities for IT programs in today's evolving environment -- How do academic programs in information technology (IT) react to the new challenges of the evolving environment and multiple stakeholders (accreditation bodies, types of schools, nontraditional students, to name a few)? As an example, according to CIO.com, in the year 2020, technical expertise will no longer be the sole province of the IT department. Employees throughout the organization will understand how to use technology to do their jobs. This extends IT development issues beyond internal training for the IT department, or even traditional entry level or Master's MIS programs found in business schools. New IT graduates need to have a different set of skills; but in addition, non-traditional entrants to the profession, existing IT employees, and mid-career IT professionals are also seeking development opportunities that our academic institutions aim to address.; Fun versus productivity and intentions to use ICT's in Bolivia -- Despite decades of studies on the use of information and communication technologies (ICT's) and almost as many decades of research on national cultural variables around the world, the people of Bolivia may be among the least studied on both counts. This research in progress provides a brief overview of our research that seeks to begin closing this gap. This study applies the technology acceptance model and individual espoused cultural values using a societal sample of 1129 Bolivian respondents seeking to understand how computers and Internet are being accepted by users in a country where many conditions of ICT development such as infrastructure, electronic commerce or electronic government have been only moderately established.; Panel - Cybersecurity workforce development -- ; Trustworthiness attribution -- Insider threat is a “wicked” contemporary organizational problem. It poses significant threats to organizational operations and information security. This article reviews insider threat research and outlines key propositions to conceptualize the interpretation of dynamic human information behavior in an organizational setting, which represent an integration of trustworthiness and human sensors’ attribution in close relationships. These propositions posit that when a focal individual violates integrity-based trust, the group can collectively attribute a shift in trustworthiness, triggering a natural peer attribution process that assigns cause to observed behavior. Group communication can thus reflect subtle changes in a focal individual’s perceived trustworthiness. The ability to understand group-based computer-mediated communication patterns over time may become essential in safeguarding information assets and the “digital well-being” of today’s organizations. This article contributes a novel theoretical lens to examine dynamic insights on insider threat detection.; A cultural perspective on individual choices of STEM education and subsequent occupations -- Attention to health and maintece of a skilled IT workforce is an issue that will not disappear any time in the near future. There is also multi-disciplinary support for a new cultural approach to understanding student attraction to specific IT educational programs and the IT occupation. This paper proposes a new cultural framework to study influences on, and the specific nature of IT cultural assumptions and values of students that affect attraction to information technology (IT) related Science, Technology, Engineering, and Mathematics (STEM) education, and careers. We integrate two cultural theories specific to IT: Kaarst-Brown's (1995) theory of underlying assumptions that reflect one of five specific ""IT Cultural Archetypes,"" and Guzman's (2006) theory of IT Occupational Culture and Commitment. This paper presents theoretical foundations, an investigative model with propositions, a discussion of methodological considerations, and implications for research.; Researching the older it professional -- Many developed nations' populations are aging. For workplaces, this has two important implications: organizations face an increasingly older workforce, at the same time that they experience a higher level of retirements. Both of these factors suggest some dramatic implications for those studying the workplace that must be considered. Regrettably, findings show that age-based research on older adults' experiences with technology is severely lacking (Birkland & Kaarst-Brown, 2007). To help address this gap, this paper reviews the sampling, ethical, and methodological implications for those who seek to study IT professionals and IT use in the aging workplace.; Houston, we've had a problem... -- ; Cultural richness versus cultural large scale insights -- The increasing globalization of business and of the Information Technology (IT) workforce has increased interest in cross-cultural issues associated with distributed software development, virtual teams, and cultural conflict or collaboration using information and communication technologies (ICT's) [6]. We continue to see a reliance on studies using quantitative methods that compare a limited number of cultural variables (such as Hofstede's 1984), often because of the challenges associated with richer interpretive or ethnographic studies. Ethnography is a traditional design approach when studying rich cultural issues, deeply rooted in anthropology and goals of rich, emic description, and understanding [1]. Unfortunately, in information systems (IS) research, there is a predomit emphasis on quantitative survey designs, sacrificing cultural richness for broader sampling of more limited variables. Our extended abstract proposes mixed method designs that incorporate both quantitative and qualitative methods as a viable, richer alternative to survey research of cultural studies. For purposes of our presentation at ACM SIGMIS-CPR, we are providing some preliminary arguments from our larger study where additional research is analyzed and compared. To illustrate our points, however, we briefly compare two IS cultural studies, one using comparative ethnography and one using a sequential, phased mixed method design. Our goal is not to discourage rich cultural ethnographies, but to provide a viable alternative approach that may enable more culture research in IS.; Cracks in the security foundation -- Despite the increased focus on IT security, much of our reliance on 'information sensitivity classifications' is based on broadly specified technical 'access controls' or policies and procedures for the handling of organizational data - many of them developed incrementally over decades. One area ignored in research and practice is how human beings make ""sensitivity judgments"" or 'classify' information they may encounter in everyday activities. This has left what we view as a crack in the IT security foundation. This crack has created a tension between formal IT security classification schema, technical controls, and policy, and the sensitivity judgments that everyday workers must make about the non-coded information they deal with. As noted in government and private reports, a new look at information sensitivity classification is vital to the expanding reach and criticality of information security. Based on a grounded theory study that elicited 188 judgements of sensitive information, we found valuable lessons for IT security in how workers, both in IT and outside of IT, recognize, classify, and react to their human judgments of sensitive information.; Once upon a time -- Allegories are fictional tales that convey meaning not explicitly set out in their narratives. In writing them, researchers move beyond the “realistic” tale to frame coherent organizational metaphors and symbols and to offer a multi-layered truth that lies “between the lines” in the often subconscious spaces of organizational life. As such, this genre offers an evocative, yet concise alternative to traditional approaches for information systems research. Drawing on a 2-year cultural study of strategic alignment of IT in two insurance organizations as illustrative context, the allegory is introduced and demonstrated in five steps to guide researchers in creating their own allegories. This illustration uses allegory to recast diverse cultural and historical data into short stories that involve magic dragons and wizards, thereby demonstrating the usefulness of the genre for comparative, multi-case designs to translate organizational features to achieve a common representation. In conclusion, the paper offers reflections on how the genre of allegory may contribute to future information systems research, to alternative styles of presentation, and to reflexive practices.; Chahta Sia — I am Choctaw: Using Images as a Methodology for Cultural and Technological Discourse -- ; Symbolic Roles of the IT Field Researcher: Integrating Change, Power and Researcher Challenges -- ; IT Governance and Sarbanes-Oxley: The latest sales pitch or real challenges for the IT Function? -- ; Situating Kaarst-Brown's IT Culture Theory for Anticipatory Design: The Value of Localized Symbols and Myths -- ; The Placement Evolution of Information Systems Graduates -- ; ""IT Culture"" Theory: Exploring Universal Archetypes and Localized Symbols for Anticipatory Design -- ; Editors' comments -- ; Special issue editorial -- ; The cio role-understanding an organization’s view of the cio -- At the 2003 society for Information Management’s (SIM) annual meeting in New York City, many of the sessions focused on what CIOs could do once they got a seat with their business peers at the executive meeting table. Heightened concerns about information security and legislative compliance have increased interest in the answer. Despite the importance of IT to modern organizations, many IT executives are still not at that table because they are not viewed as equal to their business peers. Even elevating IT executives to C-level management and giving them the title of Chief Information Officer (CIO) do not guarantee that they are accepted and invited to high-level business meetings. This article provides one perspective on why some organizations are more open than others to affording their CIO an effective, influential, senior executive role. Our conclusion: Domit assumptions about IT in different areas of an enterprise can explain differences in CIO status. Five assumptions that matter are: 1 Who should control IT direction 2 How central IT is seen to business strategy 3 The value placed on IT knowledge 4 Justifications for investing in IT 5 Who are deemed winners and losers when a new IT system is installed. This article explores these assumptions, and the IT clusters they form, to help CIOs and other senior IT executives better address the different “assumption environments” they face.; Lessons for IT Project Manager Efficacy -- In the maturing IT project management space, there are still many debates about the skills needed to achieve success. This article presents a review and synthesis of project management literature that highlights the potential conflict in goals and the measurement of “success” from three perspectives: project outcomes, project management processes, and the project manager's influence. Our review indicates that each perspective of success, defined by various stakeholders at various points in time, shifts the focus onto different skills and knowledge. Drawing upon this tri-focal lens, we propose a shift in focus on success to the intersection, or “sweet spot of project manager efficacy”.; The future of iT work -- The future of work is widely debated in terms of skills shortages, disappearing or emerging jobs, ongoing automation through artificial intelligence (AI), and what might happen if we do not have to work due to increased substitution of human with machine labor. Our goal is not to rehash these debates, but to reflect on them in terms of information technology (IT) work in particular. The purpose of thinking about the future is not to predict with precision or certainty what will happen. Rather the purpose is to sensitize us toward choosing pathways and taking actions that increase the probability of the futures we would prefer and decrease the probability of future states we would like to avoid. This paper considers a number of trends and reflects upon them from the dual, potentially conflicting perspectives of IT worker and of society. We close with our thoughts on convergence of both trends and impact, and potential implications.; The potential of emerging technology for social change -- The purpose of this panel is to explore the potential for emerging technology to engender social change. Technology is transformative, and has already seen innovative application in business and industry, and of course in relation to society and social networking. We will discuss the current state of 'emerging technology', and several perspectives of considerations with emerging technologies and society. We will describe some current applications of emerging technology in a range of fields, in order to identify the potential for emerging technology to support social change. Our goal is to open discussions about opportunities for emerging technology, and practical applications or approaches to how these opportunities can be exploited.; Panel - Preparing the next generation of computer personnel -- The purpose of this panel is to explore different techniques and approaches that are currently in use within the tertiary sector to prepare students in the technology industry for the move to working in the industry. A growing demand from employers for soft skills, and from university bodies for positive graduate employment outcomes is leading to a re-imagining of our approach to coursework. Work integrated learning and industry involvement within coursework and assessment will be presented, together with approaches for encouraging students to engage with industry and the development of non-traditional course offerings.; How do public library administrators generate and evaluate ideas for new services? A proposed model based on evidence from Cuyahoga County Public Library -- A library's ability to innovate remains crucial to its sustained success, yet our understanding of innovation at the library level is still underdeveloped. While we know that libraries (like most service providers) typically innovate through the adoption of technological and organizational innovations, few attempts have been made to conceptualize this process. After reviewing briefly the literature on innovation at the library level, this short paper reports on an exploratory case study of the generation and evaluation of new service ideas (i.e., service innovation's 'front end') by administrators at Cuyahoga County Public Library (CCPL) in Ohio, a public library renowned for its innovativeness. From this case study a working model is proposed and supported with examples.; Mindful new service conception in not-for-profit organisations -- Service innovation entails developing new services, but new service development can be difficult even with slack resources. While no consensus has been reached on the determits of new service development (NSD) performance, some research has pointed to the importance of new service conception (NSC) practices. Research into NSC is still immature, though, and what we know about it is grounded in traditional expectations of slack resources. To better understand how new services are conceived under conditions of resource scarcity, we draw from an embedded, interpretive case study of an innovative organisation that managed ongoing new service conceptions for more than ten years under conditions of continually reduced resources. Findings show that this organisation was able to conceive many successful new services by: 1) mindfully identifying new, germane customer needs while engaging with new information sources; 2) keeping in mind unresolved customer needs while trying to identify matching potential solutions, especially external resources. This paper contributes to the NSD literature by advancing a model based on these findings.; The business transformation payoffs of cloud services at Mohawk -- As well as reduced costs and increased efficiencies, cloud services can provide business transformation payoffs, as illustrated by the case of Mohawk (formerly Mohawk Paper Mills). Mohawk designed and implemented a cloud integration platform that enabled it to transition its traditional manufacturing business model to become a serviceoriented enterprise, with significant payoffs in terms of new sources of revenue and reduced internal operating costs.; Towards a Service-Oriented Enterprise: The Payoff of Cloud Services at Mohawk -- ; The it compensation challenge -- Attracting, motivating, and retaining Information Technology (IT) professionals has proven to be an ongoing challenge, regardless of the era in question. On average, almost two-thirds of the IT operating budget goes to staffing expenses, with managers and human resources experts struggling to balance IT compensation decisions with the uncertainties their organizations face. While there are many compensation studies that provide descriptive evidence using institutional variables, we lack a comprehensive IT compensation model that explores explanations for IT compensation decision factors from the angle of reducing IT-related uncertainties. This paper integrates concepts from traditional compensation literature, the role of non-monetary rewards, and a multi-level view of factors that influence IT compensation decisions. The use of multi-level factors is supported by traditional agency theory perspectives of compensation, and by contingency theory that looks at external and internal (organizational) contingencies. An interesting result of our analysis is that agency and contingency perspectives of risk provide insights on when fixed or variable pay plans may be more beneficial to the organization. There may be conditions when risk is logically lower, but overall IT compensation amounts will be higher. In particular, our paper proposes that IT compensation can be a viable IT goverce mechanism in high-risk conditions when effective monitoring and performance measurement are less attainable, such as in outsourcing situations.; Understanding IT compensation strategies from the perspective of small non-IT firms -- Since 2008, the weakened global economy has resulted in increased layoffs, hiring freezes, and company closures in high-tech industries. Ironically, there has been increased demand for information technology professionals (IT workers) in non-high-tech industries such as ficial services, healthcare, and transportation industries. This idiosyncrasy suggests there is value in exploring IT personnel strategy in non-high-tech industries. Larger firms or high-tech companies commonly compete for IT talent through lucrative incentive payments or higher base salaries. In contrast, smaller companies or non-high-tech firms with limited resources are more constrained in their compensation strategies, and more vulnerable in competing for IT talent. Taking this predicament as a backdrop, this paper reports the findings of a case study investigating IT compensation practices in a small, U.S. based, Chinese media firm that relied on IT to change its media strategy. Focusing on four specific risk areas, we illustrate how this firm competed successfully when resources were scarce but competition high within and across the industry."
Murali Venkatesh,"Social design's implications for the IS field -- Social design is the collective task of developing an artifact for the public good. These projects are managed by community member volunteers who all have a shared conception of the public interest. In this paper we address the lack of attention social design has received in the Information Systems design research community. The paper focuses on the social organization of the design collective and outlines the threat social dilemmas pose to these projects. Throughout this discussion we challenge traditional models of action which do not support the collective action of social design. The constitutive design model is presented as a way of addressing social dilemmas in social design projects. How these social dilemmas are handled can significantly affect the form of the artifact being developed. Finally, we propose an academic curriculum for teaching the principles of social design in Information schools geared towards producing more socially conscious technical practitioners.; “Let's be friends” -- ; Smart city investments -- The city of Syracuse in New York announced an ambitious smart city plan which, when fully implemented, promises to make it the most connected city in the northeastern US. Thanks to a strategic investment by the State of New York, the city is home to what is billed as the world's first Drone Corridor for RD. We outline a decision framework (The Syracuse Wheel) for public private partnership to help city leaders and private investors navigate the exciting implications stemming from these two strategic developments and the city's environment to augment the priority areas of Autonomous Mobility and Connectivity. The Wheel positions Syracuse as a prime market for visionary Public Private Partnership (PPP) proposals given its infrastructure and assets specific to Unmanned Aerial Systems (UASs) and Autonomous Vehicle Testing. The research also suggests ways to mitigate the problems associated with data goverce and IP goverce that various large-scale PPPs have faced in the past. We conclude with a decision-making framework which facilitates a fast-track approval mechanism for investment proposals from private entities as Syracuse prepares for its future as leading-edge Smart City and UAS RD hub.; Institutional work and technology artifacts -- How artifacts come to persist is a neglected area in organizational theory. In IS, Lucas et al. 2007) stress implementation research that takes the long view, but little is known about maintece practices. Using Lawrence et al. 2009) institutional work framework, we analyze stakeholder efforts to stabilize and now maintain the Urban-net, a broadband network. We track it from inception through design stabilization to post-stabilization. Empirically, we add to research on the neglected area of maintece work. Re: theory, our contributions are two-fold. First, we distinguish artifact stabilization from maintece, a distinction Lawrence et al. 2009) ignore. Bijker's 1997) idea of stabilization offers a way to think about the two. The temporal and relational scope of the effort involved, we show, can be different. Second, we adapt the term gardening from Olsen 2003) to characterize the multi-stranded nature of maintece, involving efforts to preserve while also amending the Urban-net."
Ping Zhang,"Social commerce -- Social commerce can be briefly described as commerce activities mediated by social media. In social commerce, people do commerce or intentionally explore commerce opportunities by participating and/or engaging in a collaborative online environment. As a relatively new phenomenon first widely acknowledged in 2005, social commerce presents new opportunities to examine issues related to information/content, business strategies, management, technologies, and people's behavior. This article presents a qualitative longitudinal study which systematically examines technological features and tools in social commerce websites to illustrate their evolution and impacts on the formation of social commerce practice today and its potential future. Using captures crawled by the Wayback Machine, fifteen websites are analyzed from the year they were ""born"" to the year of 2010. The analyses are guided by a semi-structured checklist of expected and desired tools and features based on a literature review in social commerce. The study finds that social commerce activities appeared as early as the late 90s and that there are different approaches to incorporating social channels and social networks. In addition, the findings support a preliminary classification of social commerce websites, a realignment of the term's conceptualization and the anticipation of possible new directions for this market segment.; The AIS Grand Vision Project -- In 2014, the AIS Council formed a Task Force to develop a proposal for an AIS Grand Vision Project that aims to address the risks and side effects associated with ICT such as privacy, cyber-attacks, gaming addiction, fraud and cyber-crimes, global warming, sustainability, etc. As first steps, AIS leadership agreed to organize panels on this topic at AIS conferences and launch a special issue with JAIS. The Bright ICT Initiative aims to design an ICT-enabled ""bright"" future through globallycoordinated, funded research programs in partnership with academia, industry, government, and international organizations. The scope of the initiative encompasses the development of relevant technologies, business models, public policies, international agreements, standards, and metrics. Given that the proposed AIS Grand Vision Project is still in an early stage, our panel aims to stimulate further discussion on it in order to raise awareness within our community, build community consensus about its plans and objectives, and propose effective approaches to realizing the Vision. All AIS members are invited and urged to play a role in the project, and this panel provides one opportunity to learn how to get involved.; Website Features that Gave Rise to Social Commerce -- Social commerce is a form of commerce mediated by social media and social network services (SNS). As a multifaceted phenomenon, social commerce can be studied from different angles and analyzed through the lens of various disciplines. This article examines website technical features to depict the transformation of e-commerce into social commerce. We first develop a conceptual framework to capture three emphases of e-commerce: transactional, relational and social. Then, we use the framework to conduct an historical analysis of the actual website screen captures for five top e-commerce companies since their websites were established. We were able to identify and classify a total of 174 emerging technical features. Our results show that: (1) all three emphases were expressed in the websites and have been reshaping their business and marketing strategies over the years; (2) there was a clear blooming of social features in 2007; and (3) there has been a significant effort to strengthen customer and merchant ties through relational features. Our findings signal that there still is room for further exploration of the social emphasis.; Design Research and Human-Computer Interaction -- ; Effects of Empowerment on Performance in Open-source Software Projects -- An enduring issue that intrigues researchers and practitioners in open-source software (OSS) development is what motivates individuals to participate and make contributions, given the lack of numerating mechanisms. Amidst several end-state-focused motives advocated by prior studies (such as improved programming skills and future career growth), we add that an important contributing factor is empowerment , the positive feelings derived from task assessments in OSS projects. Through survey data collected from 233 OSS participants, we assess how components of psychological empowerment (i.e., autonomy, competence, meaningfulness, and impact) derived from OSS tasks may affect the work output of participants. In particular, we demonstrate that competence and impact have a positive influence on OSS participants performance, while autonomy and meaningfulness have a slightly negative influence on performance. In addition, empowerments effects on performance can be mediated by effort expended. Theoretical contributions and managerial implications of this study are discussed.; The Effects of Extrinsic Motivations and Satisfaction in Open Source Software Development -- As a new phenomenon in the software industry, Open Source Software (OSS) development has attracted a high level of research interest. Examining what motivates participants in OSS projects and how to enhance the effects of motivations has received increased attention in recent years. This study is prompted by the significant but detail-lacking examination of differential effects of various types of extrinsic motivations on participants' task effort in OSS projects and their interaction effects with participants' psychological states. Drawing upon self-determination theory, we establish four types of extrinsic motivations in OSS communities (i.e., external, introjected, identified, and integrated motivation) and investigate how these types affect task effort differently. Also, integrating self-determination theory with affective event theory, we study how satisfaction of needs for competence, autonomy, and relatedness moderates the relationships between extrinsic motivations and task effort. The research model is largely supported by data from 250 participants in various OSS projects. Theoretical contribution and practical implications are discussed.; Continued use of technology -- This study investigates factors influencing individual users' continued use of technology, or technology continuance. Technology continuance is defined as individual user's continued employment of system. We consider mobile computing technology as a particular example for the investigation. In this paper, we first review the theoretical backgrounds based on the literature of post-adoption studies. Then we develop a research framework which considers both controlled and automatic processes. In particular, a person's technology continuance is determined by both continuance intention and habit. In the continued use of technology, intention can be influenced by satisfaction of previous experiences, which are affected by cognitive and affective beliefs; and beliefs and satisfaction are also influenced by confirmation of prior expectation. Habit, which is also influenced by satisfaction, can affect the continuance usage behavior. A research design was developed, and the research model will be empirically tested by a survey with mobile computing technology users.; Understanding Data Sharing Behaviors of STEM Researchers -- A number of factors influence STEM (science, technology, engineering, and mathematics) researchers' data sharing behaviors. Based on the theory of planned behavior, a research model focusing on beliefs, attitudes, norms, and resource factors was proposed. The research model was tested with a total of 1298 responses from a national survey in the United States (US). The data analysis results, using the partial least squares (PLS) technique, show that attitudinal beliefs (including perceived career benefit, risk, and perceived effort), disciplinary norms, and perceived availability of data repositories all have significant impacts on STEM researchers' attitudes toward data sharing, and further, both the attitude toward data sharing and the availability of data repositories have strong influences on researchers' data sharing behaviors. These results demonstrate that the theory of planned behavior is a useful theoretical framework for explaining STEM researchers' data sharing behaviors. From the practical perspective, this research suggests that information professionals can better serve STEM researchers by allocating their efforts in two ways: (1) Providing appropriate data services and tools to reduce researchers' efforts involved in data sharing, and (2) providing data repositories to facilitate researchers' data sharing behaviors.; Absent information technology in legitimate information systems research -- The current identity of the information systems (IS) discipline, to certain extent, relies on the presence of information technology. The urgent call to theorizing IT artifacts made by previous IS studies raises concerns on the roles and importance of IT artifacts in the wide range of topics investigated by IS scholars, especially in the studies in which IT artifacts are considered absent. We analyze the topics, IT artifacts, and contexts of these studies from the 2009 and 2010 ICIS proceedings to address this concern. We find that IT professions and IT artifacts are significant contextual factors that cannot be ignored in these studies. This helps the IS discipline to rethink the establishment of its intellectual identity solely on the premise of theorizing IT artifacts.; What makes customers shop online? -- Electronic commerce customer relationship management (e-CRM) has become a fundamental research area, as business-to-customer e-commerce (B2C) is growing at a phenomenal rate. Among the many issues eCRM addresses, one question is often asked: ""What makes customers shop online?"" Thorough understanding of this issue will help an electronic store become more competitive. A good number of studies have been conducted to answer this question. These studies seem to take diverse perspectives and investigate various aspects of the phenomenon, yet few have drawn coherent pictures of the dynamics. The objective of this chapter is to draw such a picture. To fit the theme of advances in MIS, we conduct an analytical review of the IS literature on B2C online shopping behavior at the level of the individual. We develop a classification of research variables and a framework to provide an overview of the state of the art of this area and to point out limitations and directions for future research. The results show that one's online shopping intention, behavior, and satisfaction are significantly associated with one's beliefs about and affective reactions to e-commerce/e-stores and one's attitudes toward online shopping. In addition, external environment, demographics, personal characteristics, and e-store characteristics have significant effects on customers' shopping intention, behavior, and satisfaction, either directly or mediated by beliefs, affect, and attitudes. Needed for future research are a common theoretical framework, widely accepted instruments, and consistency in terminology to allow comparing results across studies and to accumulate knowledge. We also call for more research effort in customer satisfaction and affective reactions, which have not received adequate attention despite their fundamental roles in customers' online shopping.; A typology of online window shopping consumers -- Consumer online shopping behaviors are well attended in the IS and marketing literature. Yet, there is another group of individuals who spend a lot of time online but do not purchase anything. This online window shopping phenomenon is intriguing to both scholars and marketers yet it is less studied and little understood. Questions such as what the online window shopping consumers do during their visits, how to differentiate their activities and how to design marketing strategies to stimulate them to buy are all essential and beg for investigation. To address this gap, we propose a typology of online window shopping consumers based on the Consumer Information Processing Model, then empirically validate and refine the typology using a set of clickstream data. The final typology contains four main types of online window shopper consumers: 1) promotion finders, 2) social & hedonic experience seekers, 3) information gatherers, and 4) learners & novices. This study extends consumer online behavior research in both e-commerce and social commerce by focusing on the specific group of consumers who only do online window shopping. Besides theoretical contributions, the findings also provide marketers and businesses with valuable references for designing targeted marketing strategies or promotional activities for online window shopping consumers.; Human-machine function allocation in information systems -- In the past, information systems development methodologies primarily focus on whether the needs of an organization could be met. In recent years, several human-centered systems development methodologies are developed to emphasize both organizational and human needs. In addition to an information system being useful, its usability become a central concern, and user analysis and task analysis are important parts in these methodologies. Human-machine function allocation is an important aspect of task analysis. Yet, current research and practice in this area show a gap for systematic and consistent guidelines and approaches. To address this gap, this paper proposes three guidelines and a comprehensive approach for human-machine function allocation when designing organizational information systems. Built on Price's decision matrix, Levels of Automation, and the Analytic Hierarchy Process (AHP), our approach consists of four steps in determining human-machine function allocation. To illustrate this approach, an application example is provided.; Coping with Nuisances on the Web -- A model of web annoyance coping was constructed based on the Cognitive-Motivational-Relational Theory of Emotion. The proposed model predicts that web users would cope with annoyances through both problem- and emotion-focused strategies. In two focus groups, participants identified nuisances encountered during use of the two websites (Facebook and MySlice), and their reactions to the nuisances as coping strategies. The findings include a web nuisance categorization and empirical evidence to support the proposed model of web annoyance coping. Besides filling a gap in the literature and providing theoretical contributions, the study has practical implications to website designers, marketers and other stakeholders.; Human-Computer Interaction: Interactivity, Immersion and Invisibility as the New Extensions -- ; The Impact of Social Media Features on Teaching Presence in Communities of Inquiry -- ; Deconstructing Motivations of ICT Adoption and Use: A Theoretical Model and its Applications to Social ICT -- ; Applying Extended Adaptive Structuration Theory to Qualitative Research on Human-Computer Interaction -- ; Online Information Product Design -- With users placing an increasing demand on cross-product integration in electronic markets, the success of new information products becomes increasingly dependent on its integration design with existing products. Consequently, many online vendors have been incorporating branding into information product designs. This approach reflects a critical marketing strategy called ""brand extension."" In contrast to the popularity of this strategy by online vendors, however, there is little theoretical work or empirical evaluation in the information systems (IS) literature on the relationship between information product integration design under the same brand umbrella and consumers' usage of the newly introduced information products. Addressing this gap, this study investigates the antecedents of online brand extension evaluation with an emphasis on the influence of product integration. Based on the stimulus-organism-response paradigm and the categorization theory, this study proposes and validates a research model using a scenario-based experiment that involves a search engine and its extension to an e-commerce website and an online encyclopedia. The findings confirm that integration level influences perceived fit and perceived tie between focal and newly extended products. Perceived fit and perceived tie positively impact users' evaluations of online brand extension, and consequently influence users' intention to use the extended products. User expertise moderates the effect of product integration on perceived tie: the greater the users' expertise in focal product, the stronger perceived tie is affected by online product integration. This study contributes to both research and practice by advancing the overall understanding of exploiting online branding values and by providing insights into online information product design and promotion.; Moderating effects of perceived affordances on users' adaptive media use -- Factors contributing to communication media adoption have been well studied. Several theories (e.g., media richness theory and media synchronicity theory) have been developed to explain or predict media adoption behavior. However, adoption is only an initial stage of media use. Reasons for adaptive media use in postadoption phase are of greater significance and interest. This poster posits that people's media use is dynamic in various communication environments, and it is determined by effects of multiple factors, including media characteristics, message complexity, and social context, whose influences are moderated by users' perceived affordances of media's capabilities to satisfy their needs.; Categorizing Consumer Behavioral Responses and Artifact Design Features -- Many consumers encounter and interact with digital artifacts and services on a daily basis, either willingly or unwillingly. This paper conceptualizes consumer online behaviors into more refined categories in the context of online advertising. Behaviors can be differentiated by their directions and intensities. Approach and avoidance are two directions of behavioral responses when consumers encounter online advertisements. Active and passive behaviors reflect the levels of intensity of behavioral efforts consumers put when dealing with online advertisements. Active behavioral responses mean that consumers make effort to act upon online ads, either approaching or avoiding them. Passive behavioral responses indicate that consumers make little effort to change the current status, and would approach or avoid in a passive way. We posit that consumers’ behavioral responses can be generally categorized into four major types across these two dimensions: active approach, passive approach, active avoidance, and passive avoidance. In addition, we categorize the design features of online advertisements with a three-facet framework: ad content, ad form, and ad action. Ad content is concerned with the message or meaning that an ad carries; ad form is about materializing content based on presentation styles such as media, location, color, audio, etc.; and ad action is concerned with the behaviors of an ad such as movement, onset timing, frequency, etc. Due to the novelty of the categorizations, an exploratory study was conducted to provide empirical evidence on the categorizations of the four behavior types and three design feature types. Our findings indicate that all four types of consumer behaviors were present, and all behaviors identified by our study can be classified into one of the four types. The same is true for the design feature categorization. We illustrate that the categorization of the three types of ad design features can also guide the understanding of consumers’ judgments of ads, which may function as a bridge of ad design features’ influence on consumer behaviors. This study contributes to a stronger, more refined understanding of how consumers react to online advertising services, and how such responses relate to various types of design features. It also has practical implications for the design, delivery, and management of digital artifacts and services in general.; Forced or Inspired: Understanding Consumers' Cognitive Appraisals and Behavioral Responses towards Online Advertising -- ; Perceived Affordances of Web Advertisements of Web Advertisements: Implications for Information Artifacts Design -- ; Media Selection Preferences of US College Students: Empirical Evidence and A Proposed Research Model -- ; Gamification and basic human needs in information technology design -- Gamification is a promising approach to enhance user experience in many contexts. Taking a motivational perspective and using the motivational affordances theory as a guiding framework, this paper presents a literature analysis of 60 journal articles that study motivational influences of gamification in information technology design. Our results reveal that four types of game design features and eight basic human needs are studied in this pool of literature. Correspondence analysis indicates some interesting associations between game design features and basic human needs. We discuss the findings and suggest potential directions for future investigations.; Passive or active -- Approach and avoidance are two major types of behavioral responses when consumers encounter interferences caused by online advertising. This paper argues that approach-avoidance is not the only dimension from which researchers can examine behavioral responses toward online advertising. The inclusion of the active-passive behaviors dimension enriches the understanding of consumers' coping strategies. Active and passive behaviors differ from each other by the intensity of coping efforts. Active behavioral responses imply that consumers act upon online ads and make efforts to approach or avoid them. Passive behavioral responses indicate that consumers make little efforts to change the current status, and would rather approach or avoid in a passive way. Data was collected through an online survey by asking participants to recall their experiences with online ads and their behavioral responses. We found that the effects of ad design characteristics (content, form, and behavior) on consumers' behavioral responses differ across two-dimensions: Approach-Avoidance and Active- Passive. In addition, these effects also vary when consumers have different views (negative vs. positive) of the online ads. The contribution of this study lies in suggesting the two-dimensional view of studying consumers' responses toward online ads and in deepening our understanding of consumer behavior in dealing with digital artefacts in general.; The impact of atmospheric cues on consumers’ approach and avoidance behavioral intentions in social commerce websites -- Approach and avoidance are typical behavioral tendencies of consumers when exposed to a new environment. Drawing on the stimulus-organism-response (S-O-R) framework, this study investigates the effects of atmospheric cues on consumers' approach and avoidance intentions in social commerce environments. We elucidate the interaction mechanisms between atmospheric cues (task, aesthetic and social cues) and consumers' evaluations through the lens of perceived affordances. Then we investigate how three types of perceived affordances (utilitarian, hedonic and connective) influence consumers’ approach and avoidance behavioral intentions. A three-way factorial experiment provides strong evidence that task cues, aesthetic cues and social cues elicit perceived utilitarian, hedonic and connective affordances, respectively. Approach behavioral intentions were affected by all three types of perceived affordances, yet avoidance intentions were only affected by perceived utilitarian and hedonic affordances. This paper discusses both theoretical and practical implications for social commerce research.; The Evolution of Social Commerce: An Examination from the People, Business, Technology, and Information Perspective -- Social commerce is a form of commerce mediated by social media and is converging both online and offline environments. As a relatively new phenomenon, social commerce has evolved quickly in practice, yet has gained little attention in the IS discipline. With its pervasiveness in businesses and people's lives, social commerce presents ample research opportunities that can have both theoretical and practical significance and implications. This article aims to capture researchers' attention by describing the characteristics of social commerce and its potential future directions. We trace the evolutionary patterns of social commerce chronologically, based on trade articles and academic publications from 2005 to 2011. A framework that combines people, management, technology, and information dimensions is used to provide a systematic analysis of social commerce development. Our examination shows that since 2005, the year the term social commerce was incepted, assumptions and understanding of people in social commerce move from a simple and general description of human social nature to a rich exploration with different angles from social psychology, social heuristics, national culture, and economic situations. On the management dimension, business strategies and models evolve from the short-tail to long-tail thinking, with invented concepts such as branded social networks/communities, niche social networks/communities, niche brands, co-creating, team-buying, and multichannel social networks. Technologically, IT platforms and capabilities for social commerce evolve from blogs, to social networking sites, to media sharing sites, and to smartphones. While Facebook becomes a profit-generating platform, creating the notion of f-commerce, Google and Twitter become strong competitors with great potentials. Information in social commerce evolves from peer-generated, to community-generated (crowdsourcing), to consumer and marketer co-created, and to global crowdsourced. Our examination identifies various conceptualizations, terminologies, views, and perspectives about social commerce and its relation to other well-known concepts such as e-commerce. In light of the evolution of social commerce, we provide possible future directions for research and practice.; Conceptualizations of technology in the information field -- The interdisciplinary nature of the information field (iField) calls for a greater understanding of how iSchool scholars engage with information technology in their research. The purpose of this article is to study how much emphasis iSchool scholars put into studying technology, and how they conceptualize technology in their research. Using content analysis as our method of investigation, we coded journal articles published by tenure track faculty members between 2008 and 2010 from five iSchools (Drexel, Michigan, Pittsburgh, Syracuse, and Washington). We report preliminary empirical evidence showing a microscopic view on the diversity in how iSchool scholars engage with technology, one of the fundamental components in the iField.; Affect in the ICT Context -- ; Advances in social commerce research -- ; The Intellectual Characteristics of the Information Field -- As the information field (IField) becomes more recognized by different constituencies for education and research, the need to better understand its intellectual characteristics becomes more compelling. Although there are various conceptualizations of the IField, to date, in-depth studies based on empirical evidence are scarce. This article reports a study that fills this gap. We focus on the first five ISchools in the ICaucus as a proxy to represent the IField. The intellectual characteristics are depicted by two independent sets of data on tenure track faculty as knowledge contributors: their intellectual heritages and the intellectual substance in their journal publications. We use a critical analysis method to examine doctoral training areas and 3 years of journal publications. Our results indicate that (a) the IField can be better conceptualized with empirical support by a four-component model that includes People, Information, Technology, and Management, as predicted by the I-Model (Zhang & Benjamin, 2007); (b) the ISchools' faculty members are diverse, interdisciplinary, and multidisciplinary as shown by their intellectual heritages, by their research foci, by journals in which they publish, by the contexts within which they conduct research, and by the levels of analysis in research investigations; (c) the five ISchools share similarities while evincing differences in both faculty heritages and intellectual substances; (d) ISchool tenure track faculty members do not collaborate much with each other within or across schools although there is great potential; and (e) intellectual heritages are not good predictors of scholars' intellectual substance. We conclude by discussing the implications of the findings on IField identity, IField development, new ISchool formation and existing ISchool evolution, faculty career development, and collaboration within the IField.; The Affective Response Model -- Affect is a critical factor in human decisions and behaviors within many social contexts. In the information and communication technology (ICT) context, a growing number of studies consider the affective dimension of human interaction with ICTs. However, few of these studies take systematic approaches, resulting in inconsistent conclusions and contradictory advice for researchers and practitioners. Many of these issues stem from ambiguous conceptualizations of various affective concepts and their relationships. Before researchers can address questions such as ""what causes affective responses in an ICT context"" and ""what impacts do affective responses have on human interaction with ICTs,"" a theoretical foundation for affective concepts and their relationships has to be established. This theory and review paper addresses three research questions: (1) What are pertinent affective concepts in the ICT context? (2) In what ways are these affective concepts similar to, or different from each other? (3) How do these affective concepts relate to or influence one another? Based on theoretical reasoning and empirical evidence, the affective response model (ARM) is developed. ARM is a theoretically bound conceptual framework that provides a systematic and holistic reference map for any ICT study that considers affect. It includes a taxonomy that classifies affective concepts along five dimensions: the residing, the temporal, the particular/general stimulus, the object/behavior stimulus, and the process/outcome dimensions. ARM also provides a nomological network to indicate the causal or co-occurring relationships among the various types of affective concepts in an ICT interaction episode. ARM has the power for explaining and predicting, as well as prescribing, potential future research directions.; The IS History Initiative -- After officially appointing an AIS historian and forming the AIS history task force at the beginning of 2013, the AIS supported a set of systematic efforts, named IS history initiative, to preserve and represent the IS field’s history. From the perspective of the first AIS historian, I provide some background for the IS history initiative. Then I outline a detailed strategic plan and current status of its implementation. Ultimately, the IS history initiative has three goals: (1) to collect, represent, and preserve the IS field’s history; (2) to interpret, write, disseminate, and review the IS field’s history; and (3) to discover/identify IS genealogy, roots, sources, and facets that deserve to be examined from a historical point of view. Correspondingly, the strategic plan contains three parts. Each part has several specific tasks, many of which were already completed at the time of this writing, and several are either in progress or are planned for future efforts. This paper overviews both current efforts and guiding future efforts related to preserving and representing IS history.; Americas Conference on Information Systems AMCIS2013 Chicago IS History -- The history of any academic discipline plays an important role in shaping the discipline and giving the discipline its unique identity. AIS is initiating an effort to collect, preserve, interpret, write and disseminate the history of the IS field. Ping Zhang was selected as the AIS Historian, and the supporting committee includes Frank Land, Rudy Hirschheim, Doug Vogel, Richard Baskerville, Dan Robey, and Andy Schwarz. AIS hopes to maintain the legacy and heritage of the IS field by starting now when many pioneers in our field are still among us. As part of the first initiatives, the AIS History committee is organizing panels at IS conferences, including ECIS, PACIS, AMCIS and ICIS. This is one type of activity that will help collect as well as communicate/share the IS history with the community. The main idea is to invite some of the most influential pioneers in our field as the panelists to offer their memories, opinions, suggestions, and share such with the audience. At AMCIS, the theme of the panel is: IS Timeline and The Institutional Roles of IS.; IT artifacts and the state of IS research -- To understand the state of IS research is, to a large extent, to understand (1) what are considered IT artifacts by IS scholars, and (2) how do IS scholars approach IT artifacts in their studies. This study addresses these two questions by providing a conceptual model of five types of core IT artifacts and a five-facet framework of IS scholars' approaches to studying IT artifacts. Using a critical literature review, the conceptualizations are tested with the collective wisdom by IS scholars in the most recent IS studies published in the 2009 and 2010 ICIS proceedings. The findings shed light on where the IS discipline is standing in terms of its focus on IT artifacts. Implications for research and practice are discussed. This study contributes to our continued understanding of the development and evolution of the IS discipline and the potential directions it may take.; An Interview with Dr. Gordon Everest on his Career and the IS Field -- ; IS History Initiative: Continued Efforts and Results -- ; The linkage between conferences and journals in the information systems field -- Younger scholars often receive advice to submit work to conferences for feedback and polishing in anticipation that they will later submit it to a journal for publication. But is this a normal practice? What do the IS scholars really think or do about the linkage between conferences and journals? What are IS journals’ policies and their editors-in-chiefs’ views on that linkage? This paper explores aspects of the relationship between conference presentation and journal publication, which include motivations for participating in conferences, potential for subsequent publication, preferred journal targets, and progress of paper development following conference presentation. We obtained data that form the basis for our findings and recommendations from two main sources: 1) a panel study with two sequential surveys of IS scholars who presented papers at three consecutive International Conference on Information Systems (ICIS) meetings (in St. Louis 2010, Shanghai 2011, and Orlando 2012) and 2) an email interview with the editors-in-chief of 21 major IS journals in regard to their respective journals’ policies and their personal views. The paper provides recommendations for various stakeholders including scholars, journal editors, conference organizers, leaders in the field, and anyone outside the IS field who wants to understand its norms and culture.; IS History — The Evolution of IS Education (Conference Panel Abstract) -- ; IS History: What It Is and How to Best Represent It (Conference Panel Abstract) -- ; IS History: The Origin of IS in Different Regions (Conference Panel Abstract) -- ; What consumers think, feel, and do toward digital ADS -- With the wide deployment of digital technologies, come along information artefacts in various forms for various purposes that consumers have to interact with. This paper reports a multi-phase study to address the following questions in the digital advertising context: (1) to what extent did consumers use ads in the past? (2) What are consumers' perceived values toward ads? (3) What are consumers' attitudes toward ads? (4) What is the likelihood that consumers will continue to use or recommend ads in the future? And (5) to what extent can we predict consumers' perceived values, attitudes, and future behavioral intention toward ads? Phase 1 used two focus groups and identified types of ads in three technological platforms. Phase 2 focused on targeted ads in the desktop/web platform and used an online survey with 279 consumers. Phase 3 used another online survey from 218 consumers on two specific types of ads. Collectively, the study provides answers to the questions as well as many other insights for research and practice on digital ads in particular and information artefacts in general.; State of IT artifacts -- The notion of IT artifact as the core of the IS discipline has been generally accepted by IS scholars, despite a thick gray area consisting of multiple and varied conceptualizations of IT artifacts. In this study, we do not seek to clarify this gray area, or to impose any specific worldview upon it. Rather, we strive to present an accurate representation of the current state of IT artifacts as researchers conceptualized them. We do so through content analysis of 134 research articles from the most recent proceedings of the International Conference on Information Systems (ICIS) 2009. We consider three facets for our analysis: IT artifact conceptualization adopted from Orlikowski and Iacono's (2001), context of a study, and granularity of IT artifact treatment. These facets inform us as to the current state of IT artifacts. We provide discussions about the intersections of these three facets, comparison of our analysis of IT artifacts to two other studies, and provide implications for IS scholars and the IS discipline as a whole.; The influence of industries and practice on the IS field -- The history of any academic discipline plays an important role in shaping the discipline, giving the discipline its unique identity, and establishing the foundation for the future. AIS is initiating an effort to collect, preserve, interpret, write and disseminate the history of the IS field. As part of the initiatives, the AIS History task force has organized panels at all major IS conferences, including ECIS, PACIS, AMCIS, and ICIS in 2013 on various aspects of the IS field. This is one type of activity that will help collect as well as disseminate the IS history with the community. More info on the IS history project can be found at http://history.aisnet.org. At AMCIS 2014, the theme of the panel is:The historical development of industries' influence on the future of IS. We hope to recollect some major events, decision points, milestones, and critical thoughts over the many decades on how industry and practice has influenced the IS discipline in terms of its topical focus, education emphasis and curricula, philosophical positions, research approaches, and other aspects. The ultimate goal is to gain insight on the future roles of industry and practice in the IS discipline.; Social commerce research -- Social commerce has quickly emerged as a new area of inquiry for both practitioners and researchers, suggesting the potential impacts of social media and social networking technologies and services in shaping commercial channels on and off the Internet. This essay starts by providing a brief overview of social commerce research and practice in light of the wide attention it has drawn in the industry. Then, we propose a research framework with an integrated view of social commerce that consists of four key components: business, technology, people, and information. The framework helps us understand the development of social commerce research and practice to date. Subsequently, we report some preliminary findings from a bibliometric study of academic and industry publications in social commerce to reveal recent trends and research topics, as well as some verification of the research framework. Finally, we discuss five articles in this special issue and categorize them in terms of the proposed social commerce research framework."
Rachel Clarke,"Breaking records -- A bibliographic record is a conceptual whole that includes all bibliographic information about a resource together in one place. With the Semantic Web, individual data statements are linked across the web. This position article argues that the traditional conceptualization of bibliographic records affects the affordances and limitations of that data. A historical analysis of the development of bibliographic records contrasted with the Semantic Web model reveals how the “record” model shaped library cataloging and the implications on library catalogs today. Reification of the record model for bibliographic data hampers possibilities for innovation in cataloging, inspiring a reconceptualization of bibliographic description.; Color By Numbers -- ; Beyond Buildings -- ; Cataloging and Classification for Art and Design School Libraries -- ; User Perceptions of Associative Thesaural Relationships -- ; Metadata for Digitally Distributed Video Games at the Seattle Interactive Media Museum -- ; Facet Analysis of Video Game Genres -- ; Picturing Classification -- ; Using critical design to explore the future of libraries -- Purpose: The purpose of this paper is to propose the use of critical design as an approach for considering the future of libraries. Design/methodology/approach: This paper describes a specific instance of critical design: timeline of the far future of libraries. Findings: Reflections on the critical design are presented. Originality/value: This paper offers the first application of critical design in the context of librarianship.; Toward a design epistemology for librarianship -- The design of information tools and services is an integral component of librarianship, yet American librarianship has self-identified as a social science for more than 100 years. This article suggests an alternative epistemological perspective to the scientific tradition in librarianship: design epistemology. The article discusses key elements that compose design epistemology and presents examples of manifestations of these elements in librarianship. Analysis reveals that librarianship has much in common with design epistemology, yet the field lacks explicit acknowledgment of design as a fundamental epistemological framework. The article concludes with a call to reconceptualize librarianship as a design discipline.; Designing a New Librarianship -- ; Designing Innovative Library and Information Services: The Design Thinking Process -- ; Transitioning From the MLS to the MLD -- ; Design Thinking for Design Librarians -- ; STEMming the Tide -- ; Visualizing Library of Congress Subject Headings in Charlottesville’s Wake -- ; Timeline of the Far Future of Libraries -- ; Where Do Librarians Come From? -- ; It’s Not Rocket Library Science -- ; Design Topics in Graduate Library Education -- ; Everyday Cataloger Concerns -- ; Toward a Third Wave of User-Centered Librarianship -- ; Powerful Propaganda -- ; Designing the Future of Librarianship -- ; Breaking Records: The History of Bibliographic Records and Their Influence in Conceptualizing Bibliographic Data -- ; The Power of the Card Catalog -- ; How we done it good -- “How we done it good” publications—a genre concerning project-based approaches that describe how (and sometimes why) something was done—are often rebuked in the library research community for lacking traditional scientific validity, reliability, and generalizability. While scientific methodologies may be a common approach to research and inquiry, they are not the only methodological paradigms. This research posits that the how we done it good paradigm in librarianship reflects a valid and legitimate approach to research. By drawing on the concept of research through design, this study shows how these how we done it good projects reflect design methodologies which draw rigor from process, invention, relevance, and extensibility rather than replicability, generalizability, and predictability. Although these projects implicitly reflect research through design, the methodology is not yet explicitly harnessed in librarianship. More support for these types of projects can be achieved by making the legitimate design framework more explicit and increasing support from publication venues.; Cataloging research by design -- This article asserts that many research questions (RQs) in cataloging reflect design-based RQs, rather than traditional scientific ones. To support this idea, a review of existing discussions of RQs is presented to identify prominent types of RQs, including design-based RQs. RQ types are then classified into a taxonomic framework and compared with RQs from the Everyday Cataloger Concerns project, which aimed to identify important areas of research from the perspective of practicing catalogers. This comparative method demonstrates the ways in which the research areas identified by cataloging practitioners reflect design RQs—and therefore require design approaches and methods to answer them.; The more things change, the more they stay the same -- Discussions of diversity in American librarianship usually focus on gender or ethnicity, but historical studies also show a lack of diversity in educational and disciplinary backgrounds. Librarians traditionally hail from the humanities, especially English and history. But as current educational attention shifts to science, technology, engineering, and math (STEM) fields, are librarians reflecting this change? Anonymized data from ALA-accredited graduate programs from the last five years were collected, coded, and classified to determine librarians' educational and disciplinary backgrounds and in what ways, if any, they differ from the past 65 years and from the contemporary US general population. Unsurprisingly, we found that contemporary librarians still hail predomitly from English and history'a stark contrast from the business and health undergraduate degrees earned by the general US population. Backgrounds in STEM fields remain lacking in librarianship, but librarians with undergraduate education in the arts are on the rise, perhaps supporting the creativity, flexibility, innovation, and risk taking necessary in twenty-first-century libraries.; Exploring the role of repertoire in library cataloging -- Purpose: Library work is increasingly being explored from the perspective of design. Still, little work has actively explored specific aspects of design as they relate to library cataloging. The purpose of this paper is to dive deeper into the relationship between library cataloging and design by exploring a specific aspect of design – the concept of repertoire, or the use of previous experiences and bodies of knowledge during current work. Design/methodology/approach: To examine catalogers’ use of repertoire, this paper employed a juxtaposition of field observations of professional library catalogers’ work processes with elements of “think-aloud” protocols. Findings: The researchers identified three major types of repertory knowledge that were demonstrated by catalogers: internally embedded repertory knowledge; externally embedded repertory knowledge; and seeking out new knowledge using other sources. Additionally, certain trends were noted concerning which repertory knowledge was utilized for which particular task. Determining subject and genre headings were noted for relying quite extensively on internal repertoire such as personal knowledge and institutional knowledge, along with external sources, such as personal notes and local examples. Originality/value: This paper adds to a growing body of work calling for design approaches in libraries and related information settings, and breaks ground by applying the previously unexplored concept of repertoire to librarianship, specifically library cataloging, which offers a new perspective on cataloger’s judgement.; Metadata for diversity -- Purpose: The purpose of this paper is to investigate what metadata elements for access points currently exist to represent diverse library reading materials, either in libraries or from external sources, as well as what metadata elements for access points are currently not present but are necessary to represent diverse library reading materials. Design/methodology/approach: A field scan of thirteen contemporary metadata schemas identified elements that might serve as potential access points regarding the diversity status of resource creators as well as topical or thematic content. Elements were semantically mapped using a metadata crosswalk to understand the intellectual and conceptual space of the elements. Element definitions and application of controlled vocabularies were also examined where possible to offer an additional context. Findings: Metadata elements describing gender, occupation, geographic region, audience and age currently exist in many schemas and could potentially be used to offer access to diverse library materials. However, metadata elements necessary to represent racial, ethnic, national and cultural identity are currently not present in specific forms necessary for enabling resource access and collection assessment. The lack of distinct elements contributes to the implicit erasure of marginalized identities. Originality/value: The search for metadata describing diversity is a first step toward enabling more systematic access to diverse library materials. The need for systematic description of diversity to make visible and promote diverse materials is highlighted in this paper. Though the subject of this paper is library organization systems and, for clarity, uses terms specific to the library profession, the issues present are relevant to all information professionals and knowledge organization systems.; Design thinking and methods in library practice and graduate library education -- Despite interest in the application of design thinking and methods in librarianship, there seems to be a disconnect between application and education to support it. This study used an online questionnaire to elicit feedback from library workers in the United States about interest in and use of design thinking and methods in library practice, and the need for design skills and abilities in library education. We found that practicing librarians perceive design thinking and methods have relevance to library work, but opinions vary based on library type and nature of the work. Design thinking and methods were used mostly for space planning and program development, with applications emphasizing empathy and user/community understanding aspects—despite myriad other possibilities. Most respondents were in favor of including design thinking and methods in MLIS programs, which can support more robust applications through inclusion of the theoretical, philosophical, and epistemological underpinnings from which design thinking and methods emerge.; Design thinking -- ; What We Mean When We Say ‘Design’: A Field Scan of Coursework Offerings on Design Topics in Master’s Level Library Education -- ; The Role of Design in Poole’s Index to Periodical Literature: Implications for American Librarianship -- ; The Critical Catalog: Social Justice, Tricksterism, and Library Information Systems -- ; From “Library Science” to “Library Design”: Recasting the Narrative of Academic Librarianship -- ; The Critical Catalog: Giving Voice to Diverse Library Materials through Provocative Design -- ; The critical catalog -- Although laudable strides have been made to highlight and provide access to diverse library materials about and made by traditionally marginalized communities, current approaches are curatorial, non-scalable, and non-systematic. Using a critical design approach, we address how libraries might move beyond curatorial practices with the proposal of a “Critical Catalog” that advocates for diverse materials and discusses the problems and challenges of categorizing identity. The proposed provocative catalog offers the possibility to raise awareness of diverse library materials; expose readers to new and different resources, ideas and cultures; alter reading habits; and ultimately provide more equitable representation by preventing the inadvertent and unintentional erasure of diverse library materials, thus giving a stronger voice to marginalized communities.; A conceptual model for video games and interactive media -- In this article, we describe a conceptual model for video games and interactive media. Existing conceptual models such as the Functional Requirements for Bibliographic Records (FRBR) are not adequate to represent the unique descriptive attributes, levels of variance, and relationships among video games. Previous video game-specific models tend to focus on the development of video games and their technical aspects. Our model instead attempts to reflect how users such as game players, collectors, and scholars understand video games and the relationships among them. We specifically consider use cases of gamers, with future intentions of using this conceptual model as a foundation for developing a union catalog for various libraries and museums. In the process of developing the model, we encountered many challenges, including conceptual overlap with and divergence from FRBR, entity scoping, complex relationships among entities, and the question of how to model additional content for game expansion. Future work will focus on making this model interoperable with existing ontologies as well as further understanding and description of content and relationships.; Empirical evaluation of metadata for video games and interactive media -- Despite increasing interest in and acknowledgment of the significance of video games, current descriptive practices are not sufficiently robust to support searching, browsing, and other access behaviors from diverse user groups. To address this issue, the Game Metadata Research Group at the University of Washington Information School, in collaboration with the Seattle Interactive Media Museum, worked to create a standardized metadata schema. This metadata schema was empirically evaluated using multiple approaches - collaborative review, schema testing, semi-structured user interview, and a large-scale survey. Reviewing and testing the schema revealed issues and challenges in sourcing the metadata for particular elements, determining the level of granularity for data description, and describing digitally distributed games. The findings from user studies suggest that users value various subject and visual metadata, information about how games are related to each other, and data regarding game expansions/alterations such as additional content and networked features. The metadata schema was extensively revised based on the evaluation results, and we present the new element definitions from the revised schema in this article. This work will serve as a platform and catalyst for advances in the design and use of video game metadata.; Developing a video game metadata schema for the Seattle Interactive Media Museum -- As interest in video games increases, so does the need for intelligent access to them. However, traditional organizational systems and standards fall short. To fill this gap, we are collaborating with the Seattle Interactive Media Museum to develop a formal metadata schema for video games. In the paper, we describe how the schema was established from a user-centered design approach and introduce the core elements from our schema. We also discuss the challenges we encountered as we were conducting a domain analysis and cataloging real-world examples of video games. Inconsistent, vague, and subjective sources of information for title, genre, release date, feature, region, language, developer and publisher information confirm the importance of developing a standardized description model for video games.; A qualitative investigation of users' discovery, access, and organization of video games as information objects -- Video games are popular consumer products as well as research subjects, yet little exists about how players and other stakeholders find video games and what information they need to select, acquire and play video games. With the aim of better understanding people's game-related information needs and behaviour, we conducted 56 semi-structured interviews with users who find, play, purchase, collect and recommend video games. Participants included gamers, parents, collectors, industry professionals, librarians, educators and scholars. From this user data, we derive and discuss key design implications for video game information systems: designing for target user populations, enabling recommendations based on appeals, offering multiple automatic organization options and providing relationship-based, user-generated, subject and visual metadata. We anticipate this work will contribute to building future video game information systems with new and improved access to games.; Understanding Appeals of Video Games for Readers’ Advisory and Recommendation -- ; Learning by design -- Librarianship has not traditionally been considered a design practice. However, children's librarians plan, deliver, and reflect on storytimes in implicit ways that seem to align with design principles. Drawing on empirical data from the VIEWS2 study, this poster explores the premise that design principles implicitly inform the creation of these library programs for young children. Comparing models of storytime production and models of design reveals that key design principles—especially iteration and reflection—are present throughout storytime production. The reciprocal and influential nature of these design concepts combined with the model of storytime production lead to a new model of storytime design, with implications for library research, practice, and pedagogy as well as models of design.; More Than Form and Function -- "
Radhika Garg,"An Exploratory Study for Understanding Reasons of (Not-)Using Internet of Things -- ; Open data privacy and security policy issues and its influence on embracing the Internet of Things -- Information and communication technologies (ICT) are changing the way people interact with each other. Today, every physical device can have the capability to connect to the Internet (digital presence) to send and receive data. Internet connected cameras, home automation systems, connected cars are all examples of interconnected Internet of Things (IoT). IoT can bring benefits to users in terms of monitoring and intelligent capabilities, however, these devices collect, transmit, store, and have a potential to share vast amount of personal and individual data that encroach private spaces and can be vulnerable to security breaches. The ecosystem of IoT comprises not only of users, various sensors, and devices but also other stakeholders of IoT such as data collectors, processors, regulators, and policy-makers. Even though the number of commercially available IoT devices is on steep rise, the uptake of these devices has been slow, and abandonment rapid. This paper explains how stakeholders (including users) and technologies form an assemblage in which these stakeholders are cumulatively responsible for making IoT an essential element of day-to-day living and connectivity. To this end, this paper examines open issues in data privacy and security policies (from perspectives of the European Union and North America), and its effects on stakeholders in the ecosystem. This paper concludes by explaining how these open issues, if unresolved, can lead to another wave of digital division and discrimination in the use of IoT.; Exploring everyday sharing practices of smart speakers -- Smart devices like mobile phones, tablets, and smart watches are designed under the assumption that they will be used by a single user. In contrast, many other devices such as smart thermostats and smart speakers are inherently sharable. This paper presents preliminary results (based on a data set of 15 participants) from an ongoing multi-methods study (using diary study and semi-structured interviews) that aims to gain a nuanced understanding of motivators and constraints of sharing such smart devices, which are cumulatively referred to as Internet of Things. Specifically, this paper illuminates the purposes and practices of sharing smart speakers and discusses two influential factors that shape these practices. Finally, we discuss the implications of our findings and provide guidelines for the design of future smart conversational speakers.; Impact of Reddit Discussions on Use or Abandonment of Wearables -- Discussion platform, Reddit, is the third most visited website in the US. People can post their questions on this platform to get varying opinions from fellow users, which in turn might also influence their behavior and choices. Wearables are becoming widely adopted, yet challenges persist in their effective long term use because of technical and device related, or personal issues. Therefore, by employing sentiment analysis, this paper aims to analyze how decisions of use or abandonment of wearables are influenced by discussions on Reddit. The results are based on the analysis of 6680 posts and their associated 50,867 comments posted between December 2015 – December 2017 on the subreddit (user created groups) on android wear. Our results show that sentiment of the discussion is majorly dictated by the sentiment of the post itself, and people decide to continue using their devices when fellow Redditors offer them workarounds, or the discussion receives majority of positive or fact-driven neutral comments.; Legal Considerations of IoT Applications in Fog and Cloud Environments -- The Internet of Things is the latest paradigm that encompasses the potential of connecting a physical object to the Internet, and then utilizes cloud services to collect, store and process data generated by these connected devices. In order to reduce the service latency of computations, processes, and storage at further situated Cloud nodes, the Fog paradigm was born, which brings data management closer to the end user or to the edge of the network of a provider. Fog nodes can not only be geographically distributed, but also more dynamic in nature than cloud nodes, therefore it is even more difficult to ensure data protection. The operation of such complex systems, thus, raises legal issues such as who owns or processes the data, who is liable in terms of a possible security breach. In this paper we aim to discuss the latest advances of corresponding legislation in the European Union and in the United States of America that affect these technology developments. First, we investigate IoT and Fog characteristics and identify different use cases of loT-Fog-Cloud environments that will be then used to discuss possible legal issues. We conclude the paper with role mappings for the identified cases, and by proposing recommendations on how to govern data management in these complex systems to ensure data protection as mandated by current legislations across these two regions. Our investigations imply that as we broaden the scope and complexity of the managed systems, the user control of the sensed private data weakens, and the responsibility of data protection are shifting towards fog, cloud and service providers.; `When you can do it, why can't I?'': Racial and Socioeconomic Differences in Family Technology Use and Non-Us -- There is racial diversity as well as economic inequality in the United States (U.S.). To gain a nuanced understanding of how households from different socio economic and racial backgrounds integrate technology into their lives, we conducted a diary study with 22 parents who were Asian Indian (the fastest-growing immigrant population in U.S.) and 18 who were White American (the largest racial group in U.S.) parents from the working and middle classes. The participants logged in-situ instances of using smart phones and speaker use by, with, and around children for 8 weeks, and were interviewed once every four weeks (two times in total). Our findings reveal differences and similarities in parents' attitudes and practices of using or not using these devices around and with children, in parental restrictions of children's use of technology, and children's daily use patterns. The paper concludes with a discussions of the implications of our findings and suggestions for future design improvements in smart phones and speakers.; An Analysis of (Non-)Use Practices and Decisions of Internet of Things -- Recent market reports have suggested that adoption of the Internet of Things (IoT) does not always lead to long-term use. This paper aims to advance an understanding of the sociological process of the (non-)use of the IoT. To this end, we present results from a mixed-methods study that analyzed survey data from 834 IoT users in the U.S. Many of our participants treated these devices as co-actors for achieving their goals and continued to use them because they had developed a routine or because the devices influenced their social interactions and identity. Participants limited their use of a device when they did not feel in control, when the device failed to understand their intent, or when they did not understand the device’s behavior. We also found that excessive information offered by, disappointment due to, and the complexity of the devices led to their abandonment. Lastly, we discuss the implications of our results for understanding technology (non-)use and provide design recommendations.; “When you can do it, why can’t I?” -- There is racial diversity as well as economic inequality in the United States (U.S.). To gain a nuanced understanding of how households from different socio economic and racial backgrounds integrate technology into their lives, we conducted a diary study with 22 parents who were Asian Indian (the fastest-growing immigrant population in U.S.) and 18 who were White American (the largest racial group in U.S.) parents from the working and middle classes. The participants logged in-situ instances of using smart phones and speaker use by, with, and around children for 8 weeks, and were interviewed once every four weeks (two times in total). Our findings reveal differences and similarities in parents’ attitudes and practices of using or not using these devices around and with children, in parental restrictions of children’s use of technology, and children’s daily use patterns. The paper concludes with a discussions of the implications of our findings and suggestions for future design improvements in smart phones and speakers.; He is just like me"" -- Over the past few years, the technological vision of the HCI and UbiComp communities regarding conversational devices has become manifest in the form of smart speakers such as Google Home and Amazon Echo. Even though millions of households have adopted and integrated these devices into their daily lives, we lack a deep understanding of how different members of a household use such devices. To this end, we conducted interviews with 18 families and collected their Google Home Activity logs to understand the usage patterns of adults and children. Our findings reveal that there are substantial differences in the ways smart speakers are used by adults and children in families over an extended period of time. We report on how parents influence children's use and how different users perceive the devices. Finally, we discuss the implications of our findings and provide guidelines for improving the design of future smart speakers and conversational agents.; Conversational Technologies for In-home Learning -- Today, Conversational Agents (CA) are deeply integrated into the daily lives of millions of families, which has led children to extensively interact with such devices. Studies have suggested that the social nature of CA makes them a good learning companion for children. Therefore, to understand children's preferences for the use of CAs for the purpose of in-home learning, we conducted three participatory design sessions. In order to identify parents' requirements in this regard, we also included them in the third session. We found that children expect such devices to possess a personality and an advanced level of intelligence, and support multiple content domains and learning modes and human-like conversations. Parents desire such devices to include them in their children's learning activities, foster social engagement, and to allow them to monitor their children's use. This understanding will inform the design of future CAs for the purpose of in-home learning.; Impact of voice-based interaction on learning practices and behavior of children -- Smart devices have become an integral part of the everyday lives of children. Today, children can even use voice-based interactions to interact with devices for a wide range of activities. Previous research has shown that voice-driven interfaces have a potential to offer a potent new mechanism for teaching, engaging, and supporting children in daily life. Our paper, therefore, argues that it is critical not only to investigate how children use voice-based interactions to communicate with devices (e.g., smart speakers) but also the nature of relationships that children form with these devices, the influence such use has on children’s learning and behavior, and the role that parents or guardians play in deciding the norms of use for children. We also propose to explicitly and intricately investigate complexities in use and its impact relative to entangled identities (conveyed through overlapping attributes of gender, ethnicity, race, class) and larger social systems. To this end, we propose to use Social Learning Theory to understand how children learn through observing and interacting with smart devices, specifically using voice-based commands. Methodologically, we will conduct participatory design sessions and follow-up interviews to get a nuanced understanding of how children mentally contextualize voice-enabled smart devices and how social influence (e.g., parental expectation/norms), social function of identification (e.g., children’s emotional connection with technology), and learning goals impact their usage patterns."
Steven B Sawyer,"Rules of the game -- We focus on the roles that institutions play relative to information behavior. Our working definition of institution is the formal and informal constraints that form the basis for exchange, relationships, and decision-making. We know that institutions play significant roles in the creation, management, and uses of information. And, scholars have long recognized that institutions have both direct and indirect impacts on the sustainability and ethical value of information. What is less clear are the ways in which institutions and people's information behaviors are mutually-constituted. The goal of this panel is to highlight particular opportunities for expanding the current and modest level of attention to studying the roles of human institutions relative to information. To do so, this panel will involve the audience in a lively conversation about how information science views the role of institutions in information behavior. It includes a participatory design structured activity that will engage the audience in identifying how existing threads of research are making contributions and key areas of further inquiry. The panel will begin with dialogue sharing insights of scholars and practitioners who are interested in data goverce, information behavior, organization of information, and knowledge management. Then the panel will engage the audience in an interactive activity that explores emerging research streams and questions.; Membership has its privileges? Contracting and access to jobs that accommodate work-life needs -- Using job-spell data based on an original survey of Information Technology (IT) degree graduates from five U.S. universities, the authors investigate the link between contracting and a set of job characteristics (accommodating flexible work hours, total work hours, and working from home) associated with work-life needs. Compared with regular employees in similar jobs, workers in both independent- and agency-contracting jobs report more often working at home and working fewer hours per week. Further, agency contracting (but not independent contracting) is associated with lower odds of being able to set one's own work hours. Important differences also emerge in workplaces of varying sizes. For each job characteristic, as workplace size increases, independent contracting jobs deteriorate relative to regular employment jobs. As a consequence, in large workplaces, independent contracting jobs appear to be less accommodating of work-life needs than regular employment jobs.; The Five-Dimensional Space of the Futures of Work -- We advance a structured view of the Futures of Work (FoW) using a futurist’s lens to advance two goals: advancing core dimensions to the FoW while outlining the Futurist’s approach to considering possible futures. Professional futurists point out that they do not predict the future, but rather, build a number of futures – in plural. These views of the futures are presented as scenarios to help decision makers consider alternatives and better understand interactions among the planning dimensions. The scenarios that drive planning are constructed by drawing on characteristics or dimensions that will shape our futures. It is these dimensions that we present here. We offer five foundational dimensions for the FoW, articulating them as opposing perspectives to frame the issue: (1) Virtuality versus Compressed working arrangements; (2) Atomistic work versus Holistic work; (3) Algorithmic versus Human decision-making; (4) Neoliberal capitalism versus Safety-net capitalism; (5) Übermensch versus Nihilists. We use these dimensions to provide scenarios to illustrate their use. We conclude by reflecting on the shock of the 2020 pandemic and the roles of firm size relative to the futures of work.; Design observations for interagency collaboration -- We present 14 design observations for public safety networks (PSNs) and describe how they may apply more broadly to a wider range of inter-organizational systems within the public sector. A PSN is an interagency collaboration focused on developing and using information systems in support of information sharing and functional interoperability among public safety organizations engaged in law enforcement, criminal justice, and emergency response. We base our design observations upon an analysis of an extensive survey of 80 PSNs plus 6 in-depth case studies. The design observations identify commonalities that can guide agencies participating in interagency collaborations in addressing the interlocking issues they face. Our goal in presenting this set of design observations is to: (1) encourage improved PSN systems design and (2) draw attention to the importance of jointly addressing goverce and technological considerations when designing PSNs.; Design observations regarding public safety networks -- Through this paper we advance an initial set of 12 observations that will form the basis for developing design principles for public safety networks (PSN), and more broadly for inter-organizational systems within the public sector. A public safety network is an interagency collaboration focused on the development and use of information and communication technologies to support the information sharing and functional interoperability needs of public safety organizations engaged in law enforcement, criminal justice, and emergency response. Our goal in presenting this initial set of PSN design observations is to: (1) encourage improved PSN systems design through the development of design principles and (2) increase the attention paid, when designing and developing these forms of information systems, to the co-design of structures of goverce and operation that PSN entail.; Patterns of governance among inter-organizational coordination hubs -- We focus on the goverce of inter-organizational coordination hubs (ICH). We do so to advance conceptual and empirical insights about ICH goverce. We are motivated by the simple observation that, increasingly, organizations are engaging in shared activities, often relying on a purpose-built digital infrastructure to support collaboration among organizations. Here we use the conceptualization of network goverce to guide our analysis of characteristics of goverce that distinguish low and high performing ICH. To do this we use fuzzy-set qualitative comparative analysis and data from 61 public safety networks (PSN) - A particular form of ICH. The analysis shows there exist six distinct configurations of PSN goverce practices that lead to high performance. Common to all these configurations is competence in managing both stakeholders and the digital infrastructure. Building from the findings, we advance the role of specific competencies and network goverce more broadly.; Governance configurations for inter-organizational coordination -- We focus on networked arrangements of digital resources that are shared among otherwise independent units to advance conceptual and empirical insights about their goverce. We are motivated by the simple observation that, increasingly, independent organizations are engaging in shared activities, often relying on purpose-built digital infrastructures to support this move to inter-dependence. To advance current conceptualizations of networked goverce, we draw on data from 42 public safety networks and use fuzzy-set qualitative comparative analysis. We do so because fsQCA allows us to account for the realities of inter-dependence among the concepts and variables we consider and to illuminate the multiple viable goverce patterns that are possible. The results show the importance of network-level goverce competencies to manage stakeholders and information infrastructure to achieve high effectiveness of PSN. Analysis makes clear that there exist five configurations of PSN goverce practices that enable high levels of network goverce effectiveness. Common to all these configurations are the network-level competence in managing both stakeholders and the digital infrastructure, suggesting these are necessary (but not sufficient) network-level goverce competencies. Building from the analysis, we advance the role of specific network-level goverce competencies, and the current conceptualization of network goverce more broadly.; Designing Collaborative Networks: Lessons Learned from Public Safety -- ; Social informatics -- ; Requirements engineering blinders -- In this paper we focus empirical and conceptual attention on the social construction of information systems (IS) requirements, and illustrate that IS developers too often choose to ignore, and thus effectively black-box, the complexities of gathering requirements in order to simplify both the difficulties of their work and their relations with customers. The empirical contribution of this paper is evidence drawn from a study of how IS developers pursue requirements engineering and how they conceive its value. The factors we found to be important in this process include: the changing needs of the organization, the ways in which structured IS methods are enacted via experience and social competency, the formation of project groups, and finally engagement in interpersonal conflict and negotiations. Our conceptual contribution is theorization on the nature of developing requirements as a process of social learning.; Theorizing on the take-up of social technologies, organizational policies and norms, and consultants' knowledge-sharing practices -- We identify the effects of specific organizational norms, arrangements, and policies regarding uses of social technologies for informal knowledge sharing by consultants. For this study, the term social technologies refers to the fast-evolving suite of tools such as traditional applications like e-mail, phone, and instant messenger; emerging social networking platforms (often known as social media) such as blogs and wikis; public social networking sites (i.e., Facebook, Twitter, and LinkedIn); and enterprise social networking technologies that are specifically hosted within one organization's computing environment (i.e., Socialtext). Building from structuration theory, the analysis presented focuses on the knowledge practices of consultants related to their uses of social technologies and the ways in which organizational norms and policies influence these practices. A primary contribution of this research is a detailed contextualization of social technology uses by knowledge workers. As many organizations are allowing social media-enabled knowledge sharing to develop organically, most corporate policy toward these platforms remains defensive, not strategic, limiting opportunities. Implications for uses and expectations of social technologies arising from this research will help organizations craft relevant policies and rules to best support technology-enabled informal knowledge practices.; Social networking technologies and organizational knowledge sharing as a sociotechnical ecology -- We focus on how the uses of social networking technologies (SNT) are bound up in knowledge sharing practices. For us SNT include weblogs, wikis, corporate social networking platforms, and social networking sites such as Facebook, Twitter, and LinkedIn. Our focus is to the uses of SNT relative to people's informal networks within and across organizations. We conceive these as multidimensional networks, treating technology and humans symmetrically and as members of the same sociotechnical ecology. To date, evidence indicates that SNTs have multiple roles regarding knowledge sharing in organizational contexts, and it appears that uses of SNT advance collaborative practices in ways not fully congruent with contemporary organizational practices.; Social Technologies, Informal Knowledge Practices, and the Enterprise -- This article focuses on the ways in which social technologies facilitate informal knowledge sharing in the workplace. Social technologies include both common technologies such as email, phone, and instant messenger and emerging social networking technologies, often known as social media or Web 2.0, such as blogs, wikis, public social networking sites (i.e., Facebook, Twitter, and LinkedIn), enterprise social networking technologies, etc. We know social technologies support informal interactions over digital systems and influence informal social connections among people within and across organizational boundaries. To understand the role of social technologies in informal knowledge practices, we pursue a field study of knowledge workers in consulting firms to investigate the role of social technologies in their informal knowledge sharing practices. Our theorizing from the data is guided by the conceptual premises of sociomateriality to better understand the ways social technologies are integrated with common knowledge practices. Findings highlight five knowledge practices supported by the use of social technologies. Building from these findings we offer conceptual insights regarding the material performance of different social technologies as an assemblage.; Personalization of knowledge, personal knowledge ecology, and digital nomadism -- We examine the concept of personal knowledge management using data drawn from our study of digital nomads. We make two contributions: an empirical and conceptual development of knowledge management as it relates to independent workers and an advancement of social informatics that builds on Gibson's ecological perspective. Digital nomads provide an empirical basis to better understand how knowledge management is shifting from organization-centric, with its concomitant emphasis on organizational information systems, to worker-centric, which relies on personal knowledge ecologies. We advance this concept as a combination of personal knowledge management activities and the digital technologies that support them. Our data make clear that individuals are the locus of personal knowledge ecologies, but these ecologies are embedded in a larger community of collaborators, clients, and peers who are often extensively mediated by digital technologies. This embedding and mediation are at the core of the sociotechnical arrangements that define the personal knowledge ecologies that we document.; Networks of innovation -- We theorize on the heterogonous network of people, visions, concepts, technological artifacts, and organizations that come together to enable product innovation. Drawing on the conceptual framing and mechanisms of actor-network theory (ANT), we focus on the relationships among human and non-human actors and their roles to enact new products. We do this to contribute both evidence and theory regarding the concept of a sociotechnical assemblage that serves as the innovation network. Advancing a sociotechnical conceptualization of innovation focuses attention on the contributions of, and linkages among, different types of actors; individuals and organizations, visions and concepts, and technological artifacts and prototypes together create a means for innovation to occur. The empirical basis for this theorizing comes from a detailed study of the community of research scientists, faculty, and graduate students; institutions such as research labs, funding sources, and product companies who were (and mostly still are) involved in tabletop computing. Analysis highlights the centrality of visions, concepts and technological artifacts in the innovation network. We also find that formal organizations play important, but often unrealized, roles in supporting innovation.; Platformic Management, Boundary Resources for Gig Work, and Worker Autonomy -- We advance the concept of platformic management, and the ways in which platforms help to structure project-based or “gig” work. We do so knowing that the popular press and a substantial number of the scholarly publications characterize the “rise of the gig economy” as advancing worker autonomy and flexibility, focusing attention to online digital labor platforms such as Uber and Amazon’s Mechanical Turk. Scholars have conceptualized the procedures of control exercised by these platforms as exerting “algorithmic management,” reflecting the use of extensive data collection to feed algorithms that structure work. In this paper, we broaden the attention to algorithmic management and gig-working control in two ways. First, we characterize the managerial functions of Upwork, an online platform that facilitates knowledge-intensive freelance labor - to advance discourse beyond ride-sharing and room-renting labor. Second, we advance the concept of platformic management as a means to convey a broader and sociotechnical premise of these platforms’ functions in structuring work. We draw on data collected from Upwork forum discussions, interviews with gig workers who use Upwork, and a walkthrough analysis of the Upwork platform to develop our analysis. Our findings lead us to articulate platformic management -- extending beyond algorithms -- and to present the platform as a “boundary resource” to illustrate the paradoxical affordances of Upwork and similar labor platforms. That is, the platform (1) enables the autonomy desired by gig workers, while (2) also serving as a means of control that helps maintain the viability of transactions and protects the platform from disintermediation.; Social scientists, documents and cyberinfrastructure -- A limited understanding of the distributed work practices of social scientists impedes current efforts to develop cyberinfrastructure (CI) that meets the needs of these scholars. In this paper we review literature on the theory, organization, collaborative practices, and epistemic cultures of the social sciences to summarize fundamental characteristics about the nature of their work practices. Building off these insights, we advance a document-centered articulation of social scientists' distributed work practices derived from a pilot study of scholars in the field of information studies. We use a mixed-methodological approach involving the mapping of digital and physical documents, automated tracking of desktop and online repositories, participant-generated images of physical documents and desktop, behavioral queries, along with interviews and participant observation. Our findings suggest that an approach focused on documents offers a tangible entree into understanding the distributed work practices of social scientists. This study aims to help further discussion surrounding the uptake of CI in the social sciences and the role of academic disciplines in the design of CI tools and projects.; Exploring enterprise social systems & organisational change -- ; Conceptualizing time, space and computing for work and organizing -- Through this article we draw on concepts of time and space to help us theorize on the uses of information and communication technologies in work and for organizing. We do so because many of the contemporary discussions regarding work and organization are usually, and too often implicitly, drawing on rudimentary understandings of these concepts. Our focus here is to advance beyond simplistic articulations and to provide a more conceptually sound approach to address time, space and the uses of information and communication technologies in work. We do this focusing on temporal and spatial relations as a means to depict time and space at work. We characterize work as varying by two characteristics: the degree of interaction and the level of individual autonomy. We then develop a functional view of information and communication technologies relative to their uses for production, control, coordination, access and enjoyment. We conclude by integrating these concepts into an initial framework which allows us to theorize that new forms of work are moving towards four distinct forms of organizing. We further argue that each of these four forms has particular spatial and temporal characteristics that have distinct and different needs for information and communication technologies.; Social informatics of data norms -- Big data has been widely promoted across disciplines and sectors for its potential to enhance lives and promote knowledge discovery. However, challenges arise at all stages of the data lifecycle due to the complexity of interactions between data and the contexts within which they are collected and managed, which has implications for interpretations of this data and eventual use of information and the creation of knowledge products from these data. Starting from the perspective of social informatics, this panel will discuss: the reciprocal relationships between data and context; specific challenges in distinct stages of data generation, data repository implementation, data curation, data use, and data reproducibility; and the implications of these challenges and their potential solutions for both social informatics research and society in general.; The social informatics of knowledge -- In the Introduction to this special issue on the Social Informatics of Knowledge, the editors of the issue reflect on the history of the term “social informatics” and how the articles in this issue both reflect and depart from the original concept. We examine how social informatics researchers have studied knowledge, computerization, and the workplace, and how all of those have evolved over time. We describe the process by which articles were included, how they help us understand the field of social informatics scholarship today, and reflect briefly on what the future of the field holds.; Documenting work -- ; Social scientists and cyberinfrastructure -- Contemporary cyberinfrastructure (CI) seem poorly developed to meet the distributed work practices of social scientists. We draw from the literatures of science studies and e-science practices to advance a document-centered articulation of social scientists' distributed work practices. We report on a pilot study to provide some insights into CI needs for these scholars. This study relied on a mixed-methodological approach involving the mapping of digital and physical documents, automated tracking of desktop and online repositories, participant-generated images of physical documents and desktop, behavioral queries, along with interviews and participant observation. Findings suggest a document perspective provides insight into the distributed work practices and CI uses of social scientists.; Digital assemblages -- We develop the concept of digital assemblages in order to advance current theorising on the ways in which information and communication technologies (ICTs) are helping to reshape work. The empirical setting is the US residential real estate industry-a 'living laboratory' for studying information-intensive work and the adoption and uses of ICT. We find that real estate agents' uses of ICT are pervasive and suggest that agents now embed themselves more deeply into the transacting of real estate by actively supporting buyers and sellers, rather than acting primarily as information intermediaries. Building from this, we theorise that this ICT use can more coherently be understood as a 'digital assemblage' rather than a formal information system. Digital assemblages are characterised as distinct patterns of ICT collections that, in use, are functionally equivalent and structurally similar, relying on standardised and commodified ICT and are neither formally designed nor collectively governed.; Special issue on futures for research on information systems -- ; The social design of information systems -- This panel focuses on issues of designing information systems to both account for, and better support, the increasingly social functions that computer-based tech nologies play. The goal of this panel is to serve as a forum to advance and discuss initial principles for what we are calling the social design of information systems. By social design we mean to emphasize that the presence and uses of information systems play an often significant role in supporting the reshaping social relations, social structures, social boundaries, and social norms. Many such aspects of this reshaping are highlighted in the scholarship of IFIP 8.2 members, and with this panel we seek to focus the collective attention of the assembled scholars to shift attention from (problematizing( the issues with designing information systems toward advancing socially relevant design principles (e.g., Iivari et al. 1998).; Social interactions of information systems development teams -- We report results from a longitudinal study of information systems development (ISD) teams. We use data drawn from 60 ISD teams at 22 sites of 15 Fortune 500 organizations to explore variations in performance relative to these teams social interactions. To do this, we characterize ISD as a form of new product development and focus on team-level social interactions with external stakeholders. Drawing on cluster analysis, we identify five patterns of team-level social interactions and the relationships of these patterns to a suite of objective and subjective measures of ISD performance. Analysis leads us to report three findings. First, data indicate that no one of the five identified patterns maximizes all performance measures. Second, data make clear that the most common approach to ISD is the least effective relative to our suite of performance measures. Third, data from this study show that early indications of ISD project success do not predict actual outcomes. These findings suggest two issues for research and practice. First, these findings indicate that varying patterns of social interactions lead to differences in ISD team performance. Second, the findings illustrate that singular measures of ISD performance are an oversimplification and that multiple measures of ISD performance are unlikely to agree.; U.S. public safety networks -- Through this paper we advance insights regarding common patterns among information and communication technology (ICT) architectures (ICTA) found in United States' public safety networks (PSNs). A PSN is an inter-organizational collaboration enabled by ICT to support information sharing and interoperability needs of police and associated public safety organizations. Substantial evidence makes clear the information systems designed and used by PSNs are typically expensive and complex, support multiple public agencies from different organs of government and span different political and geographic boundaries. Better understanding of PSN ICTA patterns could lead to improved designs and possibly improved performance of these (and perhaps other forms of) multi-agency technology-enabled collaborations. Empirical data from 61 operational PSNs provides the basis for this work. These data were analyzed using fuzzy set Qualitative Comparative Analysis (fsQCA), an approach ideally suited for detailed analyses across smaller data sets that allows us to assess inter-dependence among variables. Results show that (1) functionally similar configuration patterns of ICTA exist among PSNs and (2) several common architectural patterns are associated with higher levels of PSN performance, but these include a large number of unique successful arrangements.; Architectural patterns of U.S. public safety networks -- This paper contains analysis and some initial insights into the patterns of information technology (IT) architecture found in United States' public safety networks (PSNs). A PSN is understood to be an inter-organizational collaboration enabled by IT in support of the information sharing and interoperability needs of police and associated public safety organizations. We know the information systems designed and used by PSNs are often complex, expensive, and must support multiple public safety agencies. Improving our understanding of PSN IT architecture patterns could lead to improved designs and possibly improved performance of PSNs themselves. Data collected on 61 PSNs are analyzed using fuzzy set Qualitative Comparative Analysis (fsQCA). The fsQCA method is explained in detail for those unfamiliar with this technique. Results illuminate (1) functionally similar configuration patterns of IT architecture among PSNs and (2) multiple architectural patterns associated with PSN performance.; Sociotechnical approaches to the study of information systems -- Through this chapter, we introduce and explain the sociotechnical premise relative to the study of information systems (IS). The sociotechnical premise can be articulated as (1) the mutual constitution of people and technologies (and, specifically, digital technologies*), (2) the contextual embeddedness of this mutuality, and (3) the importance of collective action. Some readers will value this chapter for its breadth of coverage. Established sociotechnical scholars will likely thirst for more advanced discussions than what we provide here. Some readers will value the material in this chapter for identifying particular debates, current themes, or emerging approaches. We see this as a special opportunity and focus on these topics at the chapter’s end.; Infrastructural Competence -- ; Advancing Social Informatics -- ; Comparing internal and external interoperability of digital infrastructures -- This research study compares the internal and external interoperability of digital infrastructures across two cyberinfrastructure organizations. Internal interoperability refers to the work that goes into developing seamless relations to align people and resources for a CI provision whereas external interoperability refers to the linkages the CI provision makes to the larger institutional ecology of science. The case study is designed to look at the goverce of digital infrastructures to understand policy decisions in relation to three institutional aspects of science: funding, publication norms, and training and professionalization. Initial findings suggest that internal interoperability is similar for both digital infrastructures whereas external interoperability differs and is shaped by the domain of science that is stewarding the development of the provision. The study concludes by suggesting that linking digital infrastructure development to the components of science practice may be a starting point to understand how they become embedded (or not) in scientific work.; Distancing Bonus Or Downscaling Loss? The Changing Livelihood of Us Online Workers in Times of COVID-19 -- We draw on data from the Online Labour Index and interviews with freelancers in the United States securing work on online platforms, to illuminate effects of the COVID-19 pandemic. The pandemic's global economic upheaval is shuttering shops and offices. Those able to do so are now working remotely from their homes. They join workers who have always been working remotely: freelancers who earn some or all of their income from projects secured via online labour platforms. Data allow us to sketch a first picture of how the initial months of the COVID-19 pandemic have affected the livelihoods of online freelancers. The data shows online labour demand falling rapidly in early March 2020, but with an equally rapid recovery. We also find significant differences between countries and occupations. Data from interviews make clear jobs are increasingly scarce even as more people are creating profiles and seeking freelance work online.; Intellectual diversity and the faculty composition of iSchools -- We provide evidence and discuss findings regarding the intellectual distribution and faculty composition of academic units involved in the iSchool community. To better understand the intellectual heritage and major influences shaping the development of the individual and collective identities in iSchools, we develop a classification of the intellectual domains of iSchool faculty education. We use this to develop a descriptive analysis of the community's intellectual composition. The discussion focuses on characterizing intellectual diversity in the iSchools. We conclude with a discussion of the potential implications of these trends relative to the future development of the iSchool community.; Documents and distributed scientific collaboration -- We ask the question: What document infrastructures do scientists build to support their virtual organizing and documenting practices? Cyberinfrastructure (CI) is seen by many as playing a critical role in the future of social, behavioral, and economic sciences (SBE) by enabling innovation and scientific discovery. However, little is known about SBE scientists' distributed collaboration, a vital practice that CI must support for the doing of science. To provide insight into this question we interviewed 12 scientists regarding their work practices as they pursue joint research projects with colleagues from other universities. We identify the most frequently used physical and digital tools for SBE science and collaboration and characterize commonplace scientific practices in this domain with a paradigmatic example."
